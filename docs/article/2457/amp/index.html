<!DOCTYPE html>
<html amp lang="en-US">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1">
		<title>知识蒸馏（Knowledge Distillation） – 有组织在!</title>
		<link rel="canonical" href="https://uzzz.org/article/2457/">
	<script type="text/javascript" src="https://cdn.ampproject.org/v0.js" async></script>
<style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>	<script type="application/ld+json">{"@context":"http:\/\/schema.org","publisher":{"@type":"Organization","name":"有组织在!","logo":"https:\/\/uzzz.org\/wp-content\/uploads\/2019\/10\/cropped-icon.png"},"@type":"BlogPosting","mainEntityOfPage":"https:\/\/uzzz.org\/article\/2457\/","headline":"知识蒸馏（Knowledge Distillation）","datePublished":"2018-06-04T08:55:38+00:00","dateModified":"2018-06-04T08:55:38+00:00","author":{"@type":"Person","name":"fandyvon"}}</script>
	
	<style amp-custom>
		/* Generic WP styling */

.alignright {
	float: right;
}

.alignleft {
	float: left;
}

.aligncenter {
	display: block;
	text-align: center;
	margin-left: auto;
	margin-right: auto;
}

.amp-wp-enforced-sizes {
	/** Our sizes fallback is 100vw, and we have a padding on the container; the max-width here prevents the element from overflowing. **/
	max-width: 100%;
	margin: 0 auto;
}


/*
 * Prevent cases of amp-img converted from img to appear with stretching by using object-fit to scale.
 * See <https://github.com/ampproject/amphtml/issues/21371#issuecomment-475443219>.
 * Also use object-fit:contain in worst case scenario when we can't figure out dimensions for an image.
 * Additionally, in side of \AMP_Img_Sanitizer::determine_dimensions() it could $amp_img->setAttribute( 'object-fit', 'contain' )
 * so that the following rules wouldn't be needed.
 */
amp-img.amp-wp-enforced-sizes[layout="intrinsic"] > img,
amp-anim.amp-wp-enforced-sizes[layout="intrinsic"] > img {
	object-fit: contain;
}

amp-fit-text blockquote,
amp-fit-text h1,
amp-fit-text h2,
amp-fit-text h3,
amp-fit-text h4,
amp-fit-text h5,
amp-fit-text h6 {
	font-size: inherit;
}

/**
 * Override a style rule in Twenty Sixteen and Twenty Seventeen.
 * It set display:none for audio elements.
 * This selector is the same, though it adds body and uses amp-audio instead of audio.
 */
body amp-audio:not([controls]) {
	display: inline-block;
	height: auto;
}

/*
 * Style the default template messages for submit-success, submit-error, and submitting. These elements are inserted
 * by the form sanitizer when a POST form lacks the action-xhr attribute.
 */
.amp-wp-default-form-message > p {
	margin: 1em 0;
	padding: 0.5em;
}

.amp-wp-default-form-message[submitting] > p,
.amp-wp-default-form-message[submit-success] > p.amp-wp-form-redirecting {
	font-style: italic;
}

.amp-wp-default-form-message[submit-success] > p:not(.amp-wp-form-redirecting) {
	border: solid 1px #008000;
	background-color: #90ee90;
	color: #000;
}

.amp-wp-default-form-message[submit-error] > p {
	border: solid 1px #f00;
	background-color: #ffb6c1;
	color: #000;
}

/* Prevent showing empty success message in the case of an AMP-Redirect-To response header. */
.amp-wp-default-form-message[submit-success] > p:empty {
	display: none;
}

amp-carousel .amp-wp-gallery-caption {
	position: absolute;
	bottom: 0;
	left: 0;
	right: 0;
	text-align: center;
	background-color: rgba(0, 0, 0, 0.5);
	color: #fff;
	padding: 1rem;
}

.wp-block-gallery[data-amp-carousel="true"] {
	display: block;
	flex-wrap: unset;
}

/* Template Styles */

.amp-wp-content,
.amp-wp-title-bar div {
		margin: 0 auto;
	max-width: 840px;
	}

html {
	background: #0a89c0;
}

body {
	background: #fff;
	color: #353535;
	font-family: Georgia, 'Times New Roman', Times, Serif;
	font-weight: 300;
	line-height: 1.75em;
}

p,
ol,
ul,
figure {
	margin: 0 0 1em;
	padding: 0;
}

a,
a:visited {
	color: #0a89c0;
}

a:hover,
a:active,
a:focus {
	color: #353535;
}

/* Quotes */

blockquote {
	color: #353535;
	background: rgba(127,127,127,.125);
	border-left: 2px solid #0a89c0;
	margin: 8px 0 24px 0;
	padding: 16px;
}

blockquote p:last-child {
	margin-bottom: 0;
}

/* UI Fonts */

.amp-wp-meta,
.amp-wp-header div,
.amp-wp-title,
.wp-caption-text,
.amp-wp-tax-category,
.amp-wp-tax-tag,
.amp-wp-comments-link,
.amp-wp-footer p,
.back-to-top {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen-Sans", "Ubuntu", "Cantarell", "Helvetica Neue", sans-serif;
}

/* Header */

.amp-wp-header {
	background-color: #0a89c0;
}

.amp-wp-header div {
	color: #fff;
	font-size: 1em;
	font-weight: 400;
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: .875em 16px;
	position: relative;
}

.amp-wp-header a {
	color: #fff;
	text-decoration: none;
}


.amp-wp-header .amp-wp-site-icon {
	/** site icon is 32px **/
	background-color: #fff;
	border: 1px solid #fff;
	border-radius: 50%;
	position: absolute;
	right: 18px;
	top: 10px;
}

/* Article */

.amp-wp-article {
	color: #353535;
	font-weight: 400;
	margin: 1.5em auto;
	max-width: 840px;
	overflow-wrap: break-word;
	word-wrap: break-word;
}

/* Article Header */

.amp-wp-article-header {
	align-items: center;
	align-content: stretch;
	display: flex;
	flex-wrap: wrap;
	justify-content: space-between;
	margin: 1.5em 16px 0;
}

.amp-wp-title {
	color: #353535;
	display: block;
	flex: 1 0 100%;
	font-weight: 900;
	margin: 0 0 .625em;
	width: 100%;
}

/* Article Meta */

.amp-wp-meta {
	color: #696969;
	display: inline-block;
	flex: 2 1 50%;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0 0 1.5em;
	padding: 0;
}

.amp-wp-article-header .amp-wp-meta:last-of-type {
	text-align: right;
}

.amp-wp-article-header .amp-wp-meta:first-of-type {
	text-align: left;
}

.amp-wp-byline amp-img,
.amp-wp-byline .amp-wp-author {
	display: inline-block;
	vertical-align: middle;
}

.amp-wp-byline amp-img {
	border: 1px solid #0a89c0;
	border-radius: 50%;
	position: relative;
	margin-right: 6px;
}

.amp-wp-posted-on {
	text-align: right;
}

/* Featured image */

.amp-wp-article-featured-image {
	margin: 0 0 1em;
}
.amp-wp-article-featured-image amp-img {
	margin: 0 auto;
}
.amp-wp-article-featured-image.wp-caption .wp-caption-text {
	margin: 0 18px;
}

/* Article Content */

.amp-wp-article-content {
	margin: 0 16px;
}

.amp-wp-article-content ul,
.amp-wp-article-content ol {
	margin-left: 1em;
}

.amp-wp-article-content .wp-caption {
	max-width: 100%;
}

.amp-wp-article-content amp-img {
	margin: 0 auto;
}

.amp-wp-article-content amp-img.alignright {
	margin: 0 0 1em 16px;
}

.amp-wp-article-content amp-img.alignleft {
	margin: 0 16px 1em 0;
}

/* Captions */

.wp-caption {
	padding: 0;
}

.wp-caption.alignleft {
	margin-right: 16px;
}

.wp-caption.alignright {
	margin-left: 16px;
}

.wp-caption .wp-caption-text {
	border-bottom: 1px solid #c2c2c2;
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0;
	padding: .66em 10px .75em;
}

/* AMP Media */

.alignwide,
.alignfull {
	clear: both;
}

amp-carousel {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}
amp-iframe,
amp-youtube,
amp-instagram,
amp-vine {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}

.amp-wp-article-content amp-carousel amp-img {
	border: none;
}

amp-carousel > amp-img > img {
	object-fit: contain;
}

.amp-wp-iframe-placeholder {
	background: #c2c2c2 url( https://uzzz.org/wp-content/plugins/amp/assets/images/placeholder-icon.png ) no-repeat center 40%;
	background-size: 48px 48px;
	min-height: 48px;
}

/* Article Footer Meta */

.amp-wp-article-footer .amp-wp-meta {
	display: block;
}

.amp-wp-tax-category,
.amp-wp-tax-tag {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 1.5em 16px;
}

.amp-wp-comments-link {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	text-align: center;
	margin: 2.25em 0 1.5em;
}

.amp-wp-comments-link a {
	border-style: solid;
	border-color: #c2c2c2;
	border-width: 1px 1px 2px;
	border-radius: 4px;
	background-color: transparent;
	color: #0a89c0;
	cursor: pointer;
	display: block;
	font-size: 14px;
	font-weight: 600;
	line-height: 18px;
	margin: 0 auto;
	max-width: 200px;
	padding: 11px 16px;
	text-decoration: none;
	width: 50%;
	-webkit-transition: background-color 0.2s ease;
			transition: background-color 0.2s ease;
}

/* AMP Footer */

.amp-wp-footer {
	border-top: 1px solid #c2c2c2;
	margin: calc(1.5em - 1px) 0 0;
}

.amp-wp-footer div {
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: 1.25em 16px 1.25em;
	position: relative;
}

.amp-wp-footer h2 {
	font-size: 1em;
	line-height: 1.375em;
	margin: 0 0 .5em;
}

.amp-wp-footer p {
	color: #696969;
	font-size: .8em;
	line-height: 1.5em;
	margin: 0 85px 0 0;
}

.amp-wp-footer a {
	text-decoration: none;
}

.back-to-top {
	bottom: 1.275em;
	font-size: .8em;
	font-weight: 600;
	line-height: 2em;
	position: absolute;
	right: 16px;
}
		/* Inline stylesheets */
.htmledit_views{font-family:-apple-system,SF UI Text,Arial,PingFang SC,Hiragino Sans GB,Microsoft YaHei,WenQuanYi Micro Hei,sans-serif,SimHei,SimSun}.htmledit_views a>amp-img{padding:1px;margin:1px;border:none;outline:#0782c1 solid 1px}.htmledit_views p{font-size:16px;color:#4d4d4d;font-weight:400;line-height:26px;margin:0 0 16px;overflow-x:auto}.htmledit_views amp-img{max-width:100%}.htmledit_views strong{font-weight:700}.htmledit_views *{box-sizing:border-box}.htmledit_views h1{color:#4f4f4f;margin:8px 0 16px;font-weight:700}.htmledit_views h1{font-size:28px;line-height:36px}.htmledit_views pre{white-space:pre-wrap;word-wrap:break-word;margin:0 0 24px;overflow-x:auto;padding:8px}.htmledit_views pre{font-family:Consolas,Inconsolata,Courier,monospace;font-size:14px;line-height:22px;color:#000}.htmledit_views pre code,.htmledit_views pre code div{font-family:"Source Code Pro","DejaVu Sans Mono","Ubuntu Mono","Anonymous Pro","Droid Sans Mono",Menlo,Monaco,Consolas,Inconsolata,Courier,monospace,"PingFang SC","Microsoft YaHei",sans-serif}.htmledit_views code{border-radius:4px}.htmledit_views a{color:#4ea1db;text-decoration:none}.htmledit_views a:focus,.htmledit_views a:hover{color:#ca0c16}.htmledit_views a:visited{color:#6795b5}.htmledit_views pre code{display:block;line-height:22px;overflow-x:auto;white-space:pre;word-wrap:normal;border-radius:4px;padding:8px}.htmledit_views pre code:not(.hljs){background-color:#f3f4f5}.htmledit_views pre code,.htmledit_views pre code div{font-size:14px}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-539b047{text-align:center}	</style>
</head>

<body class="">

<header id="top" class="amp-wp-header">
	<div>
		<a href="https://uzzz.org/">
										<amp-img src="https://uzzz.org/wp-content/uploads/2019/10/cropped-icon-32x32.png" width="32" height="32" class="amp-wp-site-icon"></amp-img>
						<span class="amp-site-title">
				有组织在!			</span>
		</a>

					</div>
</header>

<article class="amp-wp-article">
	<header class="amp-wp-article-header">
		<h1 class="amp-wp-title">知识蒸馏（Knowledge Distillation）</h1>
			<div class="amp-wp-meta amp-wp-byline">
					<amp-img src="https://secure.gravatar.com/avatar/e786821a74ef0467825a7d60183307bc?s=24&d=mm&r=g" alt="fandyvon" width="24" height="24" layout="fixed"></amp-img>
				<span class="amp-wp-author author vcard">fandyvon</span>
	</div>
<div class="amp-wp-meta amp-wp-posted-on">
	<time datetime="2018-06-04T16:55:38+00:00">
		2 years ago	</time>
</div>
	</header>

	
	<div class="amp-wp-article-content">
		<div id="article_content" class="article_content clearfix">
 <br>
 
 
 
<div class="htmledit_views" id="content_views">
<h1>1、Distilling the Knowledge in a Neural Network</h1>
<p>Hinton的文章”Distilling the Knowledge in a Neural Network”首次提出了知识蒸馏（暗知识提取）的概念，通过引入与教师网络（teacher network：复杂、但推理性能优越）相关的软目标（soft-target）作为total loss的一部分，以诱导学生网络（student network：精简、低复杂度）的训练，实现知识迁移（knowledge transfer）。</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180604160949186?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="640" height="289" layout="intrinsic"><noscript><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180604160949186?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="640" height="289"></noscript></amp-img></p>
<p>如上图所示，教师网络（左侧）的预测输出除以温度参数（Temperature）之后、再做softmax变换，可以获得软化的概率分布（软目标），数值介于0~1之间，取值分布较为缓和。Temperature数值越大，分布越缓和；而Temperature数值减小，容易放大错误分类的概率，引入不必要的噪声。针对较困难的分类或检测任务，Temperature通常取1，确保教师网络中正确预测的贡献。硬目标则是样本的真实标注，可以用one-hot矢量表示。total loss设计为软目标与硬目标所对应的交叉熵的加权平均（表示为KD loss与CE loss），其中软目标交叉熵的加权系数越大，表明迁移诱导越依赖教师网络的贡献，这对训练初期阶段是很有必要的，有助于让学生网络更轻松的鉴别简单样本，但训练后期需要适当减小软目标的比重，让真实标注帮助鉴别困难样本。另外，教师网络的推理性能通常要优于学生网络，而模型容量则无具体限制，且教师网络推理精度越高，越有利于学生网络的学习。</p>
<p>教师网络与学生网络也可以联合训练，此时教师网络的暗知识及学习方式都会影响学生网络的学习，具体如下（式中三项分别为教师网络softmax输出的交叉熵loss、学生网络softmax输出的交叉熵loss、以及教师网络数值输出与学生网络softmax输出的交叉熵loss）：</p>
<p><strong>联合训练的Paper地址：</strong><a href="https://arxiv.org/abs/1711.05852" rel="nofollow" data-token="7c9a7dab2065570ef96d38a9c0285090">https://arxiv.org/abs/1711.05852</a></p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="44" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180906092731238?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="540" layout="intrinsic"><noscript><img alt="" class="has" height="44" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180906092731238?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="540"></noscript></amp-img></p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="331" src="https://uzshare.com/_p?https://img-blog.csdn.net/201809060928044?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="673" layout="intrinsic"><noscript><img alt="" class="has" height="331" src="https://uzshare.com/_p?https://img-blog.csdn.net/201809060928044?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="673"></noscript></amp-img></p>
<h1>2、Exploring Knowledge Distillation of Deep Neural Networks for Efficient Hardware Solutions</h1>
<p>这篇文章将total loss重新定义如下：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180604162913410?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="688" height="26" layout="intrinsic"><noscript><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180604162913410?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="688" height="26"></noscript></amp-img></p>
<p><strong>GitHub地址：</strong><a href="https://github.com/peterliht/knowledge-distillation-pytorch" rel="nofollow" data-token="fbeb707ed47634087a5e836b433b1f02">https://github.com/peterliht/knowledge-distillation-pytorch</a></p>
<p>total loss的Pytorch代码如下，引入了精简网络输出与教师网络输出的KL散度，并在诱导训练期间，先将teacher network的预测输出缓存到CPU内存中，可以减轻GPU显存的overhead：</p>
<pre class="has">
<code class="language-python">def loss_fn_kd(outputs, labels, teacher_outputs, params):
    """
    Compute the knowledge-distillation (KD) loss given outputs, labels.
    "Hyperparameters": temperature and alpha
    NOTE: the KL Divergence for PyTorch comparing the softmaxs of teacher
    and student expects the input tensor to be log probabilities! See Issue #2
    """
    alpha = params.alpha
    T = params.temperature
    KD_loss = nn.KLDivLoss()(F.log_softmax(outputs/T, dim=1),
                             F.softmax(teacher_outputs/T, dim=1)) * (alpha * T * T) + \
                             F.cross_entropy(outputs, labels) * (1. - alpha)

    return KD_loss</code></pre>
<h1>3、Ensemble of Multiple Teachers</h1>
<p><strong>第一种算法：</strong>多个教师网络输出的soft label按加权组合，构成统一的soft label，然后指导学生网络的训练：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="127" src="https://uzshare.com/_p?https://img-blog.csdn.net/2018090414465243?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="530" layout="intrinsic"><noscript><img alt="" class="has" height="127" src="https://uzshare.com/_p?https://img-blog.csdn.net/2018090414465243?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="530"></noscript></amp-img></p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="270" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180904144737333?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="535" layout="intrinsic"><noscript><img alt="" class="has" height="270" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180904144737333?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="535"></noscript></amp-img></p>
<p><strong>第二种算法：</strong>由于加权平均方式会弱化、平滑多个教师网络的预测结果，因此可以随机选择某个教师网络的soft label作为guidance：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="200" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180904145125595?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="539" layout="intrinsic"><noscript><img alt="" class="has" height="200" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180904145125595?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="539"></noscript></amp-img></p>
<p><strong>第三种算法：</strong>同样地，为避免加权平均带来的平滑效果，首先采用教师网络输出的soft label重新标注样本、增广数据、再用于模型训练，该方法能够让模型学会从更多视角观察同一样本数据的不同功能：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="224" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180904145903860?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="536" layout="intrinsic"><noscript><img alt="" class="has" height="224" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180904145903860?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="536"></noscript></amp-img></p>
<p><strong>Paper地址：</strong></p>
<p><a href="https://www.researchgate.net/publication/319185356_Efficient_Knowledge_Distillation_from_an_Ensemble_of_Teachers" rel="nofollow" data-token="6cdd0157e63dc26e6c9f039d431913ad">https://www.researchgate.net/publication/319185356_Efficient_Knowledge_Distillation_from_an_Ensemble_of_Teachers</a></p>
<h1>4、Hint-based Knowledge Transfer</h1>
<p>为了能够诱导训练更深、更纤细的学生网络（deeper and thinner FitNet），需要考虑教师网络中间层的Feature Maps（作为Hint），用来指导学生网络中相应的Guided layer。此时需要引入L2 loss指导训练过程，该loss计算为教师网络Hint layer与学生网络Guided layer输出Feature Maps之间的差别，若二者输出的Feature Maps形状不一致，Guided layer需要通过一个额外的回归层，具体如下：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="59" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180904151630725?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="709" layout="intrinsic"><noscript><img alt="" class="has" height="59" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180904151630725?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="709"></noscript></amp-img></p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="317" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180904150852311?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="863" layout="intrinsic"><noscript><img alt="" class="has" height="317" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180904150852311?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="863"></noscript></amp-img></p>
<p><strong>具体训练过程分两个阶段完成：</strong>第一个阶段利用Hint-based loss诱导学生网络达到一个合适的初始化状态（只更新W_Guided与W_r）；第二个阶段利用教师网络的soft label指导整个学生网络的训练（即知识蒸馏），且total loss中soft target相关部分所占比重逐渐降低，从而让学生网络能够全面辨别简单样本与困难样本（教师网络能够有效辨别简单样本，而困难样本则需要借助真实标注，即hard target）：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="434" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180904152348516?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="927" layout="intrinsic"><noscript><img alt="" class="has" height="434" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180904152348516?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="927"></noscript></amp-img></p>
<p><strong>Paper地址：</strong><a href="https://arxiv.org/abs/1412.6550" rel="nofollow" data-token="63791d3bb0e636fd89563858176c43bc">https://arxiv.org/abs/1412.6550</a></p>
<p><strong>GitHub地址：</strong><a href="https://github.com/adri-romsor/FitNets" rel="nofollow" data-token="e73553587403dd4563b3accafc83a9c4">https://github.com/adri-romsor/FitNets</a></p>
<h1>5、Attention to Attention Transfer</h1>
<p>通过网络中间层的attention map，完成teacher network与student network之间的知识迁移。考虑给定的tensor A，基于activation的attention map可以定义为如下三种之一：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="114" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180925094725131?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="830" layout="intrinsic"><noscript><img alt="" class="has" height="114" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180925094725131?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="830"></noscript></amp-img></p>
<p>随着网络层次的加深，关键区域的attention-level也随之提高。文章最后采用了第二种形式的attention map，取p=2，并且activation-based attention map的知识迁移效果优于gradient-based attention map，loss定义及迁移过程如下：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="67" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180925100235962?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="459" layout="intrinsic"><noscript><img alt="" class="has" height="67" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180925100235962?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="459"></noscript></amp-img></p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="32" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180925100347190?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="414" layout="intrinsic"><noscript><img alt="" class="has" height="32" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180925100347190?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="414"></noscript></amp-img></p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="217" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180925100418174?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="866" layout="intrinsic"><noscript><img alt="" class="has" height="217" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180925100418174?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="866"></noscript></amp-img></p>
<p><strong>Paper地址：</strong><a href="https://arxiv.org/abs/1612.03928" rel="nofollow" data-token="29a0b52ce6f95ffa88749696b80cb572">https://arxiv.org/abs/1612.03928</a></p>
<p><strong>GitHub地址：</strong><a href="https://github.com/szagoruyko/attention-transfer" rel="nofollow" data-token="712ec1aa5770d9c436f3ec4d433bad42">https://github.com/szagoruyko/attention-transfer</a></p>
<h1>6、Flow of the Solution Procedure</h1>
<p>暗知识亦可表示为训练的求解过程（FSP: Flow of the Solution Procedure），教师网络或学生网络的FSP矩阵定义如下（Gram形式的矩阵）：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="91" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180908190729629?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="576" layout="intrinsic"><noscript><img alt="" class="has" height="91" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180908190729629?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="576"></noscript></amp-img></p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="343" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180908190755611?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="611" layout="intrinsic"><noscript><img alt="" class="has" height="343" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180908190755611?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="611"></noscript></amp-img></p>
<p>训练的第一阶段：最小化教师网络FSP矩阵与学生网络FSP矩阵之间的L2 Loss，初始化学生网络的可训练参数：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="420" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180908191130435?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="918" layout="intrinsic"><noscript><img alt="" class="has" height="420" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180908191130435?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="918"></noscript></amp-img></p>
<p>训练的第二阶段：在目标任务的数据集上fine-tune学生网络。从而达到知识迁移、快速收敛、以及迁移学习的目的。</p>
<p><strong>Paper地址：</strong></p>
<p><a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Yim_A_Gift_From_CVPR_2017_paper.pdf" rel="nofollow" data-token="7e1d838d35fcd3bb2deaa4697418f1da">http://openaccess.thecvf.com/content_cvpr_2017/papers/Yim_A_Gift_From_CVPR_2017_paper.pdf</a></p>
<h1>7、Knowledge Distillation with Adversarial Samples Supporting Decision Boundary</h1>
<p>从分类的决策边界角度分析，知识迁移过程亦可理解为教师网络诱导学生网络有效鉴别决策边界的过程，鉴别能力越强意味着模型的泛化能力越好：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="323" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180920145521968?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="886" layout="intrinsic"><noscript><img alt="" class="has" height="323" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180920145521968?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="886"></noscript></amp-img></p>
<p>文章首先利用对抗攻击策略（adversarial attacking）将基准类样本（base class sample）转为目标类样本、且位于决策边界附近（BSS: boundary supporting sample），进而利用对抗生成的样本诱导学生网络的训练，可有效提升学生网络对决策边界的鉴别能力。文章采用迭代方式生成对抗样本，需要沿loss function（基准类得分与目标类得分之差）的梯度负方向调整样本，直到满足停止条件为止：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="283" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180920150428101?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="716" layout="intrinsic"><noscript><img alt="" class="has" height="283" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180920150428101?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="716"></noscript></amp-img></p>
<p>loss function：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="30" src="https://uzshare.com/_p?https://img-blog.csdn.net/2018092015152089?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="234" layout="intrinsic"><noscript><img alt="" class="has" height="30" src="https://uzshare.com/_p?https://img-blog.csdn.net/2018092015152089?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="234"></noscript></amp-img></p>
<p>沿loss function的梯度负方向调整样本：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="68" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180920151540465?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="408" layout="intrinsic"><noscript><img alt="" class="has" height="68" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180920151540465?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="408"></noscript></amp-img></p>
<p>停止条件（只要满足三者之一）：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="136" src="https://uzshare.com/_p?https://img-blog.csdn.net/2018092015160434?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="439" layout="intrinsic"><noscript><img alt="" class="has" height="136" src="https://uzshare.com/_p?https://img-blog.csdn.net/2018092015160434?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="439"></noscript></amp-img></p>
<p>结合对抗生成的样本，利用教师网络训练学生网络所需的total loss包含CE loss、KD loss以及boundary supporting loss（BS loss）：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" height="302" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180920151838819?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="886" layout="intrinsic"><noscript><img alt="" class="has" height="302" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180920151838819?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="886"></noscript></amp-img></p>
<p><strong>Paper地址：</strong><a href="https://arxiv.org/abs/1805.05532" rel="nofollow" data-token="74570507cb0a0f46a8e3d48366718b46">https://arxiv.org/abs/1805.05532</a></p>
<h1>8、Label Refinery：Improving ImageNet Classification through Label Progression</h1>
<p>这篇文章通过迭代式的诱导训练，主要解决训练期间样本的crop与label不一致的问题，以增强label的质量，从而进一步增强模型的泛化能力：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180604163723669?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="790" height="201" layout="intrinsic"><noscript><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180604163723669?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="790" height="201"></noscript></amp-img></p>
<p>诱导过程中，total loss表示为本次迭代（t>1）网络的预测输出（概率分布）与上一次迭代输出（Label Refinery：类似于教师网络的角色）的KL散度：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180604164358160?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="808" height="330" layout="intrinsic"><noscript><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180604164358160?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25hdHVyZTU1Mzg2Mw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="808" height="330"></noscript></amp-img></p>
<p>文章实验部分表明，不仅可以用训练网络作为Label Refinery Network，也可以用其他高质量网络（如Resnet50）作为Label Refinery Network。并在诱导过程中，能够对抗生成样本，实现数据增强。</p>
<p><strong>GitHub地址：</strong><a href="https://github.com/hessamb/label-refinery" rel="nofollow" data-token="e1838d413d06c4f8fdae77d271ab51dc">https://github.com/hessamb/label-refinery</a></p>
<h1>9、Miscellaneous</h1>
<p>——– 知识蒸馏可以与量化结合使用，考虑了中间层Feature Maps之间的关系，<strong>可参考：</strong></p>
<p><a href="https://blog.csdn.net/nature553863/article/details/82147933" rel="nofollow" data-token="63b58e5f5b16fd5081d344dea82399be">https://blog.csdn.net/nature553863/article/details/82147933</a></p>
<p>——– 知识蒸馏与Hint Learning相结合，可以训练精简的Faster-RCNN，<strong>可参考：</strong></p>
<p><a href="https://blog.csdn.net/nature553863/article/details/82463249" rel="nofollow" data-token="c73c3b240a8489852a4ec253d9651f42">https://blog.csdn.net/nature553863/article/details/82463249</a></p>
<p>——– 模型压缩方面，更为详细的讨论，<strong>请参考：</strong></p>
<p><a href="https://blog.csdn.net/nature553863/article/details/81083955" rel="nofollow" data-token="23973bd49e9fd025e976be4cc0a83d29">https://blog.csdn.net/nature553863/article/details/81083955</a></p>
</div>
</div>
	</div>

	<footer class="amp-wp-article-footer">
			<div class="amp-wp-meta amp-wp-tax-category">
		Categories: <a href="https://uzzz.org/category/deeplearning/" rel="category tag">DeepLearning</a>, <a href="https://uzzz.org/category/moxingyasuo/" rel="category tag">模型压缩</a>, <a href="https://uzzz.org/category/wangluoyouhua/" rel="category tag">网络优化</a>	</div>

	</footer>
</article>

<footer class="amp-wp-footer">
	<div>
		<h2>有组织在!</h2>
		<a href="#top" class="back-to-top">Back to top</a>
	</div>
</footer>



</body>
</html>
