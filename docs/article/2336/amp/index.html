<!DOCTYPE html>
<html amp lang="en-US">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1">
	<script type="application/ld+json" class="yoast-schema-graph yoast-schema-graph--main">{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://uzzz.org/#website","url":"https://uzzz.org/","name":"\u6709\u7ec4\u7ec7\u5728!","potentialAction":{"@type":"SearchAction","target":"https://uzzz.org/?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"ImageObject","@id":"https://uzzz.org/article/2336/#primaryimage","url":"https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190307103628854.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI4NTEzMQ==,size_16,color_FFFFFF,t_70"},{"@type":"WebPage","@id":"https://uzzz.org/article/2336/#webpage","url":"https://uzzz.org/article/2336/","inLanguage":"en-US","name":"\u4f4e\u7167\u5ea6\u56fe\u50cf\u589e\u5f3a\u4e4b\u5377\u79ef\u795e\u7ecf\u7f51\u7edcRetinexNet - \u6709\u7ec4\u7ec7\u5728!","isPartOf":{"@id":"https://uzzz.org/#website"},"primaryImageOfPage":{"@id":"https://uzzz.org/article/2336/#primaryimage"},"datePublished":"2019-03-07T03:14:57+00:00","dateModified":"2019-03-07T03:14:57+00:00","author":{"@id":"https://uzzz.org/#/schema/person/29673f1347b0abda5882803c72ee5a3f"}},{"@type":["Person"],"@id":"https://uzzz.org/#/schema/person/29673f1347b0abda5882803c72ee5a3f","name":"fandyvon","sameAs":[]}]}</script>
	<title>低照度图像增强之卷积神经网络RetinexNet - 有组织在!</title>
		<link rel="canonical" href="https://uzzz.org/article/2336/">
	<script type="text/javascript" src="https://cdn.ampproject.org/v0.js" async></script>
<style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>
	<style amp-custom>
		/* Generic WP styling */

.alignright {
	float: right;
}

.alignleft {
	float: left;
}

.aligncenter {
	display: block;
	text-align: center;
	margin-left: auto;
	margin-right: auto;
}

.amp-wp-enforced-sizes {
	/** Our sizes fallback is 100vw, and we have a padding on the container; the max-width here prevents the element from overflowing. **/
	max-width: 100%;
	margin: 0 auto;
}


/*
 * Prevent cases of amp-img converted from img to appear with stretching by using object-fit to scale.
 * See <https://github.com/ampproject/amphtml/issues/21371#issuecomment-475443219>.
 * Also use object-fit:contain in worst case scenario when we can't figure out dimensions for an image.
 * Additionally, in side of \AMP_Img_Sanitizer::determine_dimensions() it could $amp_img->setAttribute( 'object-fit', 'contain' )
 * so that the following rules wouldn't be needed.
 */
amp-img.amp-wp-enforced-sizes[layout="intrinsic"] > img,
amp-anim.amp-wp-enforced-sizes[layout="intrinsic"] > img {
	object-fit: contain;
}

amp-fit-text blockquote,
amp-fit-text h1,
amp-fit-text h2,
amp-fit-text h3,
amp-fit-text h4,
amp-fit-text h5,
amp-fit-text h6 {
	font-size: inherit;
}

/**
 * Override a style rule in Twenty Sixteen and Twenty Seventeen.
 * It set display:none for audio elements.
 * This selector is the same, though it adds body and uses amp-audio instead of audio.
 */
body amp-audio:not([controls]) {
	display: inline-block;
	height: auto;
}

/*
 * Style the default template messages for submit-success, submit-error, and submitting. These elements are inserted
 * by the form sanitizer when a POST form lacks the action-xhr attribute.
 */
.amp-wp-default-form-message > p {
	margin: 1em 0;
	padding: 0.5em;
}

.amp-wp-default-form-message[submitting] > p,
.amp-wp-default-form-message[submit-success] > p.amp-wp-form-redirecting {
	font-style: italic;
}

.amp-wp-default-form-message[submit-success] > p:not(.amp-wp-form-redirecting) {
	border: solid 1px #008000;
	background-color: #90ee90;
	color: #000;
}

.amp-wp-default-form-message[submit-error] > p {
	border: solid 1px #f00;
	background-color: #ffb6c1;
	color: #000;
}

/* Prevent showing empty success message in the case of an AMP-Redirect-To response header. */
.amp-wp-default-form-message[submit-success] > p:empty {
	display: none;
}

amp-carousel .amp-wp-gallery-caption {
	position: absolute;
	bottom: 0;
	left: 0;
	right: 0;
	text-align: center;
	background-color: rgba(0, 0, 0, 0.5);
	color: #fff;
	padding: 1rem;
}

.wp-block-gallery[data-amp-carousel="true"] {
	display: block;
	flex-wrap: unset;
}

/* Template Styles */

.amp-wp-content,
.amp-wp-title-bar div {
		margin: 0 auto;
	max-width: 840px;
	}

html {
	background: #0a89c0;
}

body {
	background: #fff;
	color: #353535;
	font-family: Georgia, 'Times New Roman', Times, Serif;
	font-weight: 300;
	line-height: 1.75em;
}

p,
ol,
ul,
figure {
	margin: 0 0 1em;
	padding: 0;
}

a,
a:visited {
	color: #0a89c0;
}

a:hover,
a:active,
a:focus {
	color: #353535;
}

/* Quotes */

blockquote {
	color: #353535;
	background: rgba(127,127,127,.125);
	border-left: 2px solid #0a89c0;
	margin: 8px 0 24px 0;
	padding: 16px;
}

blockquote p:last-child {
	margin-bottom: 0;
}

/* UI Fonts */

.amp-wp-meta,
.amp-wp-header div,
.amp-wp-title,
.wp-caption-text,
.amp-wp-tax-category,
.amp-wp-tax-tag,
.amp-wp-comments-link,
.amp-wp-footer p,
.back-to-top {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen-Sans", "Ubuntu", "Cantarell", "Helvetica Neue", sans-serif;
}

/* Header */

.amp-wp-header {
	background-color: #0a89c0;
}

.amp-wp-header div {
	color: #fff;
	font-size: 1em;
	font-weight: 400;
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: .875em 16px;
	position: relative;
}

.amp-wp-header a {
	color: #fff;
	text-decoration: none;
}


.amp-wp-header .amp-wp-site-icon {
	/** site icon is 32px **/
	background-color: #fff;
	border: 1px solid #fff;
	border-radius: 50%;
	position: absolute;
	right: 18px;
	top: 10px;
}

/* Article */

.amp-wp-article {
	color: #353535;
	font-weight: 400;
	margin: 1.5em auto;
	max-width: 840px;
	overflow-wrap: break-word;
	word-wrap: break-word;
}

/* Article Header */

.amp-wp-article-header {
	align-items: center;
	align-content: stretch;
	display: flex;
	flex-wrap: wrap;
	justify-content: space-between;
	margin: 1.5em 16px 0;
}

.amp-wp-title {
	color: #353535;
	display: block;
	flex: 1 0 100%;
	font-weight: 900;
	margin: 0 0 .625em;
	width: 100%;
}

/* Article Meta */

.amp-wp-meta {
	color: #696969;
	display: inline-block;
	flex: 2 1 50%;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0 0 1.5em;
	padding: 0;
}

.amp-wp-article-header .amp-wp-meta:last-of-type {
	text-align: right;
}

.amp-wp-article-header .amp-wp-meta:first-of-type {
	text-align: left;
}

.amp-wp-byline amp-img,
.amp-wp-byline .amp-wp-author {
	display: inline-block;
	vertical-align: middle;
}

.amp-wp-byline amp-img {
	border: 1px solid #0a89c0;
	border-radius: 50%;
	position: relative;
	margin-right: 6px;
}

.amp-wp-posted-on {
	text-align: right;
}

/* Featured image */

.amp-wp-article-featured-image {
	margin: 0 0 1em;
}
.amp-wp-article-featured-image amp-img {
	margin: 0 auto;
}
.amp-wp-article-featured-image.wp-caption .wp-caption-text {
	margin: 0 18px;
}

/* Article Content */

.amp-wp-article-content {
	margin: 0 16px;
}

.amp-wp-article-content ul,
.amp-wp-article-content ol {
	margin-left: 1em;
}

.amp-wp-article-content .wp-caption {
	max-width: 100%;
}

.amp-wp-article-content amp-img {
	margin: 0 auto;
}

.amp-wp-article-content amp-img.alignright {
	margin: 0 0 1em 16px;
}

.amp-wp-article-content amp-img.alignleft {
	margin: 0 16px 1em 0;
}

/* Captions */

.wp-caption {
	padding: 0;
}

.wp-caption.alignleft {
	margin-right: 16px;
}

.wp-caption.alignright {
	margin-left: 16px;
}

.wp-caption .wp-caption-text {
	border-bottom: 1px solid #c2c2c2;
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0;
	padding: .66em 10px .75em;
}

/* AMP Media */

.alignwide,
.alignfull {
	clear: both;
}

amp-carousel {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}
amp-iframe,
amp-youtube,
amp-instagram,
amp-vine {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}

.amp-wp-article-content amp-carousel amp-img {
	border: none;
}

amp-carousel > amp-img > img {
	object-fit: contain;
}

.amp-wp-iframe-placeholder {
	background: #c2c2c2 url( https://uzzz.org/wp-content/plugins/amp/assets/images/placeholder-icon.png ) no-repeat center 40%;
	background-size: 48px 48px;
	min-height: 48px;
}

/* Article Footer Meta */

.amp-wp-article-footer .amp-wp-meta {
	display: block;
}

.amp-wp-tax-category,
.amp-wp-tax-tag {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 1.5em 16px;
}

.amp-wp-comments-link {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	text-align: center;
	margin: 2.25em 0 1.5em;
}

.amp-wp-comments-link a {
	border-style: solid;
	border-color: #c2c2c2;
	border-width: 1px 1px 2px;
	border-radius: 4px;
	background-color: transparent;
	color: #0a89c0;
	cursor: pointer;
	display: block;
	font-size: 14px;
	font-weight: 600;
	line-height: 18px;
	margin: 0 auto;
	max-width: 200px;
	padding: 11px 16px;
	text-decoration: none;
	width: 50%;
	-webkit-transition: background-color 0.2s ease;
			transition: background-color 0.2s ease;
}

/* AMP Footer */

.amp-wp-footer {
	border-top: 1px solid #c2c2c2;
	margin: calc(1.5em - 1px) 0 0;
}

.amp-wp-footer div {
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: 1.25em 16px 1.25em;
	position: relative;
}

.amp-wp-footer h2 {
	font-size: 1em;
	line-height: 1.375em;
	margin: 0 0 .5em;
}

.amp-wp-footer p {
	color: #696969;
	font-size: .8em;
	line-height: 1.5em;
	margin: 0 85px 0 0;
}

.amp-wp-footer a {
	text-decoration: none;
}

.back-to-top {
	bottom: 1.275em;
	font-size: .8em;
	font-weight: 600;
	line-height: 2em;
	position: absolute;
	right: 16px;
}
		/* Inline stylesheets */
.htmledit_views{font-family:-apple-system,SF UI Text,Arial,PingFang SC,Hiragino Sans GB,Microsoft YaHei,WenQuanYi Micro Hei,sans-serif,SimHei,SimSun}.htmledit_views a>amp-img{padding:1px;margin:1px;border:none;outline:#0782c1 solid 1px}.htmledit_views p{font-size:16px;color:#4d4d4d;font-weight:400;line-height:26px;margin:0 0 16px;overflow-x:auto}.htmledit_views amp-img{max-width:100%}.htmledit_views strong,.htmledit_views strong span{font-weight:700}.htmledit_views *{box-sizing:border-box}.htmledit_views h1,.htmledit_views h2{color:#4f4f4f;margin:8px 0 16px;font-weight:700}.htmledit_views h1{font-size:28px;line-height:36px}.htmledit_views h2{font-size:24px;line-height:32px}.htmledit_views blockquote{display:block;padding:16px 16px 0;margin:0 0 24px;border-left:8px solid #dddfe4;background:#eef0f4;overflow:auto;overflow-scrolling:touch;word-wrap:normal;word-break:normal}.htmledit_views blockquote p{font-size:16px;line-height:26px;font-weight:400;margin-bottom:16px;color:#4f4f4f}.htmledit_views hr{margin:24px 0;border:none;border-bottom:solid #ccc 1px}.htmledit_views a{color:#4ea1db;text-decoration:none}.htmledit_views a:focus,.htmledit_views a:hover{color:#ca0c16}.htmledit_views a:visited{color:#6795b5}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-7abfdd6{margin-left:0px}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-b5fbaa3{margin-left:40px}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-a0b0ba1{text-indent:50px}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-539b047{text-align:center}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-22360c5{color:#f33b45}	</style>
</head>

<body class="">

<header id="top" class="amp-wp-header">
	<div>
		<a href="https://uzzz.org/">
										<amp-img src="https://uzzz.org/wp-content/uploads/2019/10/cropped-icon-32x32.png" width="32" height="32" class="amp-wp-site-icon"></amp-img>
						<span class="amp-site-title">
				有组织在!			</span>
		</a>

					</div>
</header>

<article class="amp-wp-article">
	<header class="amp-wp-article-header">
		<h1 class="amp-wp-title">低照度图像增强之卷积神经网络RetinexNet</h1>
			<div class="amp-wp-meta amp-wp-byline">
					<amp-img src="https://secure.gravatar.com/avatar/e786821a74ef0467825a7d60183307bc?s=24&d=mm&r=g" alt="fandyvon" width="24" height="24" layout="fixed"></amp-img>
				<span class="amp-wp-author author vcard">fandyvon</span>
	</div>
<div class="amp-wp-meta amp-wp-posted-on">
	<time datetime="2019-03-07T11:14:57+00:00">
		1 year ago	</time>
</div>
	</header>

	
	<div class="amp-wp-article-content">
		<div id="article_content" class="article_content clearfix">
 <br>
 
 
 
<div class="htmledit_views" id="content_views">
<p>转载请标注：<a href="https://blog.csdn.net/weixin_38285131" rel="nofollow" data-token="80fb09a8d7a278708c96af0751400ca6">https://blog.csdn.net/weixin_38285131</a></p>
<p> </p>
<p id="main-toc"><strong>目录</strong></p>
<p id="**%E4%B8%80%E4%B8%B6Retinex%E7%90%86%E8%AE%BA%E2%80%94%E2%80%94%E5%9B%BE%E5%83%8F%E5%88%86%E8%A7%A3**-toc" class="amp-wp-7abfdd6"><a href="#**%E4%B8%80%E4%B8%B6Retinex%E7%90%86%E8%AE%BA%E2%80%94%E2%80%94%E5%9B%BE%E5%83%8F%E5%88%86%E8%A7%A3**" rel="nofollow" data-token="6015e61e9a12442bb5ad4e3b1d8c15ad">一丶Retinex理论——图像分解</a></p>
<p id="%E4%BA%8C%E4%B8%B6RetinexNet%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C-toc" class="amp-wp-7abfdd6"><a href="#%E4%BA%8C%E4%B8%B6RetinexNet%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C" rel="nofollow" data-token="5e6b61dcaeb5becd0e2f0e2179cf15b3">二丶RetinexNet卷积神经网络</a></p>
<p id="1.%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E8%AF%B4%E6%98%8E-toc" class="amp-wp-b5fbaa3"><a href="#1.%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E8%AF%B4%E6%98%8E" rel="nofollow" data-token="8f8c35233fe3727f1c1b42733b229737">1.训练数据说明</a></p>
<p id="2.%E5%88%86%E8%A7%A3%E7%BD%91%E7%BB%9C%E2%80%94%E2%80%94Decom-toc" class="amp-wp-b5fbaa3"><a href="#2.%E5%88%86%E8%A7%A3%E7%BD%91%E7%BB%9C%E2%80%94%E2%80%94Decom" rel="nofollow" data-token="ca9569f6354592fdf13ca16deb22517e">2.分解网络——Decom</a></p>
<p id="3.%E5%A2%9E%E5%BC%BA%E7%BD%91%E7%BB%9C%E2%80%94%E2%80%94Relight-toc" class="amp-wp-b5fbaa3"><a href="#3.%E5%A2%9E%E5%BC%BA%E7%BD%91%E7%BB%9C%E2%80%94%E2%80%94Relight" rel="nofollow" data-token="ac2c9595bc8f466bd180e77dec6fd99e">3.增强网络——Relight</a></p>
<p id="4.%E7%BB%93%E6%9E%9C%E5%B1%95%E7%A4%BA-toc" class="amp-wp-b5fbaa3"><a href="#4.%E7%BB%93%E6%9E%9C%E5%B1%95%E7%A4%BA" rel="nofollow" data-token="403a0550cfbde01ac556b50304fb8ade">4.结果展示</a></p>
<p>         低照度图像增强一直是计算机视觉领域的一个热门研究方向，之前传统的基于Retinex理论的研究方法已经出现很多，比如：MSR,MSRCR,MSRCP等，这些方法在低照度图像增强方面效果有明显提升，上一篇博客主要介绍了基于Retinex理论的集中图像增强方法，并给出了python代码。博客链接如下：   <br><a href="https://blog.csdn.net/weixin_38285131/article/details/88097771" rel="nofollow" data-token="696c9959ed1320933cad101d04427e22">[图像增强Retinex算法之python实现——MSR,MSRCR,MSRCP,autoMSRCR]</a>(https://blog.csdn.net/weixin_38285131/article/details/88097771)<br>         但是基于传统的图像图像处理方法处理每一张图像会比较耗时，一副4000*8000的图像需要耗时十几分钟，这样就没法批量处理低照度图像，因此本文介绍一种基于Retinex理论的卷积神经网络模型——RetinexNet,该模型是北大的童鞋在2018年发表在BMVC上的，论文名字是——<span class="amp-wp-22360c5">Deep Retinex Decomposition for Low-Light Enhancement</span><br>     <a href="http://arxiv.org/pdf/1808.04560" rel="nofollow" data-token="936cf138e9e4e57f87d8ec1a4011de5d"> [论文PDF]</a><br>    <a href="https://daooshee.github.io/BMVC2018website/" rel="nofollow" data-token="b83ecf1744121b36e2c34fcc6b41e84a"> RetinexNet项目介绍，数据集，PPT等</a></p>
<h1 id="**%E4%B8%80%E4%B8%B6Retinex%E7%90%86%E8%AE%BA%E2%80%94%E2%80%94%E5%9B%BE%E5%83%8F%E5%88%86%E8%A7%A3**">一丶Retinex理论——图像分解</h1>
<p>这个理论在上一篇博客中已有介绍，任何一幅图像可以分解为光照图像（illumination）和反射图像（reflectance），反射图像是物体的本身性质决定的即为不变的部分，光照图则受外界影响比较到，可以去除光照影响或者对光照图像进行校正，则可以达到增强图像的目的。如下图所示：</p>
<p><amp-img alt="" class="has amp-wp-enforced-sizes" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190307103628854.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI4NTEzMQ==,size_16,color_FFFFFF,t_70" width="808" height="231" layout="intrinsic"><noscript><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190307103628854.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI4NTEzMQ==,size_16,color_FFFFFF,t_70" width="808" height="231"></noscript></amp-img></p>
<p>左边即为低照度图像，中间即为光照图，右边即为反射图像，原图S（x,y）=I(x,y)*R(x,y),将图像变换到log域则变成了相减，然后将光照图像减去即可达到增强图像的目的。</p>
<h1 id="%E4%BA%8C%E4%B8%B6RetinexNet%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">二丶RetinexNet卷积神经网络</h1>
<p>摘抄自论文摘要：</p>
<p>Retinex理论是一种有效的微光图像增强工具。假设观测图像<span class="amp-wp-22360c5">可以分解为反射图像和照度图像</span>。大多数现有的基于Retinex卢纶的方法都为这种高度不适定的分解精心设计了手工约束和参数，当应用于各种场景时，这些约束和参数可能会受到模型容量的限制。Retinex包括一个用于分解的分解网络（Decom）和一个用于照明调节（Relight）的增强网络。在分解网络的训练过程中，没有分解反射和光照的地面真值。该网络的学习只有关键的约束条件，包括<span class="amp-wp-22360c5">低/正常光图像共享的一致反射率</span>，以及光照的平滑度。在分解的基础上，利用增强网络增强网对光照进行后续的亮度增强，联合去噪对反射率进行去噪操作。视网膜网是端到端可训练的，学习分解的性质有利于亮度的调节。</p>
<p>理论整体路线即为下图所示：</p>
<p><amp-img alt="" class="has amp-wp-enforced-sizes" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190307104436199.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI4NTEzMQ==,size_16,color_FFFFFF,t_70" width="848" height="480" layout="intrinsic"><noscript><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190307104436199.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI4NTEzMQ==,size_16,color_FFFFFF,t_70" width="848" height="480"></noscript></amp-img></p>
<blockquote>
<p>输入:低照度图像</p>
<p>分解网络（Decom）：对图像进行分解</p>
<p>增强网络（Relight）：对图像进行增强和调整</p>
<p>输出：校正之后的图像</p>
</blockquote>
<h2 id="1.%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E8%AF%B4%E6%98%8E">1.训练数据说明</h2>
<p>数据主要是利用单反相机不同的光圈值和感光度拍摄同一个场景，作为<strong><span class="amp-wp-22360c5">图像对</span></strong>进行训练，也就是说同一场景拍摄一个低照度图像，然后在拍摄一个正常图像进行训练，具体数据如下图所示：</p>
<p><amp-img alt="" class="has amp-wp-enforced-sizes" height="267" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190307105210787.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI4NTEzMQ==,size_16,color_FFFFFF,t_70" width="401" layout="intrinsic"><noscript><img alt="" class="has" height="267" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190307105210787.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI4NTEzMQ==,size_16,color_FFFFFF,t_70" width="401"></noscript></amp-img><amp-img alt="" class="has amp-wp-enforced-sizes" height="269" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190307105235142.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI4NTEzMQ==,size_16,color_FFFFFF,t_70" width="404" layout="intrinsic"><noscript><img alt="" class="has" height="269" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190307105235142.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI4NTEzMQ==,size_16,color_FFFFFF,t_70" width="404"></noscript></amp-img></p>
<p>作图为正常拍摄图像，右图为低照度图像，大概拍摄了500张图像对作为训练数据</p>
<h2 id="2.%E5%88%86%E8%A7%A3%E7%BD%91%E7%BB%9C%E2%80%94%E2%80%94Decom">2.分解网络——Decom</h2>
<p class="amp-wp-a0b0ba1">文中的分解网络应该是一个<span class="amp-wp-22360c5">五层的卷积神经网络</span>，代码中是利用relu函数进行激活，没有什么特别的处理，具体结构如下：</p>
<p class="amp-wp-a0b0ba1"><amp-img alt="" class="has amp-wp-enforced-sizes" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190307104837180.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI4NTEzMQ==,size_16,color_FFFFFF,t_70" width="438" height="454" layout="intrinsic"><noscript><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190307104837180.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI4NTEzMQ==,size_16,color_FFFFFF,t_70" width="438" height="454"></noscript></amp-img></p>
<p class="amp-wp-a0b0ba1">可以看到将图像对中的低照度图像和正常图像作为输入数据送入卷积神经网络进行分解，最后得到光照图像和反射图像，根据Retinex理论<span class="amp-wp-22360c5">反射图像基本接近，但是两者光照图像相差很大</span>，这样把每一张训练图像进行分解，然后再送入后面的增强网络进行训练。</p>
<h2 id="3.%E5%A2%9E%E5%BC%BA%E7%BD%91%E7%BB%9C%E2%80%94%E2%80%94Relight">3.增强网络——Relight</h2>
<p>增强网络，我看代码应该是一个九层的卷积神经网络，利用relu进行激活，中间还进行最邻近差值的resize操作，具体如下图：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190307110220911.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI4NTEzMQ==,size_16,color_FFFFFF,t_70" width="553" height="443" layout="intrinsic"><noscript><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190307110220911.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI4NTEzMQ==,size_16,color_FFFFFF,t_70" width="553" height="443"></noscript></amp-img></p>
<p> 对刚才分解的反射图像进行去噪音操作，他中间用了平滑，但是<span class="amp-wp-22360c5">我觉得用了平滑之后降低了图像本身的锐度，图像变得模糊</span>，个人觉得这一步还应该做一下增强处理，回头看看能不能修改一下这个中间处理操作。应该可以用拉普拉斯进行一下图像恢复吧，我觉得这一步降低图像锐度不太好，重建图像稍显模糊。</p>
<h2 id="4.%E7%BB%93%E6%9E%9C%E5%B1%95%E7%A4%BA">4.结果展示</h2>
<p><amp-img alt="" class="has amp-wp-enforced-sizes" height="197" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190307110659257.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI4NTEzMQ==,size_16,color_FFFFFF,t_70" width="296" layout="intrinsic"><noscript><img alt="" class="has" height="197" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190307110659257.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI4NTEzMQ==,size_16,color_FFFFFF,t_70" width="296"></noscript></amp-img><amp-img alt="" class="has amp-wp-enforced-sizes" height="199" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190307110721532.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI4NTEzMQ==,size_16,color_FFFFFF,t_70" width="299" layout="intrinsic"><noscript><img alt="" class="has" height="199" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190307110721532.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI4NTEzMQ==,size_16,color_FFFFFF,t_70" width="299"></noscript></amp-img><amp-img alt="" class="has amp-wp-enforced-sizes" height="200" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019030711075724.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI4NTEzMQ==,size_16,color_FFFFFF,t_70" width="300" layout="intrinsic"><noscript><img alt="" class="has" height="200" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019030711075724.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI4NTEzMQ==,size_16,color_FFFFFF,t_70" width="300"></noscript></amp-img></p>
<p>中间即为校正之后的，右边为正常光照图像，虽然和正常图像比不了，但是已经很不错了，</p>
<p><amp-img alt="" class="has amp-wp-enforced-sizes" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190307111037453.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI4NTEzMQ==,size_16,color_FFFFFF,t_70" width="1334" height="1063" layout="intrinsic"><noscript><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190307111037453.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zODI4NTEzMQ==,size_16,color_FFFFFF,t_70" width="1334" height="1063"></noscript></amp-img></p>
<p>最后与其他算法做了一些对比工作，感觉各有千秋吧，不过都有一定的亮度提升，还是很值得研究一哈的 做一下改进。</p>
<p>下一步，我准备用这个神经网络训练一下自己的数据，然后测试一下增强效果。</p>
<p><a href="https://pan.baidu.com/s/1SQwNMIw-meZE58HlHbE0xQ?errno=0&errmsg=Auth%20Login%20Sucess&&bduss=&ssnerror=0&traceid=" rel="nofollow" data-token="d811d83e92a6c4e4933330da0f55a37f">数据集百度网盘地址</a></p>
<p><a href="https://github.com/weichen582/RetinexNet" rel="nofollow" data-token="1c2bab8727bf4cbf1efa5b9e21f3db4f">github地址</a></p>
<p> </p>
<p>转载请注明地址：<a href="https://blog.csdn.net/weixin_38285131" rel="nofollow" data-token="80fb09a8d7a278708c96af0751400ca6">https://blog.csdn.net/weixin_38285131</a></p>
<p> </p>
<hr id="hr-toc">
<p> </p>
</div>
</div>
	</div>

	<footer class="amp-wp-article-footer">
			<div class="amp-wp-meta amp-wp-tax-category">
		Categories: <a href="https://uzzz.org/category/deeplearning/" rel="category tag">DeepLearning</a>, <a href="https://uzzz.org/category/suanfa/" rel="category tag">算法</a>, <a href="https://uzzz.org/category/jisuanji/" rel="category tag">计算机</a>	</div>

	</footer>
</article>

<footer class="amp-wp-footer">
	<div>
		<h2>有组织在!</h2>
		<a href="#top" class="back-to-top">Back to top</a>
	</div>
</footer>



</body>
</html>
