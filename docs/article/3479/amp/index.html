<!DOCTYPE html>
<html amp lang="en-US">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1">
	<script type="application/ld+json" class="yoast-schema-graph yoast-schema-graph--main">{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://uzzz.org/#website","url":"https://uzzz.org/","name":"\u6709\u7ec4\u7ec7\u5728!","potentialAction":{"@type":"SearchAction","target":"https://uzzz.org/?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"WebPage","@id":"https://uzzz.org/article/3479/#webpage","url":"https://uzzz.org/article/3479/","inLanguage":"en-US","name":"TensorFlow\u4ece\u56fe\u50cf\u4e2d\u63d0\u53d6\u533a\u57df - \u6709\u7ec4\u7ec7\u5728!","isPartOf":{"@id":"https://uzzz.org/#website"},"datePublished":"2018-06-14T06:45:01+00:00","dateModified":"2018-06-14T06:45:01+00:00","author":{"@id":"https://uzzz.org/#/schema/person/29673f1347b0abda5882803c72ee5a3f"}},{"@type":["Person"],"@id":"https://uzzz.org/#/schema/person/29673f1347b0abda5882803c72ee5a3f","name":"fandyvon","sameAs":[]}]}</script>
	<title>TensorFlow从图像中提取区域 - 有组织在!</title>
		<link rel="canonical" href="https://uzzz.org/article/3479/">
	<script type="text/javascript" src="https://cdn.ampproject.org/v0.js" async></script>
<style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>
	<style amp-custom>
		/* Generic WP styling */

.alignright {
	float: right;
}

.alignleft {
	float: left;
}

.aligncenter {
	display: block;
	text-align: center;
	margin-left: auto;
	margin-right: auto;
}

.amp-wp-enforced-sizes {
	/** Our sizes fallback is 100vw, and we have a padding on the container; the max-width here prevents the element from overflowing. **/
	max-width: 100%;
	margin: 0 auto;
}


/*
 * Prevent cases of amp-img converted from img to appear with stretching by using object-fit to scale.
 * See <https://github.com/ampproject/amphtml/issues/21371#issuecomment-475443219>.
 * Also use object-fit:contain in worst case scenario when we can't figure out dimensions for an image.
 * Additionally, in side of \AMP_Img_Sanitizer::determine_dimensions() it could $amp_img->setAttribute( 'object-fit', 'contain' )
 * so that the following rules wouldn't be needed.
 */
amp-img.amp-wp-enforced-sizes[layout="intrinsic"] > img,
amp-anim.amp-wp-enforced-sizes[layout="intrinsic"] > img {
	object-fit: contain;
}

amp-fit-text blockquote,
amp-fit-text h1,
amp-fit-text h2,
amp-fit-text h3,
amp-fit-text h4,
amp-fit-text h5,
amp-fit-text h6 {
	font-size: inherit;
}

/**
 * Override a style rule in Twenty Sixteen and Twenty Seventeen.
 * It set display:none for audio elements.
 * This selector is the same, though it adds body and uses amp-audio instead of audio.
 */
body amp-audio:not([controls]) {
	display: inline-block;
	height: auto;
}

/*
 * Style the default template messages for submit-success, submit-error, and submitting. These elements are inserted
 * by the form sanitizer when a POST form lacks the action-xhr attribute.
 */
.amp-wp-default-form-message > p {
	margin: 1em 0;
	padding: 0.5em;
}

.amp-wp-default-form-message[submitting] > p,
.amp-wp-default-form-message[submit-success] > p.amp-wp-form-redirecting {
	font-style: italic;
}

.amp-wp-default-form-message[submit-success] > p:not(.amp-wp-form-redirecting) {
	border: solid 1px #008000;
	background-color: #90ee90;
	color: #000;
}

.amp-wp-default-form-message[submit-error] > p {
	border: solid 1px #f00;
	background-color: #ffb6c1;
	color: #000;
}

/* Prevent showing empty success message in the case of an AMP-Redirect-To response header. */
.amp-wp-default-form-message[submit-success] > p:empty {
	display: none;
}

amp-carousel .amp-wp-gallery-caption {
	position: absolute;
	bottom: 0;
	left: 0;
	right: 0;
	text-align: center;
	background-color: rgba(0, 0, 0, 0.5);
	color: #fff;
	padding: 1rem;
}

.wp-block-gallery[data-amp-carousel="true"] {
	display: block;
	flex-wrap: unset;
}

/* Template Styles */

.amp-wp-content,
.amp-wp-title-bar div {
		margin: 0 auto;
	max-width: 840px;
	}

html {
	background: #0a89c0;
}

body {
	background: #fff;
	color: #353535;
	font-family: Georgia, 'Times New Roman', Times, Serif;
	font-weight: 300;
	line-height: 1.75em;
}

p,
ol,
ul,
figure {
	margin: 0 0 1em;
	padding: 0;
}

a,
a:visited {
	color: #0a89c0;
}

a:hover,
a:active,
a:focus {
	color: #353535;
}

/* Quotes */

blockquote {
	color: #353535;
	background: rgba(127,127,127,.125);
	border-left: 2px solid #0a89c0;
	margin: 8px 0 24px 0;
	padding: 16px;
}

blockquote p:last-child {
	margin-bottom: 0;
}

/* UI Fonts */

.amp-wp-meta,
.amp-wp-header div,
.amp-wp-title,
.wp-caption-text,
.amp-wp-tax-category,
.amp-wp-tax-tag,
.amp-wp-comments-link,
.amp-wp-footer p,
.back-to-top {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen-Sans", "Ubuntu", "Cantarell", "Helvetica Neue", sans-serif;
}

/* Header */

.amp-wp-header {
	background-color: #0a89c0;
}

.amp-wp-header div {
	color: #fff;
	font-size: 1em;
	font-weight: 400;
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: .875em 16px;
	position: relative;
}

.amp-wp-header a {
	color: #fff;
	text-decoration: none;
}


.amp-wp-header .amp-wp-site-icon {
	/** site icon is 32px **/
	background-color: #fff;
	border: 1px solid #fff;
	border-radius: 50%;
	position: absolute;
	right: 18px;
	top: 10px;
}

/* Article */

.amp-wp-article {
	color: #353535;
	font-weight: 400;
	margin: 1.5em auto;
	max-width: 840px;
	overflow-wrap: break-word;
	word-wrap: break-word;
}

/* Article Header */

.amp-wp-article-header {
	align-items: center;
	align-content: stretch;
	display: flex;
	flex-wrap: wrap;
	justify-content: space-between;
	margin: 1.5em 16px 0;
}

.amp-wp-title {
	color: #353535;
	display: block;
	flex: 1 0 100%;
	font-weight: 900;
	margin: 0 0 .625em;
	width: 100%;
}

/* Article Meta */

.amp-wp-meta {
	color: #696969;
	display: inline-block;
	flex: 2 1 50%;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0 0 1.5em;
	padding: 0;
}

.amp-wp-article-header .amp-wp-meta:last-of-type {
	text-align: right;
}

.amp-wp-article-header .amp-wp-meta:first-of-type {
	text-align: left;
}

.amp-wp-byline amp-img,
.amp-wp-byline .amp-wp-author {
	display: inline-block;
	vertical-align: middle;
}

.amp-wp-byline amp-img {
	border: 1px solid #0a89c0;
	border-radius: 50%;
	position: relative;
	margin-right: 6px;
}

.amp-wp-posted-on {
	text-align: right;
}

/* Featured image */

.amp-wp-article-featured-image {
	margin: 0 0 1em;
}
.amp-wp-article-featured-image amp-img {
	margin: 0 auto;
}
.amp-wp-article-featured-image.wp-caption .wp-caption-text {
	margin: 0 18px;
}

/* Article Content */

.amp-wp-article-content {
	margin: 0 16px;
}

.amp-wp-article-content ul,
.amp-wp-article-content ol {
	margin-left: 1em;
}

.amp-wp-article-content .wp-caption {
	max-width: 100%;
}

.amp-wp-article-content amp-img {
	margin: 0 auto;
}

.amp-wp-article-content amp-img.alignright {
	margin: 0 0 1em 16px;
}

.amp-wp-article-content amp-img.alignleft {
	margin: 0 16px 1em 0;
}

/* Captions */

.wp-caption {
	padding: 0;
}

.wp-caption.alignleft {
	margin-right: 16px;
}

.wp-caption.alignright {
	margin-left: 16px;
}

.wp-caption .wp-caption-text {
	border-bottom: 1px solid #c2c2c2;
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0;
	padding: .66em 10px .75em;
}

/* AMP Media */

.alignwide,
.alignfull {
	clear: both;
}

amp-carousel {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}
amp-iframe,
amp-youtube,
amp-instagram,
amp-vine {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}

.amp-wp-article-content amp-carousel amp-img {
	border: none;
}

amp-carousel > amp-img > img {
	object-fit: contain;
}

.amp-wp-iframe-placeholder {
	background: #c2c2c2 url( https://uzzz.org/wp-content/plugins/amp/assets/images/placeholder-icon.png ) no-repeat center 40%;
	background-size: 48px 48px;
	min-height: 48px;
}

/* Article Footer Meta */

.amp-wp-article-footer .amp-wp-meta {
	display: block;
}

.amp-wp-tax-category,
.amp-wp-tax-tag {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 1.5em 16px;
}

.amp-wp-comments-link {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	text-align: center;
	margin: 2.25em 0 1.5em;
}

.amp-wp-comments-link a {
	border-style: solid;
	border-color: #c2c2c2;
	border-width: 1px 1px 2px;
	border-radius: 4px;
	background-color: transparent;
	color: #0a89c0;
	cursor: pointer;
	display: block;
	font-size: 14px;
	font-weight: 600;
	line-height: 18px;
	margin: 0 auto;
	max-width: 200px;
	padding: 11px 16px;
	text-decoration: none;
	width: 50%;
	-webkit-transition: background-color 0.2s ease;
			transition: background-color 0.2s ease;
}

/* AMP Footer */

.amp-wp-footer {
	border-top: 1px solid #c2c2c2;
	margin: calc(1.5em - 1px) 0 0;
}

.amp-wp-footer div {
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: 1.25em 16px 1.25em;
	position: relative;
}

.amp-wp-footer h2 {
	font-size: 1em;
	line-height: 1.375em;
	margin: 0 0 .5em;
}

.amp-wp-footer p {
	color: #696969;
	font-size: .8em;
	line-height: 1.5em;
	margin: 0 85px 0 0;
}

.amp-wp-footer a {
	text-decoration: none;
}

.back-to-top {
	bottom: 1.275em;
	font-size: .8em;
	font-weight: 600;
	line-height: 2em;
	position: absolute;
	right: 16px;
}
		/* Inline stylesheets */
.htmledit_views{font-family:-apple-system,SF UI Text,Arial,PingFang SC,Hiragino Sans GB,Microsoft YaHei,WenQuanYi Micro Hei,sans-serif,SimHei,SimSun}.htmledit_views p{font-size:16px;color:#4d4d4d;font-weight:400;line-height:26px;margin:0 0 16px;overflow-x:auto}.htmledit_views strong,.htmledit_views strong span{font-weight:700}.htmledit_views *{box-sizing:border-box}.htmledit_views h3,.htmledit_views h4,.htmledit_views h5,.htmledit_views h6{color:#4f4f4f;margin:8px 0 16px;font-weight:700}.htmledit_views ol,.htmledit_views ul{margin:0 0 24px;padding:0;font-size:16px}.htmledit_views ul ol{margin:0 0 24px 32px}.htmledit_views ul li{list-style-type:disc;margin:8px 0 0 32px}.htmledit_views ol li{list-style-type:decimal;margin-left:40px;margin-top:8px}.htmledit_views h3{font-size:22px;line-height:30px}.htmledit_views h4{font-size:20px;line-height:28px}.htmledit_views h5{font-size:18px;line-height:26px}.htmledit_views h6{font-size:16px;line-height:24px}.htmledit_views hr{margin:24px 0;border:none;border-bottom:solid #ccc 1px}.htmledit_views pre{white-space:pre-wrap;word-wrap:break-word;margin:0 0 24px;overflow-x:auto;padding:8px}.htmledit_views pre{font-family:Consolas,Inconsolata,Courier,monospace;font-size:14px;line-height:22px;color:#000}.htmledit_views pre code,.htmledit_views pre code div,.htmledit_views pre code span{font-family:"Source Code Pro","DejaVu Sans Mono","Ubuntu Mono","Anonymous Pro","Droid Sans Mono",Menlo,Monaco,Consolas,Inconsolata,Courier,monospace,"PingFang SC","Microsoft YaHei",sans-serif}.htmledit_views code{border-radius:4px}.htmledit_views a{color:#4ea1db;text-decoration:none}.htmledit_views a:focus,.htmledit_views a:hover{color:#ca0c16}.htmledit_views a:visited{color:#6795b5}.htmledit_views pre code{display:block;line-height:22px;overflow-x:auto;white-space:pre;word-wrap:normal;border-radius:4px;padding:8px}.htmledit_views pre code:not(.hljs){background-color:#f3f4f5}.htmledit_views pre code,.htmledit_views pre code div,.htmledit_views pre code span{font-size:14px}.htmledit_views code ol{margin:0;overflow:hidden}.htmledit_views code ol li{list-style-type:none;margin-left:0;margin-top:0;height:22px}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-9bd93d3{font-size:12px}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-653ee8d{color:#37474f;font-size:14.4px;line-height:1;font-family:"Roboto Mono",monospace;padding:1px 4px;background-color:#ff6}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-2124342{color:#37474f;font-size:14.4px;line-height:1;font-family:"Roboto Mono",monospace;padding:1px 4px;background-color:#ff0}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-271d8a4{color:#37474f;font-size:14.4px;line-height:1;font-family:"Roboto Mono",monospace;padding:1px 4px}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-6bcdf70{background-color:#ff0}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-953320a{color:#37474f;background:#f7f7f7;font-size:14.4px;line-height:1;font-family:"Roboto Mono",monospace;padding:1px 4px}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-a80b77e{color:#c00}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-135af08{color:#212121}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-1760b6c{font-family:Roboto,sans-serif;color:#212121}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-dd7e280{font-size:16px}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-5235878{white-space:pre}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-c0065f4{margin:0px;padding-left:40px;list-style-position:outside;font-family:Roboto,sans-serif;font-size:16px}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-56c6b1d{color:#212121;margin:8px 0px;padding:0px}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-d252ed2{background:#ebebeb;border:0px;margin:16px 0px;color:#212121;font-family:Roboto,sans-serif;font-size:16px}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-0fe5cc9{padding:0px;font-weight:400;font-size:20px;line-height:32px;font-family:Roboto,sans-serif;margin:32px 0px 16px;color:#212121}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-ed23575{background:0px center;font-size:18px;line-height:1;font-family:"Roboto Mono",monospace;padding:0px}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-e061f80{margin:0px;padding-left:40px;list-style-position:outside;color:#212121;font-family:Roboto,sans-serif;font-size:16px}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-9fe1278{margin:8px 0px;padding:0px}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-0247e63{padding:0px;font-size:16px;line-height:24px;font-family:Roboto,sans-serif;margin:32px 0px 16px;color:#212121}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-15ae00d{margin-top:16px;margin-bottom:16px;padding-top:0px;padding-bottom:0px;color:#212121;font-family:Roboto,sans-serif;font-size:16px}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-fbce9f2{background:#f7f7f7;color:#37474f;font-size:14.4px;line-height:1;font-family:"Roboto Mono",monospace;padding:1px 4px}	</style>
</head>

<body class="">

<header id="top" class="amp-wp-header">
	<div>
		<a href="https://uzzz.org/">
										<amp-img src="https://uzzz.org/wp-content/uploads/2019/10/cropped-icon-32x32.png" width="32" height="32" class="amp-wp-site-icon"></amp-img>
						<span class="amp-site-title">
				有组织在!			</span>
		</a>

					</div>
</header>

<article class="amp-wp-article">
	<header class="amp-wp-article-header">
		<h1 class="amp-wp-title">TensorFlow从图像中提取区域</h1>
			<div class="amp-wp-meta amp-wp-byline">
					<amp-img src="https://secure.gravatar.com/avatar/e786821a74ef0467825a7d60183307bc?s=24&d=mm&r=g" alt="fandyvon" width="24" height="24" layout="fixed"></amp-img>
				<span class="amp-wp-author author vcard">fandyvon</span>
	</div>
<div class="amp-wp-meta amp-wp-posted-on">
	<time datetime="2018-06-14T14:45:01+00:00">
		2 years ago	</time>
</div>
	</header>

	
	<div class="amp-wp-article-content">
		<div id="article_content" class="article_content clearfix">
 <br>
 
 
 
<div class="htmledit_views" id="content_views">
<ol>
<li>tf.image.crop_to_bounding_box(image, offset_height, offset_width, target_height, target_width)</li>
<li>tf.image.extract_glimpse(input, size, offsets, centered=None, normalized=None, uniform_noise=None, name=None)</li>
<li><code><span class="pln">tf</span><span class="pun">.</span><span class="pln">extract_image_patches</span><span class="pun"></span></code>(<code><span class="pln">images</span><span class="pun">,</span><span class="pln"></span></code><code><span class="pln">ksizes</span><span class="pun">,</span><span class="pln"> </span></code><code><span class="pln">strides</span><span class="pun">,</span><span class="pln"></span></code><code><span class="pln">rates</span><span class="pun">,</span><span class="pln"></span></code><code></code><code><span class="pln">padding</span><span class="pun">,</span><span class="pln"></span></code><code><span class="pln">name</span><span class="pun">=</span><span class="kwd">None</span><span class="pln"></span></code><code></code>)</li>
<li>
<h6 class="amp-wp-0fe5cc9"><span class="amp-wp-9bd93d3"><code class="amp-wp-ed23575">tf.image.crop_and_resize(image, boxes, box_ind, crop_size, method=None, extrapolation_value=None, name=None)</code></span></h6>
</li>
</ol>
<p></p>
<h3 class="amp-wp-0fe5cc9"><code class="amp-wp-ed23575"></code><code class="amp-wp-ed23575">tf.image.crop_to_bounding_box(image, offset_height, offset_width, target_height, target_width)</code></h3>
<p class="amp-wp-15ae00d">Crops an image to a specified bounding box.</p>
<p class="amp-wp-15ae00d">This op cuts a rectangular part out of <code class="amp-wp-fbce9f2">image</code>. The top-left corner of the returned image is at <code class="amp-wp-fbce9f2">offset_height, offset_width</code> in <code class="amp-wp-fbce9f2">image</code>, and its lower-right corner is at <code class="amp-wp-fbce9f2">offset_height + target_height, offset_width + target_width</code>.</p>
<h5 class="amp-wp-0247e63">Args:</h5>
<ul class="amp-wp-e061f80">
<li class="amp-wp-9fe1278"><span><code class="amp-wp-fbce9f2">image</code></span>: 3-D tensor with shape <code class="amp-wp-fbce9f2">[height, width, channels]</code></li>
<li class="amp-wp-9fe1278"><span><code class="amp-wp-fbce9f2">offset_height</code></span>: Vertical coordinate of the top-left corner of the result in the input.</li>
<li class="amp-wp-9fe1278"><span><code class="amp-wp-fbce9f2">offset_width</code></span>: Horizontal coordinate of the top-left corner of the result in the input.</li>
<li class="amp-wp-9fe1278"><span><code class="amp-wp-fbce9f2">target_height</code></span>: Height of the result.</li>
<li class="amp-wp-9fe1278"><span><code class="amp-wp-fbce9f2">target_width</code></span>: Width of the result.</li>
</ul>
<h5 class="amp-wp-0247e63">Returns:</h5>
<p class="amp-wp-15ae00d">3-D tensor of image with shape <code class="amp-wp-fbce9f2">[target_height, target_width, channels]</code></p>
<h5 class="amp-wp-0247e63">Raises:</h5>
<ul class="amp-wp-e061f80">
<li class="amp-wp-9fe1278"><span><code class="amp-wp-fbce9f2">ValueError</code></span>: If the shape of <code class="amp-wp-fbce9f2">image</code> is incompatible with the <code class="amp-wp-fbce9f2">offset_*</code> or <code class="amp-wp-fbce9f2">target_*</code> arguments, or either <code class="amp-wp-fbce9f2">offset_height</code> or <code class="amp-wp-fbce9f2">offset_width</code> is negative, or either <code class="amp-wp-fbce9f2">target_height</code> or <code class="amp-wp-fbce9f2">target_width</code> is not positive.</li>
</ul>
<hr class="amp-wp-d252ed2">
<h3 class="amp-wp-0fe5cc9"><a></a><code class="amp-wp-ed23575">tf.image.extract_glimpse(input, size, offsets, centered=None, normalized=None, uniform_noise=None, name=None)</code></h3>
<p class="amp-wp-15ae00d">Extracts a glimpse from the input tensor.</p>
<p class="amp-wp-15ae00d">Returns a set of windows called glimpses extracted at location <code class="amp-wp-fbce9f2">offsets</code> from the input tensor. If the windows only partially overlaps the inputs, the non overlapping areas will be filled with random noise.</p>
<p class="amp-wp-15ae00d">The result is a 4-D tensor of shape <code class="amp-wp-fbce9f2">[batch_size, glimpse_height, glimpse_width, channels]</code>. The channels and batch dimensions are the same as that of the input tensor. The height and width of the output windows are specified in the <code class="amp-wp-fbce9f2">size</code> parameter.</p>
<p class="amp-wp-15ae00d">The argument <code class="amp-wp-fbce9f2">normalized</code> and <code class="amp-wp-fbce9f2">centered</code> controls how the windows are built:</p>
<ul class="amp-wp-e061f80">
<li class="amp-wp-9fe1278">If the coordinates are normalized but not centered, 0.0 and 1.0 correspond to the minimum and maximum of each height and width dimension.</li>
<li class="amp-wp-9fe1278">If the coordinates are both normalized and centered, they range from -1.0 to 1.0. The coordinates (-1.0, -1.0) correspond to the upper left corner, the lower right corner is located at (1.0, 1.0) and the center is at (0, 0).</li>
<li class="amp-wp-9fe1278">If the coordinates are not normalized they are interpreted as numbers of pixels.</li>
</ul>
<h5 class="amp-wp-0247e63">Args:</h5>
<ul class="amp-wp-c0065f4">
<li class="amp-wp-56c6b1d"><span><code class="amp-wp-fbce9f2">input</code></span>: A <code class="amp-wp-fbce9f2">Tensor</code> of type <code class="amp-wp-653ee8d">float32</code>. A 4-D float tensor of shape <code class="amp-wp-fbce9f2">[batch_size, height, width, channels]</code>.</li>
<li class="amp-wp-9fe1278"><span class="amp-wp-135af08"><span><code class="amp-wp-fbce9f2">size</code></span>: A <code class="amp-wp-fbce9f2">Tensor</code> of type <code class="amp-wp-2124342">int32</code>. A 1-D tensor of 2 elements containing the size of the glimpses to extract. The glimpse height must be specified first, following by the glimpse width.</span><span class="amp-wp-a80b77e">(H, W)</span></li>
<li class="amp-wp-9fe1278"><span class="amp-wp-135af08"><code class="amp-wp-fbce9f2">offsets</code></span><span class="amp-wp-135af08">: A </span><code class="amp-wp-953320a">Tensor</code><span class="amp-wp-135af08"> of type </span><code class="amp-wp-271d8a4"><strong class="amp-wp-6bcdf70">float32</strong></code><span class="amp-wp-135af08">. A 2-D integer tensor of shape </span><code class="amp-wp-953320a">[batch_size, 2]</code><span class="amp-wp-135af08"> containing the </span><span class="amp-wp-a80b77e">(y, x)</span><span class="amp-wp-135af08"> locations of the center of each window. </span></li>
</ul>
<div>
   <span class="amp-wp-1760b6c"><span class="amp-wp-dd7e280"><span class="amp-wp-5235878">`by using tf.reshape(offsets, [1, 2]) to get the needed shape</span></span></span>
  </div>
<ul class="amp-wp-c0065f4">
<li class="amp-wp-56c6b1d"><span><code class="amp-wp-fbce9f2">centered</code></span>: An optional <code class="amp-wp-fbce9f2">bool</code>. Defaults to <code class="amp-wp-fbce9f2">True</code>. indicates if the offset coordinates are centered relative to the image, in which case the (0, 0) offset is relative to the center of the input images. If false, the (0,0) offset corresponds to the upper left corner of the input images.</li>
<li class="amp-wp-56c6b1d"><span><code class="amp-wp-fbce9f2">normalized</code></span>: An optional <code class="amp-wp-fbce9f2">bool</code>. Defaults to <code class="amp-wp-fbce9f2">True</code>. indicates if the offset coordinates are normalized.</li>
<li class="amp-wp-56c6b1d"><span><code class="amp-wp-fbce9f2">uniform_noise</code></span>: An optional <code class="amp-wp-fbce9f2">bool</code>. Defaults to <code class="amp-wp-fbce9f2">True</code>. indicates if the noise should be generated using a uniform distribution or a gaussian distribution.</li>
<li class="amp-wp-56c6b1d"><span><code class="amp-wp-fbce9f2">name</code></span>: A name for the operation (optional).</li>
</ul>
<h5 class="amp-wp-0247e63">Returns:</h5>
<p class="amp-wp-15ae00d">A <code class="amp-wp-fbce9f2">Tensor</code> of type <code class="amp-wp-fbce9f2">float32</code>. A tensor representing the glimpses <code class="amp-wp-fbce9f2">[batch_size, glimpse_height, glimpse_width, channels]</code>.</p>
<p class="amp-wp-15ae00d"><code><span class="pln"><br></span></code></p>
<p class="amp-wp-15ae00d"><code><span class="pln">tf</span><span class="pun">.</span><span class="pln">extract_image_patches</span><span class="pun"></span></code>(<code><span class="pln">images</span><span class="pun">,</span><span class="pln"></span></code><code><span class="pln">ksizes</span><span class="pun">,</span><span class="pln"> </span></code><code><span class="pln">strides</span><span class="pun">,</span><span class="pln"></span></code><code><span class="pln">rates</span><span class="pun">,</span><span class="pln"></span></code><code></code><code><span class="pln">padding</span><span class="pun">,</span><span class="pln"></span></code><code><span class="pln">name</span><span class="pun">=</span><span class="kwd">None</span><span class="pln"></span></code><code></code>)</p>
<p class="amp-wp-15ae00d">
</p><p>Defined in <code>tensorflow/python/ops/gen_array_ops.py</code>.</p>
<p>See the guide: <a href="https://www.tensorflow.org/api_guides/python/array_ops#Slicing_and_Joining" rel="nofollow" data-token="0a0c1f965f3b314fc190586829ea31a9">Tensor Transformations > Slicing and Joining</a></p>
<p>Extract <code>patches</code> from <code>images</code> and put them in the “depth” output dimension.</p>
<h4>Args:</h4>
<ul>
<li><strong><code>images</code></strong>: A <code>Tensor</code>. Must be one of the following types: <code>float32</code>, <code>float64</code>, <code>int32</code>, <code>uint8</code>, <code>int16</code>, <code>int8</code>, <code>int64</code>, <code>bfloat16</code>, <code>uint16</code>, <code>half</code>, <code>uint32</code>, <code>uint64</code>.4-D Tensor with shape <code>[batch, in_rows, in_cols, depth]</code>.</li>
<li><strong><code>ksizes</code></strong>: A list of <code>ints</code> that has length <code>>= 4</code>.The size of the sliding window for each dimension of <code>images</code>.</li>
<li><strong><code>strides</code></strong>: A list of <code>ints</code> that has length <code>>= 4</code>.1-D of length 4. How far the centers of two consecutive patches are inthe images. Must be: <code>[1, stride_rows, stride_cols, 1]</code>.</li>
<li><strong><code>rates</code></strong>: A list of <code>ints</code> that has length <code>>= 4</code>.1-D of length 4. Must be: <code>[1, rate_rows, rate_cols, 1]</code>. This is theinput stride, specifying how far two consecutive patch samples are in theinput. Equivalent to extracting patches with<code>patch_sizes_eff = patch_sizes + (patch_sizes - 1) * (rates - 1)</code>, followed bysubsampling them spatially by a factor of <code>rates</code>. This is equivalent to<code>rate</code> in dilated (a.k.a. Atrous) convolutions.</li>
<li>
<p><strong><code>padding</code></strong>: A <code>string</code> from: <code>"SAME", "VALID"</code>.The type of padding algorithm to use.</p>
<p>We specify the size-related attributes as:</p>
<pre><code class="language-python"><code><span class="pln">      ksizes </span><span class="pun">=</span><span class="pln"> </span><span class="pun">[</span><span class="lit">1</span><span class="pun">,</span><span class="pln"> ksize_rows</span><span class="pun">,</span><span class="pln"> ksize_cols</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">]</span><span class="pln">       strides </span><span class="pun">=</span><span class="pln"> </span><span class="pun">[</span><span class="lit">1</span><span class="pun">,</span><span class="pln"> strides_rows</span><span class="pun">,</span><span class="pln"> strides_cols</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">]</span><span class="pln">       rates </span><span class="pun">=</span><span class="pln"> </span><span class="pun">[</span><span class="lit">1</span><span class="pun">,</span><span class="pln"> rates_rows</span><span class="pun">,</span><span class="pln"> rates_cols</span><span class="pun">,</span><span class="pln"> </span><span class="lit">1</span><span class="pun">]</span><span class="pln"> </span></code></code></pre>
</li>
<li>
<p><strong><code>name</code></strong>: A name for the operation (optional).</p>
</li>
</ul>
<h4>Returns:</h4>
<p>A <code>Tensor</code>. Has the same type as <code>images</code>.</p>
<p></p>
<hr class="amp-wp-d252ed2">
<h3 class="amp-wp-0fe5cc9"><a></a><code class="amp-wp-ed23575">tf.image.crop_and_resize(image, boxes, box_ind, crop_size, method=None, extrapolation_value=None, name=None)</code></h3>
<p class="amp-wp-15ae00d">Extracts crops from the input image tensor and bilinearly resizes them (possibly</p>
<p class="amp-wp-15ae00d">with aspect ratio change) to a common output size specified by <code class="amp-wp-fbce9f2">crop_size</code>. This is more general than the <code class="amp-wp-fbce9f2">crop_to_bounding_box</code> op which extracts a fixed size slice from the input image and does not allow resizing or aspect ratio change.</p>
<p class="amp-wp-15ae00d">Returns a tensor with <code class="amp-wp-fbce9f2">crops</code> from the input <code class="amp-wp-fbce9f2">image</code> at positions defined at the bounding box locations in <code class="amp-wp-fbce9f2">boxes</code>. The cropped boxes are all resized (with bilinear interpolation) to a fixed <code class="amp-wp-fbce9f2">size = [crop_height, crop_width]</code>. The result is a 4-D tensor <code class="amp-wp-fbce9f2">[num_boxes, crop_height, crop_width, depth]</code>.</p>
<h5 class="amp-wp-0247e63">Args:</h5>
<ul class="amp-wp-e061f80">
<li class="amp-wp-9fe1278"><span><code class="amp-wp-fbce9f2">image</code></span>: A <code class="amp-wp-fbce9f2">Tensor</code>. Must be one of the following types: <code class="amp-wp-fbce9f2">uint8</code>, <code class="amp-wp-fbce9f2">int8</code>, <code class="amp-wp-fbce9f2">int16</code>, <code class="amp-wp-fbce9f2">int32</code>, <code class="amp-wp-fbce9f2">int64</code>, <code class="amp-wp-fbce9f2">half</code>, <code class="amp-wp-fbce9f2">float32</code>, <code class="amp-wp-fbce9f2">float64</code>. A 4-D tensor of shape <code class="amp-wp-fbce9f2">[batch, image_height, image_width, depth]</code>. Both <code class="amp-wp-fbce9f2">image_height</code> and <code class="amp-wp-fbce9f2">image_width</code> need to be positive.</li>
<li class="amp-wp-9fe1278"><span><code class="amp-wp-fbce9f2">boxes</code></span>: A <code class="amp-wp-fbce9f2">Tensor</code> of type <code class="amp-wp-fbce9f2">float32</code>. A 2-D tensor of shape <code class="amp-wp-fbce9f2">[num_boxes, 4]</code>. The <code class="amp-wp-fbce9f2">i</code>-th row of the tensor specifies the coordinates of a box in the <code class="amp-wp-fbce9f2">box_ind[i]</code> image and is specified in normalized coordinates <code class="amp-wp-fbce9f2">[y1, x1, y2, x2]</code>. A normalized coordinate value of <code class="amp-wp-fbce9f2">y</code> is mapped to the image coordinate at <code class="amp-wp-fbce9f2">y * (image_height - 1)</code>, so as the<code class="amp-wp-fbce9f2">[0, 1]</code> interval of normalized image height is mapped to <code class="amp-wp-fbce9f2">[0, image_height - 1] in image height coordinates. We do allow y1 > y2, in which case the sampled crop is an up-down flipped version of the original image. The width dimension is treated similarly. Normalized coordinates outside the</code>[0, 1]<code class="amp-wp-fbce9f2">range are allowed, in which case we use</code>extrapolation_value` to extrapolate the input image values.</li>
<li class="amp-wp-9fe1278"><span><code class="amp-wp-fbce9f2">box_ind</code></span>: A <code class="amp-wp-fbce9f2">Tensor</code> of type <code class="amp-wp-fbce9f2">int32</code>. A 1-D tensor of shape <code class="amp-wp-fbce9f2">[num_boxes]</code> with int32 values in <code class="amp-wp-fbce9f2">[0, batch)</code>. The value of <code class="amp-wp-fbce9f2">box_ind[i]</code> specifies the image that the <code class="amp-wp-fbce9f2">i</code>-th box refers to.</li>
<li class="amp-wp-9fe1278"><span><code class="amp-wp-fbce9f2">crop_size</code></span>: A <code class="amp-wp-fbce9f2">Tensor</code> of type <code class="amp-wp-fbce9f2">int32</code>. A 1-D tensor of 2 elements, <code class="amp-wp-fbce9f2">size = [crop_height, crop_width]</code>. All cropped image patches are resized to this size. The aspect ratio of the image content is not preserved. Both <code class="amp-wp-fbce9f2">crop_height</code> and <code class="amp-wp-fbce9f2">crop_width</code> need to be positive.</li>
<li class="amp-wp-9fe1278"><span><code class="amp-wp-fbce9f2">method</code></span>: An optional <code class="amp-wp-fbce9f2">string</code> from: <code class="amp-wp-fbce9f2">"bilinear"</code>. Defaults to <code class="amp-wp-fbce9f2">"bilinear"</code>. A string specifying the interpolation method. Only ‘bilinear’ is supported for now.</li>
<li class="amp-wp-9fe1278"><span><code class="amp-wp-fbce9f2">extrapolation_value</code></span>: An optional <code class="amp-wp-fbce9f2">float</code>. Defaults to <code class="amp-wp-fbce9f2">0</code>. Value used for extrapolation, when applicable.</li>
<li class="amp-wp-9fe1278"><span><code class="amp-wp-fbce9f2">name</code></span>: A name for the operation (optional).</li>
</ul>
<h5 class="amp-wp-0247e63">Returns:</h5>
<p class="amp-wp-15ae00d">A <code class="amp-wp-fbce9f2">Tensor</code> of type <code class="amp-wp-fbce9f2">float32</code>. A 4-D tensor of shape <code class="amp-wp-fbce9f2">[num_boxes, crop_height, crop_width, depth]</code>.</p>
</div>
</div>
	</div>

	<footer class="amp-wp-article-footer">
			<div class="amp-wp-meta amp-wp-tax-category">
		Categories: Uncategorized	</div>

	</footer>
</article>

<footer class="amp-wp-footer">
	<div>
		<h2>有组织在!</h2>
		<a href="#top" class="back-to-top">Back to top</a>
	</div>
</footer>



</body>
</html>
