<!DOCTYPE html>
<html amp lang="en-US">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1">
	<script type="application/ld+json" class="yoast-schema-graph yoast-schema-graph--main">{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://uzzz.org/#website","url":"https://uzzz.org/","name":"\u6709\u7ec4\u7ec7\u5728!","potentialAction":{"@type":"SearchAction","target":"https://uzzz.org/?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"ImageObject","@id":"https://uzzz.org/article/2672/#primaryimage","url":"https://uzshare.com/_p?https://img-blog.csdn.net/20180709201827973?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"},{"@type":"WebPage","@id":"https://uzzz.org/article/2672/#webpage","url":"https://uzzz.org/article/2672/","inLanguage":"en-US","name":"2017CS231n\u674e\u98de\u98de\u6df1\u5ea6\u89c6\u89c9\u8bc6\u522b\u7b14\u8bb0\uff08\u4e00\uff09\u2014\u2014\u8ba1\u7b97\u673a\u89c6\u89c9\u6982\u8ff0\u548c\u5386\u53f2\u80cc\u666f - \u6709\u7ec4\u7ec7\u5728!","isPartOf":{"@id":"https://uzzz.org/#website"},"primaryImageOfPage":{"@id":"https://uzzz.org/article/2672/#primaryimage"},"datePublished":"2018-07-09T12:26:35+00:00","dateModified":"2018-07-09T12:26:35+00:00","author":{"@id":"https://uzzz.org/#/schema/person/29673f1347b0abda5882803c72ee5a3f"}},{"@type":["Person"],"@id":"https://uzzz.org/#/schema/person/29673f1347b0abda5882803c72ee5a3f","name":"fandyvon","sameAs":[]}]}</script>
	<title>2017CS231n李飞飞深度视觉识别笔记（一）——计算机视觉概述和历史背景 - 有组织在!</title>
		<link rel="canonical" href="https://uzzz.org/article/2672/">
	<script type="text/javascript" src="https://cdn.ampproject.org/v0.js" async></script>
<style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>
	<style amp-custom>
		/* Generic WP styling */

.alignright {
	float: right;
}

.alignleft {
	float: left;
}

.aligncenter {
	display: block;
	text-align: center;
	margin-left: auto;
	margin-right: auto;
}

.amp-wp-enforced-sizes {
	/** Our sizes fallback is 100vw, and we have a padding on the container; the max-width here prevents the element from overflowing. **/
	max-width: 100%;
	margin: 0 auto;
}


/*
 * Prevent cases of amp-img converted from img to appear with stretching by using object-fit to scale.
 * See <https://github.com/ampproject/amphtml/issues/21371#issuecomment-475443219>.
 * Also use object-fit:contain in worst case scenario when we can't figure out dimensions for an image.
 * Additionally, in side of \AMP_Img_Sanitizer::determine_dimensions() it could $amp_img->setAttribute( 'object-fit', 'contain' )
 * so that the following rules wouldn't be needed.
 */
amp-img.amp-wp-enforced-sizes[layout="intrinsic"] > img,
amp-anim.amp-wp-enforced-sizes[layout="intrinsic"] > img {
	object-fit: contain;
}

amp-fit-text blockquote,
amp-fit-text h1,
amp-fit-text h2,
amp-fit-text h3,
amp-fit-text h4,
amp-fit-text h5,
amp-fit-text h6 {
	font-size: inherit;
}

/**
 * Override a style rule in Twenty Sixteen and Twenty Seventeen.
 * It set display:none for audio elements.
 * This selector is the same, though it adds body and uses amp-audio instead of audio.
 */
body amp-audio:not([controls]) {
	display: inline-block;
	height: auto;
}

/*
 * Style the default template messages for submit-success, submit-error, and submitting. These elements are inserted
 * by the form sanitizer when a POST form lacks the action-xhr attribute.
 */
.amp-wp-default-form-message > p {
	margin: 1em 0;
	padding: 0.5em;
}

.amp-wp-default-form-message[submitting] > p,
.amp-wp-default-form-message[submit-success] > p.amp-wp-form-redirecting {
	font-style: italic;
}

.amp-wp-default-form-message[submit-success] > p:not(.amp-wp-form-redirecting) {
	border: solid 1px #008000;
	background-color: #90ee90;
	color: #000;
}

.amp-wp-default-form-message[submit-error] > p {
	border: solid 1px #f00;
	background-color: #ffb6c1;
	color: #000;
}

/* Prevent showing empty success message in the case of an AMP-Redirect-To response header. */
.amp-wp-default-form-message[submit-success] > p:empty {
	display: none;
}

amp-carousel .amp-wp-gallery-caption {
	position: absolute;
	bottom: 0;
	left: 0;
	right: 0;
	text-align: center;
	background-color: rgba(0, 0, 0, 0.5);
	color: #fff;
	padding: 1rem;
}

.wp-block-gallery[data-amp-carousel="true"] {
	display: block;
	flex-wrap: unset;
}

/* Template Styles */

.amp-wp-content,
.amp-wp-title-bar div {
		margin: 0 auto;
	max-width: 840px;
	}

html {
	background: #0a89c0;
}

body {
	background: #fff;
	color: #353535;
	font-family: Georgia, 'Times New Roman', Times, Serif;
	font-weight: 300;
	line-height: 1.75em;
}

p,
ol,
ul,
figure {
	margin: 0 0 1em;
	padding: 0;
}

a,
a:visited {
	color: #0a89c0;
}

a:hover,
a:active,
a:focus {
	color: #353535;
}

/* Quotes */

blockquote {
	color: #353535;
	background: rgba(127,127,127,.125);
	border-left: 2px solid #0a89c0;
	margin: 8px 0 24px 0;
	padding: 16px;
}

blockquote p:last-child {
	margin-bottom: 0;
}

/* UI Fonts */

.amp-wp-meta,
.amp-wp-header div,
.amp-wp-title,
.wp-caption-text,
.amp-wp-tax-category,
.amp-wp-tax-tag,
.amp-wp-comments-link,
.amp-wp-footer p,
.back-to-top {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen-Sans", "Ubuntu", "Cantarell", "Helvetica Neue", sans-serif;
}

/* Header */

.amp-wp-header {
	background-color: #0a89c0;
}

.amp-wp-header div {
	color: #fff;
	font-size: 1em;
	font-weight: 400;
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: .875em 16px;
	position: relative;
}

.amp-wp-header a {
	color: #fff;
	text-decoration: none;
}


.amp-wp-header .amp-wp-site-icon {
	/** site icon is 32px **/
	background-color: #fff;
	border: 1px solid #fff;
	border-radius: 50%;
	position: absolute;
	right: 18px;
	top: 10px;
}

/* Article */

.amp-wp-article {
	color: #353535;
	font-weight: 400;
	margin: 1.5em auto;
	max-width: 840px;
	overflow-wrap: break-word;
	word-wrap: break-word;
}

/* Article Header */

.amp-wp-article-header {
	align-items: center;
	align-content: stretch;
	display: flex;
	flex-wrap: wrap;
	justify-content: space-between;
	margin: 1.5em 16px 0;
}

.amp-wp-title {
	color: #353535;
	display: block;
	flex: 1 0 100%;
	font-weight: 900;
	margin: 0 0 .625em;
	width: 100%;
}

/* Article Meta */

.amp-wp-meta {
	color: #696969;
	display: inline-block;
	flex: 2 1 50%;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0 0 1.5em;
	padding: 0;
}

.amp-wp-article-header .amp-wp-meta:last-of-type {
	text-align: right;
}

.amp-wp-article-header .amp-wp-meta:first-of-type {
	text-align: left;
}

.amp-wp-byline amp-img,
.amp-wp-byline .amp-wp-author {
	display: inline-block;
	vertical-align: middle;
}

.amp-wp-byline amp-img {
	border: 1px solid #0a89c0;
	border-radius: 50%;
	position: relative;
	margin-right: 6px;
}

.amp-wp-posted-on {
	text-align: right;
}

/* Featured image */

.amp-wp-article-featured-image {
	margin: 0 0 1em;
}
.amp-wp-article-featured-image amp-img {
	margin: 0 auto;
}
.amp-wp-article-featured-image.wp-caption .wp-caption-text {
	margin: 0 18px;
}

/* Article Content */

.amp-wp-article-content {
	margin: 0 16px;
}

.amp-wp-article-content ul,
.amp-wp-article-content ol {
	margin-left: 1em;
}

.amp-wp-article-content .wp-caption {
	max-width: 100%;
}

.amp-wp-article-content amp-img {
	margin: 0 auto;
}

.amp-wp-article-content amp-img.alignright {
	margin: 0 0 1em 16px;
}

.amp-wp-article-content amp-img.alignleft {
	margin: 0 16px 1em 0;
}

/* Captions */

.wp-caption {
	padding: 0;
}

.wp-caption.alignleft {
	margin-right: 16px;
}

.wp-caption.alignright {
	margin-left: 16px;
}

.wp-caption .wp-caption-text {
	border-bottom: 1px solid #c2c2c2;
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0;
	padding: .66em 10px .75em;
}

/* AMP Media */

.alignwide,
.alignfull {
	clear: both;
}

amp-carousel {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}
amp-iframe,
amp-youtube,
amp-instagram,
amp-vine {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}

.amp-wp-article-content amp-carousel amp-img {
	border: none;
}

amp-carousel > amp-img > img {
	object-fit: contain;
}

.amp-wp-iframe-placeholder {
	background: #c2c2c2 url( https://uzzz.org/wp-content/plugins/amp/assets/images/placeholder-icon.png ) no-repeat center 40%;
	background-size: 48px 48px;
	min-height: 48px;
}

/* Article Footer Meta */

.amp-wp-article-footer .amp-wp-meta {
	display: block;
}

.amp-wp-tax-category,
.amp-wp-tax-tag {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 1.5em 16px;
}

.amp-wp-comments-link {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	text-align: center;
	margin: 2.25em 0 1.5em;
}

.amp-wp-comments-link a {
	border-style: solid;
	border-color: #c2c2c2;
	border-width: 1px 1px 2px;
	border-radius: 4px;
	background-color: transparent;
	color: #0a89c0;
	cursor: pointer;
	display: block;
	font-size: 14px;
	font-weight: 600;
	line-height: 18px;
	margin: 0 auto;
	max-width: 200px;
	padding: 11px 16px;
	text-decoration: none;
	width: 50%;
	-webkit-transition: background-color 0.2s ease;
			transition: background-color 0.2s ease;
}

/* AMP Footer */

.amp-wp-footer {
	border-top: 1px solid #c2c2c2;
	margin: calc(1.5em - 1px) 0 0;
}

.amp-wp-footer div {
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: 1.25em 16px 1.25em;
	position: relative;
}

.amp-wp-footer h2 {
	font-size: 1em;
	line-height: 1.375em;
	margin: 0 0 .5em;
}

.amp-wp-footer p {
	color: #696969;
	font-size: .8em;
	line-height: 1.5em;
	margin: 0 85px 0 0;
}

.amp-wp-footer a {
	text-decoration: none;
}

.back-to-top {
	bottom: 1.275em;
	font-size: .8em;
	font-weight: 600;
	line-height: 2em;
	position: absolute;
	right: 16px;
}
		/* Inline stylesheets */
:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-e215155{font-size:18px}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-9456def{color:#000}	</style>
</head>

<body class="">

<header id="top" class="amp-wp-header">
	<div>
		<a href="https://uzzz.org/">
										<amp-img src="https://uzzz.org/wp-content/uploads/2019/10/cropped-icon-32x32.png" width="32" height="32" class="amp-wp-site-icon"></amp-img>
						<span class="amp-site-title">
				有组织在!			</span>
		</a>

					</div>
</header>

<article class="amp-wp-article">
	<header class="amp-wp-article-header">
		<h1 class="amp-wp-title">2017CS231n李飞飞深度视觉识别笔记（一）——计算机视觉概述和历史背景</h1>
			<div class="amp-wp-meta amp-wp-byline">
					<amp-img src="https://secure.gravatar.com/avatar/e786821a74ef0467825a7d60183307bc?s=24&d=mm&r=g" alt="fandyvon" width="24" height="24" layout="fixed"></amp-img>
				<span class="amp-wp-author author vcard">fandyvon</span>
	</div>
<div class="amp-wp-meta amp-wp-posted-on">
	<time datetime="2018-07-09T20:26:35+00:00">
		2 years ago	</time>
</div>
	</header>

	
	<div class="amp-wp-article-content">
		<div id="article_content" class="article_content clearfix">
 <br>
 
 
 
<div class="htmledit_views" id="content_views">
<p><strong><span class="amp-wp-9456def"><span class="amp-wp-e215155">第一章 计算机视觉概述和历史背景</span></span></strong></p>
<p><strong><span class="amp-wp-9456def">课时1 计算机视觉概述</span></strong></p>
<p><span class="amp-wp-9456def">    计算机视觉：针对视觉数据的研究。</span></p>
<p><span class="amp-wp-9456def">    关键是如何用算法来开发可以利用和理解的数据，视觉数据存在的问题是它们很难理解，有时把视觉数据称为“互联网的暗物质”，它们构成了网络上传输的大部分数据。</span></p>
<p><span class="amp-wp-9456def">    根据YouTube的一个统计实例：大概每秒钟，有长达5小时的数据内容会被上传到YouTube，所以通过人工给每个视频标上注释、分类是非常困难甚至不可能的，计算机视觉是解决这种问题的重要技术，它能够对照片进行标签、分类，处理视频的每一帧。</span></p>
<p><span class="amp-wp-9456def">    计算机视觉是一个与很多领域紧密关联的学科，它涉及到比如说工程、物理、生物等许多不同的领域：</span></p>
<p align="center"><amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201827973?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="415" height="263" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201827973?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="415" height="263" class=""></noscript></amp-img></p>
<p><span class="amp-wp-9456def">    对于CS231n这么课程，它专注于一类特定的算法，围绕神经网络，特别是卷积神经网络，并将其应用于各种视觉识别任务。</span></p>
<p><strong><span class="amp-wp-9456def"> </span></strong></p>
<p><strong><span class="amp-wp-9456def">课时2 计算机视觉历史背景</span></strong></p>
<p><span class="amp-wp-9456def">    视觉的历史可以追溯到很久以前，动物拥有视觉的开端：</span></p>
<p align="center"><amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201848797?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="359" height="252" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201848797?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="359" height="252" class=""></noscript></amp-img></p>
<p><span class="amp-wp-9456def">    如今，视觉成为了最重要的感知系统，人类的大脑皮层中有几乎一半的神经元与视觉有关，这项最重要的感知系统可以使人们生存、工作、运动等等，视觉对人们真的至关重要。</span></p>
<p><span class="amp-wp-9456def">    以上谈到了人类的视觉，那么人类让计算机获得视觉的历史又是怎么样的呢？</span></p>
<p align="center"><amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201854715?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="350" height="249" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201854715?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="350" height="249" class=""></noscript></amp-img></p>
<p><span class="amp-wp-9456def">    现在知道的最早的相机追溯到17世纪文艺复兴时期的暗箱，这是一种通过小孔成像的相机，这和动物早期的眼睛非常相似，通过小孔接收光线，后面的平板手机信息并且投影成像。</span></p>
<p><span class="amp-wp-9456def">    同时，生物学家开始研究视觉的机理，最具影响力并且启发了计算机视觉的一项研究是在五六十年代，休伯尔和威泽尔使用电生理学的研究，他们提出了“哺乳动物的视觉处理机制是怎样的”，通过观察何种刺激会引起视觉皮层神经的激烈反应，他们发现猫的大脑的初级视觉皮层有各种各样的细胞，其中最重要的是当它们朝着某个特定方向运动时，对面向边缘产生回应的细胞。</span></p>
<p align="center"><amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201902678?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="332" height="234" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201902678?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="332" height="234" class=""></noscript></amp-img></p>
<p><span class="amp-wp-9456def">    他们发现视觉处理是始于视觉世界的简单结构，面向边缘，沿着视觉处理的途径的移动信息也在变化，大脑建立了复杂的视觉信息，直到它可以识别更为复杂的视觉世界。</span></p>
<p><span class="amp-wp-9456def">    计算机视觉的历史是从60年代开始，从Larry Roberts的计算机视觉的第一篇博士论文开始。</span></p>
<p><span class="amp-wp-9456def">    1966年，一个如今非常著名的MIT暑期项目“Summer Vision Project”，它试图有效的使用暑期工作时间来构建视觉系统的重要组成部分，五十年来，计算机视觉领域已经从哪个夏季项目发展成为全球数千名研究人员的领域，并且仍然处理一些最根本的问题，这个领域已经成长为人工智能领域最重要和发展最快的领域之一。</span></p>
<p><span class="amp-wp-9456def">    70年代后期David Marr撰写的一本非常有影响力的书，内容包括了他是如何理解计算机视觉和应该如何开发可以使计算机识别世界的算法，他指出了为了拍摄一幅图像并获得视觉世界的最终全面3D表现必须经历的几个过程，如下图所示：</span></p>
<p align="center"><amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201912570?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="335" height="225" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201912570?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="335" height="225" class=""></noscript></amp-img></p>
<p><span class="amp-wp-9456def">    这是一个非常理想化的思想过程，也是一个非常直观化的方式并考虑如何解构视觉信息。</span></p>
<p><span class="amp-wp-9456def">    70年代另一个重要的开创性问题：如何越过简单的块状世界并开始识别或表示现实世界的对象？</span></p>
<p align="center"><amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201921962?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="296" height="216" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201921962?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="296" height="216" class=""></noscript></amp-img></p>
<p><span class="amp-wp-9456def">    一个被称为“广义圆柱体”，一个被称为“图形结构”，他们的基本思想是每个对象都是由简单的几何图形单位组成，所以任何一种表示方法是将物体的复杂结构简约成一个集合体。</span></p>
<p><span class="amp-wp-9456def">    80年代David lowe思考的如何重建或识别由简单的物体结构组成的视觉空间，它尝试识别剃须刀，通过线和边缘进行构建，其中大部分是直线之间的组合。</span></p>
<p><span class="amp-wp-9456def">    从60年代到80年代，考虑的问题是计算机视觉的任务是什么，要解决物体识别的问题非常难。所以，当思考解决视觉问题过程中出现的问题时，另一个重要的问题产生：如果识别目标太难，首先要做的是目标分割。</span></p>
<p><span class="amp-wp-9456def">    这个任务就是把一张图片中的像素点归类到有意义的区域，可能不知道这些像素点组合到一起是一个人形，但可以把属于人的像素点从背景中抠出来，这个过程就叫作图像分割。</span></p>
<p><span class="amp-wp-9456def">    下面是Malik和Jianbo shi完成的用一个算法对图像进行分割：</span></p>
<p align="center"><amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201932661?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="347" height="230" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201932661?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="347" height="230" class=""></noscript></amp-img></p>
<p><span class="amp-wp-9456def">    还有一个重要的研究是由Paul Viola和Michael Jones完成的，使用AdaBoost算法进行实时面部检测，在这个研究后不久推出了第一个能在数码相机中实现实时面部检测的数码相机，所以这是从基础科学研究到实际应用的一个快速转化。</span></p>
<p><span class="amp-wp-9456def">    关于如何做到更好的目标识别，是可以继续研究的领域，，所以在90年代末和21世纪的前几年，一个重要的思想方法就是基于特征的目标识别。由David Lowe完成的叫做SIFT特征，思路是匹配整个目标。</span></p>
<p align="center"><amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201941468?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="360" height="178" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201941468?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="360" height="178" class=""></noscript></amp-img></p>
<p><span class="amp-wp-9456def">    通过观察目标的某些部分、某些特征，它们往往能够在变化中具有表现性和不变性，所以目标识别的首要任务是在目标上确认这些关键的特征，然后把这些特征与相似的目标进行匹配，它比匹配整个目标要容易的多。例如，上图中一个stop标识中的SIFT特征与另一个stop标识中的SIFT特征相匹配。</span></p>
<p><span class="amp-wp-9456def">    有些工作是把这些特征放在一起以后，研究如何在实际图片中比较合理地设计人体姿态和辨认人体姿态，这方面一个工作被称为“方向梯度直方图”，另一个被称为“可变部件模型”。</span></p>
<p align="center"><amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201949391?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="347" height="224" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201949391?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="347" height="224" class=""></noscript></amp-img></p>
<p><span class="amp-wp-9456def">    所以，从60年代、70年代、80年代一直到21世纪，图片的质量随着互联网的发展，计算机视觉领域也能拥有更好的数据了，直到21世纪早期，才开始真正拥有标注的数据集能够衡量在目标识别方面取得的成果，其实一个最著名的数据集叫做PASCAL Visual Challenge。</span></p>
<p align="center"><amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201955857?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="312" height="177" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201955857?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="312" height="177" class=""></noscript></amp-img></p>
<p><span class="amp-wp-9456def">    与此同时，提出了一个重要的问题：是否具备了识别真是世界中的每一个物体的能力或者说大部分物体。这个问题也是由机器学习中的一个现象驱动：大部分的机器学习算法，无论是图模型还是SVM、AdaBoost都可能会在训练过程中过拟合。因此，有这两方面的动力，一是单纯想识别自然界中的万物，二是要回归机器学习克服瓶颈—过拟合问题，开始开展了一个ImageNet的项目，汇集所有能找到的图片，组建一个尽可能大的数据集。</span></p>
<p align="center"><amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709202003416?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="333" height="207" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709202003416?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="333" height="207" class=""></noscript></amp-img></p>
<p><span class="amp-wp-9456def">    这是当时AI领域最大的数据集，将目标检测算法的发展推到了一个新的高度，尤其重要的是如何推动基准测试的进展。</span></p>
<p><span class="amp-wp-9456def">    下面是ImageNet挑战赛的从2010到2015的图像分类结果：</span></p>
<p align="center"><amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709202009561?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="348" height="166" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709202009561?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="348" height="166" class=""></noscript></amp-img></p>
<p><span class="amp-wp-9456def">    横轴表示年份，纵轴表示比赛结果的错误率，可以看到错误率正在稳步下降。可以看到图中2012的错误率下降的非常显著，这一年的算法是一种卷积神经网络模型，这也将是这门课程学习的重点，深入研究什么是卷积神经网络模型，也就是现在被熟知的深度学习。</span></p>
<p><span class="amp-wp-9456def"> </span></p>
<p><strong><span class="amp-wp-9456def">课时3 CS321n课程概述</span></strong></p>
<p><span class="amp-wp-9456def">    CS321n将聚焦于视觉识别问题，第一个主要问题就是图像分类问题：让算法接收一张图作为输入，从固定的类别集合中选出该图像所属的类别。这个基本的分类器在很多地方都有不同的应用。</span></p>
<p><span class="amp-wp-9456def">    在CS231n课程中，将讨论一些其他的视觉识别问题，它们都建立在专门为图像分类而开发的各种工具之上，一些和图像分类的问题，比如目标检测或图像摘要生成。</span></p>
<p><span class="amp-wp-9456def">    图像分类关注的是大图整体，目标检测则告诉你物体具体出现在图片的哪个位置以及物体之间的联系是什么，图像摘要是当给到一幅图像，需要生成一段句子来描述这幅图像。</span></p>
<p align="center"><amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709202023289?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="318" height="219" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709202023289?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="318" height="219" class=""></noscript></amp-img></p>
<p><span class="amp-wp-9456def">   CNN，卷积神经网络只是深度学习架构的一种，但是它的成功是压倒性的，成为了目标识别的重要工具。回到ImageNet挑战赛中，2012年Krizhevsky和他的导师提出了卷积神经网络，并夺得了冠军；而在这之前，一直都是特征+支持向量机的结构，一种分层结构；而在这之后，获得冠军的算法都是卷积神经网络。</span></p>
<p align="center"><amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709202104412?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="316" height="188" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709202104412?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="316" height="188" class=""></noscript></amp-img></p>
<p><span class="amp-wp-9456def">    然而，卷积神经网络并不是一夜之间就成功的，事实上，这些算法可以追溯到更早的时候，与卷积神经网络有关的其中一项基础性工作是由Yann LeCun和他的伙伴于90年代完成的，1998年他们利用卷积神经网络进行数字识别。</span></p>
<p align="center"><amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709202111782?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="319" height="227" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709202111782?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="319" height="227" class=""></noscript></amp-img></p>
<p><span class="amp-wp-9456def">    所有既然这些算法在90年代就很突出，为什么到最近几年才变得这么流行呢？从数学的角度来说，有很重要的两点引起了深度学习架构的复兴，一个是摩尔定律，计算能力在变得越来越高；另一个是数据，算法需要大量的数据，需要给它们提供非常多的带标签的图像和像素，以便能最终取得更好的效果，有了大数据集，可以实现更强大的模型。</span></p>
<p><span class="amp-wp-9456def">    在计算机视觉领域，正尝试着制造一个拥有和人类一样视觉能力的机器，这样可以利用这些视觉系统可以实现很多惊奇的事情，但是当继续在该领域深入的时候，仍然有着大量的挑战和问题亟待解决，比如对整个照片进行密集标记、感知分组、使能够确定每个像素点的归属，这些仍是研究中的问题，所以需要持续不断地改进算法，从而做到更好。</span></p>
<p><span class="amp-wp-9456def">    与简单的“在物体上贴标签”比起来，我们往往希望深入地理解图片中的人们在做什么、各个物体之间的关系是什么，于是我们开始探究物体之间的联系，这是一个被称为视觉基因组的项目。</span></p>
<p align="center"><amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709202122653?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="358" height="227" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709202122653?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="358" height="227" class=""></noscript></amp-img></p>
<p><span class="amp-wp-9456def">    计算机视觉领域的一个愿景即是“看图说故事”，人类的生物视觉系统是非常强大的，看到一张图片，就能够描述图片的内容，并且只需不到一秒种的时间，如果能够让计算机也能做的同样的事情，那毋庸置疑是一项重大的突破；如果要实现真实深刻的图像理解，如今的计算机视觉算法仍然有很长的路要走。</span></p>
<p><span class="amp-wp-9456def">    计算机视觉能让世界变得更加美好，它还可以被应用到类似医学诊断、自动驾驶、机器人或者和这些完全版不同的领域。</span></p>
<p><span class="amp-wp-9456def"> </span></p>
</div>
</div>
	</div>

	<footer class="amp-wp-article-footer">
			<div class="amp-wp-meta amp-wp-tax-category">
		Categories: <a href="https://uzzz.org/category/jiqixuexi/" rel="category tag">机器学习</a>, <a href="https://uzzz.org/category/jisuanji/" rel="category tag">计算机</a>	</div>

	</footer>
</article>

<footer class="amp-wp-footer">
	<div>
		<h2>有组织在!</h2>
		<a href="#top" class="back-to-top">Back to top</a>
	</div>
</footer>



</body>
</html>
