<!DOCTYPE html>
<html amp lang="en-US">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1">
	<script type="application/ld+json" class="yoast-schema-graph yoast-schema-graph--main">{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://uzzz.org/#website","url":"https://uzzz.org/","name":"\u6709\u7ec4\u7ec7\u5728!","potentialAction":{"@type":"SearchAction","target":"https://uzzz.org/?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"ImageObject","@id":"https://uzzz.org/article/3037/#primaryimage","url":"https://uzshare.com/_p?https://img-blog.csdn.net/20180611155233733?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2Mzg3Njgz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"},{"@type":"WebPage","@id":"https://uzzz.org/article/3037/#webpage","url":"https://uzzz.org/article/3037/","inLanguage":"en-US","name":"DL\u5b66\u4e60\u7b14\u8bb0-\u56fe\u50cf\u9884\u5904\u7406 - \u6709\u7ec4\u7ec7\u5728!","isPartOf":{"@id":"https://uzzz.org/#website"},"primaryImageOfPage":{"@id":"https://uzzz.org/article/3037/#primaryimage"},"datePublished":"2018-06-11T08:43:58+00:00","dateModified":"2018-06-11T08:43:58+00:00","author":{"@id":"https://uzzz.org/#/schema/person/29673f1347b0abda5882803c72ee5a3f"}},{"@type":["Person"],"@id":"https://uzzz.org/#/schema/person/29673f1347b0abda5882803c72ee5a3f","name":"fandyvon","sameAs":[]}]}</script>
	<title>DL学习笔记-图像预处理 - 有组织在!</title>
		<link rel="canonical" href="https://uzzz.org/article/3037/">
	<script type="text/javascript" src="https://cdn.ampproject.org/v0.js" async></script>
<style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>
	<style amp-custom>
		/* Generic WP styling */

.alignright {
	float: right;
}

.alignleft {
	float: left;
}

.aligncenter {
	display: block;
	text-align: center;
	margin-left: auto;
	margin-right: auto;
}

.amp-wp-enforced-sizes {
	/** Our sizes fallback is 100vw, and we have a padding on the container; the max-width here prevents the element from overflowing. **/
	max-width: 100%;
	margin: 0 auto;
}


/*
 * Prevent cases of amp-img converted from img to appear with stretching by using object-fit to scale.
 * See <https://github.com/ampproject/amphtml/issues/21371#issuecomment-475443219>.
 * Also use object-fit:contain in worst case scenario when we can't figure out dimensions for an image.
 * Additionally, in side of \AMP_Img_Sanitizer::determine_dimensions() it could $amp_img->setAttribute( 'object-fit', 'contain' )
 * so that the following rules wouldn't be needed.
 */
amp-img.amp-wp-enforced-sizes[layout="intrinsic"] > img,
amp-anim.amp-wp-enforced-sizes[layout="intrinsic"] > img {
	object-fit: contain;
}

amp-fit-text blockquote,
amp-fit-text h1,
amp-fit-text h2,
amp-fit-text h3,
amp-fit-text h4,
amp-fit-text h5,
amp-fit-text h6 {
	font-size: inherit;
}

/**
 * Override a style rule in Twenty Sixteen and Twenty Seventeen.
 * It set display:none for audio elements.
 * This selector is the same, though it adds body and uses amp-audio instead of audio.
 */
body amp-audio:not([controls]) {
	display: inline-block;
	height: auto;
}

/*
 * Style the default template messages for submit-success, submit-error, and submitting. These elements are inserted
 * by the form sanitizer when a POST form lacks the action-xhr attribute.
 */
.amp-wp-default-form-message > p {
	margin: 1em 0;
	padding: 0.5em;
}

.amp-wp-default-form-message[submitting] > p,
.amp-wp-default-form-message[submit-success] > p.amp-wp-form-redirecting {
	font-style: italic;
}

.amp-wp-default-form-message[submit-success] > p:not(.amp-wp-form-redirecting) {
	border: solid 1px #008000;
	background-color: #90ee90;
	color: #000;
}

.amp-wp-default-form-message[submit-error] > p {
	border: solid 1px #f00;
	background-color: #ffb6c1;
	color: #000;
}

/* Prevent showing empty success message in the case of an AMP-Redirect-To response header. */
.amp-wp-default-form-message[submit-success] > p:empty {
	display: none;
}

amp-carousel .amp-wp-gallery-caption {
	position: absolute;
	bottom: 0;
	left: 0;
	right: 0;
	text-align: center;
	background-color: rgba(0, 0, 0, 0.5);
	color: #fff;
	padding: 1rem;
}

.wp-block-gallery[data-amp-carousel="true"] {
	display: block;
	flex-wrap: unset;
}

/* Template Styles */

.amp-wp-content,
.amp-wp-title-bar div {
		margin: 0 auto;
	max-width: 840px;
	}

html {
	background: #0a89c0;
}

body {
	background: #fff;
	color: #353535;
	font-family: Georgia, 'Times New Roman', Times, Serif;
	font-weight: 300;
	line-height: 1.75em;
}

p,
ol,
ul,
figure {
	margin: 0 0 1em;
	padding: 0;
}

a,
a:visited {
	color: #0a89c0;
}

a:hover,
a:active,
a:focus {
	color: #353535;
}

/* Quotes */

blockquote {
	color: #353535;
	background: rgba(127,127,127,.125);
	border-left: 2px solid #0a89c0;
	margin: 8px 0 24px 0;
	padding: 16px;
}

blockquote p:last-child {
	margin-bottom: 0;
}

/* UI Fonts */

.amp-wp-meta,
.amp-wp-header div,
.amp-wp-title,
.wp-caption-text,
.amp-wp-tax-category,
.amp-wp-tax-tag,
.amp-wp-comments-link,
.amp-wp-footer p,
.back-to-top {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen-Sans", "Ubuntu", "Cantarell", "Helvetica Neue", sans-serif;
}

/* Header */

.amp-wp-header {
	background-color: #0a89c0;
}

.amp-wp-header div {
	color: #fff;
	font-size: 1em;
	font-weight: 400;
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: .875em 16px;
	position: relative;
}

.amp-wp-header a {
	color: #fff;
	text-decoration: none;
}


.amp-wp-header .amp-wp-site-icon {
	/** site icon is 32px **/
	background-color: #fff;
	border: 1px solid #fff;
	border-radius: 50%;
	position: absolute;
	right: 18px;
	top: 10px;
}

/* Article */

.amp-wp-article {
	color: #353535;
	font-weight: 400;
	margin: 1.5em auto;
	max-width: 840px;
	overflow-wrap: break-word;
	word-wrap: break-word;
}

/* Article Header */

.amp-wp-article-header {
	align-items: center;
	align-content: stretch;
	display: flex;
	flex-wrap: wrap;
	justify-content: space-between;
	margin: 1.5em 16px 0;
}

.amp-wp-title {
	color: #353535;
	display: block;
	flex: 1 0 100%;
	font-weight: 900;
	margin: 0 0 .625em;
	width: 100%;
}

/* Article Meta */

.amp-wp-meta {
	color: #696969;
	display: inline-block;
	flex: 2 1 50%;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0 0 1.5em;
	padding: 0;
}

.amp-wp-article-header .amp-wp-meta:last-of-type {
	text-align: right;
}

.amp-wp-article-header .amp-wp-meta:first-of-type {
	text-align: left;
}

.amp-wp-byline amp-img,
.amp-wp-byline .amp-wp-author {
	display: inline-block;
	vertical-align: middle;
}

.amp-wp-byline amp-img {
	border: 1px solid #0a89c0;
	border-radius: 50%;
	position: relative;
	margin-right: 6px;
}

.amp-wp-posted-on {
	text-align: right;
}

/* Featured image */

.amp-wp-article-featured-image {
	margin: 0 0 1em;
}
.amp-wp-article-featured-image amp-img {
	margin: 0 auto;
}
.amp-wp-article-featured-image.wp-caption .wp-caption-text {
	margin: 0 18px;
}

/* Article Content */

.amp-wp-article-content {
	margin: 0 16px;
}

.amp-wp-article-content ul,
.amp-wp-article-content ol {
	margin-left: 1em;
}

.amp-wp-article-content .wp-caption {
	max-width: 100%;
}

.amp-wp-article-content amp-img {
	margin: 0 auto;
}

.amp-wp-article-content amp-img.alignright {
	margin: 0 0 1em 16px;
}

.amp-wp-article-content amp-img.alignleft {
	margin: 0 16px 1em 0;
}

/* Captions */

.wp-caption {
	padding: 0;
}

.wp-caption.alignleft {
	margin-right: 16px;
}

.wp-caption.alignright {
	margin-left: 16px;
}

.wp-caption .wp-caption-text {
	border-bottom: 1px solid #c2c2c2;
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0;
	padding: .66em 10px .75em;
}

/* AMP Media */

.alignwide,
.alignfull {
	clear: both;
}

amp-carousel {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}
amp-iframe,
amp-youtube,
amp-instagram,
amp-vine {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}

.amp-wp-article-content amp-carousel amp-img {
	border: none;
}

amp-carousel > amp-img > img {
	object-fit: contain;
}

.amp-wp-iframe-placeholder {
	background: #c2c2c2 url( https://uzzz.org/wp-content/plugins/amp/assets/images/placeholder-icon.png ) no-repeat center 40%;
	background-size: 48px 48px;
	min-height: 48px;
}

/* Article Footer Meta */

.amp-wp-article-footer .amp-wp-meta {
	display: block;
}

.amp-wp-tax-category,
.amp-wp-tax-tag {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 1.5em 16px;
}

.amp-wp-comments-link {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	text-align: center;
	margin: 2.25em 0 1.5em;
}

.amp-wp-comments-link a {
	border-style: solid;
	border-color: #c2c2c2;
	border-width: 1px 1px 2px;
	border-radius: 4px;
	background-color: transparent;
	color: #0a89c0;
	cursor: pointer;
	display: block;
	font-size: 14px;
	font-weight: 600;
	line-height: 18px;
	margin: 0 auto;
	max-width: 200px;
	padding: 11px 16px;
	text-decoration: none;
	width: 50%;
	-webkit-transition: background-color 0.2s ease;
			transition: background-color 0.2s ease;
}

/* AMP Footer */

.amp-wp-footer {
	border-top: 1px solid #c2c2c2;
	margin: calc(1.5em - 1px) 0 0;
}

.amp-wp-footer div {
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: 1.25em 16px 1.25em;
	position: relative;
}

.amp-wp-footer h2 {
	font-size: 1em;
	line-height: 1.375em;
	margin: 0 0 .5em;
}

.amp-wp-footer p {
	color: #696969;
	font-size: .8em;
	line-height: 1.5em;
	margin: 0 85px 0 0;
}

.amp-wp-footer a {
	text-decoration: none;
}

.back-to-top {
	bottom: 1.275em;
	font-size: .8em;
	font-weight: 600;
	line-height: 2em;
	position: absolute;
	right: 16px;
}
		/* Inline stylesheets */
:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-323ff77{background-color:#fff;color:#000;font-family:"宋体";font-size:9pt}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-4ed290b{color:#609}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-055ec14{color:#008080}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-6b7fa96{color:#808080}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-8880ce2{color:#000080}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-93316a4{color:#00f}	</style>
</head>

<body class="">

<header id="top" class="amp-wp-header">
	<div>
		<a href="https://uzzz.org/">
										<amp-img src="https://uzzz.org/wp-content/uploads/2019/10/cropped-icon-32x32.png" width="32" height="32" class="amp-wp-site-icon"></amp-img>
						<span class="amp-site-title">
				有组织在!			</span>
		</a>

					</div>
</header>

<article class="amp-wp-article">
	<header class="amp-wp-article-header">
		<h1 class="amp-wp-title">DL学习笔记-图像预处理</h1>
			<div class="amp-wp-meta amp-wp-byline">
					<amp-img src="https://secure.gravatar.com/avatar/e786821a74ef0467825a7d60183307bc?s=24&d=mm&r=g" alt="fandyvon" width="24" height="24" layout="fixed"></amp-img>
				<span class="amp-wp-author author vcard">fandyvon</span>
	</div>
<div class="amp-wp-meta amp-wp-posted-on">
	<time datetime="2018-06-11T16:43:58+00:00">
		2 years ago	</time>
</div>
	</header>

	
	<div class="amp-wp-article-content">
		<div id="article_content" class="article_content clearfix">
 <br>
 
 
 
<div class="htmledit_views" id="content_views">
<div>
   一、为什么使用图像预处理
  </div>
<div>
   1、图像的亮度、对比度等属性对图像的影响是非常大的，相同物体在不同的亮度，对比度下差别非常大。在图像识别的问题中，我们经常会遇到阴影、强曝光之类的图片，这些因素都不应该影响最后的识别结果，所以我们要对图像进行预处理，使得得到的神经网络模型尽可能小的被无关因素所影响。
  </div>
<div>
   2、在我们遇到图像样本过少，或者不均衡时，也可以使用图像预处理，增加样本数量。
  </div>

<div>
   3、有时物体拍摄的角度不同，也会有很大的差异，所以刻意将图像进行随机的翻转，可以提高模型健壮性。
  </div>
<div>
   二、图像处理函数
  </div>

<div>
   1、读取图像的原始数据。
  </div>
<div>
   图像在存储是并不是直接记录这些矩阵中的数字，而是记录经过压缩编码之后的结果，所以要将一个图片还原成三维矩阵，需要一个解码的过程。
  </div>

<div>
<pre class="amp-wp-323ff77">image_raw_data = tf.gfile.FastGFile(<span class="amp-wp-055ec14"><strong>'images/image_0043.jpg'</strong></span>, <span class="amp-wp-055ec14"><strong>'rb'</strong></span>).read()
img_data = tf.image.decode_jpeg(image_raw_data)</pre>
</div>
<div>
   2、图像大小调整
  </div>

<div>
   图像大小调整有两种方法，
  </div>
<div>
   第一种是通过算法使得新的图像尽量保存原始图像上的所有信息。
  </div>
<div>
   第二种是对图像进行裁剪或者填充，只获得感兴趣区域。
  </div>
<div>
   TensorFlow提供了四种缩放图像的算法，注意要加入截断函数，防止数值越界。
  </div>
<div>
   <amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180611155233733?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2Mzg3Njgz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="741" height="179" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180611155233733?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2Mzg3Njgz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="741" height="179" class=""></noscript></amp-img>
  </div>
<div>
<pre class="amp-wp-323ff77"><span class="amp-wp-6b7fa96"><em>#重新调整图片大小 </em></span><span class="amp-wp-8880ce2"><strong>def </strong></span>resize(image_data):
    <span class="amp-wp-8880ce2"><strong>with </strong></span>tf.Session() <span class="amp-wp-8880ce2"><strong>as </strong></span><span class="amp-wp-6b7fa96">sess</span>:
        image_data = tf.image.convert_image_dtype(image_data, <span class="amp-wp-4ed290b">dtype</span>=tf.float32)
        methods=[<span class="amp-wp-055ec14"><strong>'Bilinear Interpolation'</strong></span>, <span class="amp-wp-055ec14"><strong>'Nearest neighbor interpolation'</strong></span>, <span class="amp-wp-055ec14"><strong>'Bicubic interpolation'</strong></span>, <span class="amp-wp-055ec14"><strong>'Area interpolation'</strong></span>]
        plt.subplot(<span class="amp-wp-93316a4">231</span>), plt.imshow(image_data.eval()), plt.title(<span class="amp-wp-055ec14"><strong>'original'</strong></span>)
        step = <span class="amp-wp-93316a4">231
</span><span class="amp-wp-93316a4">        </span><span class="amp-wp-8880ce2"><strong>for </strong></span>i <span class="amp-wp-8880ce2"><strong>in </strong></span><span class="amp-wp-8880ce2">range</span>(<span class="amp-wp-93316a4">4</span>):
            step += <span class="amp-wp-93316a4">1
</span><span class="amp-wp-93316a4">            </span>resized = tf.image.resize_images(image_data, [<span class="amp-wp-93316a4">300</span>, <span class="amp-wp-93316a4">300</span>], <span class="amp-wp-4ed290b">method</span>=i)
            resized = tf.clip_by_value(resized, <span class="amp-wp-93316a4">0.0</span>, <span class="amp-wp-93316a4">1.0</span>)
            plt.subplot(step),plt.imshow(resized.eval()), plt.title(methods[i])

        plt.show()
</pre>
</div>
<div>
   显示图像如下：
  </div>
<div>
   <amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/201806111553340?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2Mzg3Njgz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="753" height="538" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/201806111553340?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2Mzg3Njgz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="753" height="538" class=""></noscript></amp-img>
  </div>
<div>
   剪裁和填充图片，通过tf.image.resize_image_with_crop_or_pad函数实现，第一参数是输入图像，后面是裁剪以后的大小。如果小于输入图像，那么就裁剪输入图像居中部分的大小；如果大于输入图像，就填充输入图像四周。
  </div>
<div>
<pre class="amp-wp-323ff77"><span class="amp-wp-6b7fa96"><em>#裁剪和填充图片 </em></span><span class="amp-wp-8880ce2"><strong>def </strong></span>crop_and_pad(image_data):
    <span class="amp-wp-8880ce2"><strong>with </strong></span>tf.Session() <span class="amp-wp-8880ce2"><strong>as </strong></span><span class="amp-wp-6b7fa96">sess</span>:
        <span class="amp-wp-6b7fa96"><em>#resize_image_with_crop_or_pad 如果输入图像尺寸大于输出图像，截取原始图像中居中的部分 </em></span><span class="amp-wp-6b7fa96"><em> #如果输入小于输出，会在原始图像四周填充全0背景 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>croped_1 = tf.image.resize_image_with_crop_or_pad(image_data, <span class="amp-wp-93316a4">300</span>, <span class="amp-wp-93316a4">300</span>)
        croped_2 = tf.image.resize_image_with_crop_or_pad(image_data, <span class="amp-wp-93316a4">1000</span>, <span class="amp-wp-93316a4">1000</span>)
        padded = tf.image.resize_image_with_crop_or_pad(image_data, <span class="amp-wp-93316a4">3000</span>, <span class="amp-wp-93316a4">3000</span>)
        show(croped_1)
        show(croped_2)
        show(padded)</pre>
</div>
<div>
   也提供了按比例调整图像大小的函数，tf.image.ecntral_crop，
  </div>
<div>
   
  </div>

<pre class="amp-wp-323ff77"></pre>
<div>
   <span class="amp-wp-6b7fa96"><em>#截取中间50%的图片 </em></span><br>
   <span class="amp-wp-8880ce2"><strong>def </strong></span>central_crop(image_data):<br>
   <span class="amp-wp-8880ce2"><strong>with </strong></span>tf.Session()<br>
   <span class="amp-wp-8880ce2"><strong>as </strong></span><br>
   <span class="amp-wp-6b7fa96">sess</span>: central_croped = tf.image.central_crop(image_data,<br>
   <span class="amp-wp-93316a4">0.5</span>) plt.imshow(central_croped.eval()) plt.show()
  </div>
<div>
  </div>


<div>
   还有固定尺寸的裁剪，第二三个参数是起始点的坐标，第四五个参数是宽高
<pre class="amp-wp-323ff77"></pre>
<pre class="amp-wp-323ff77"><span class="amp-wp-6b7fa96"><em>#固定边框提取 </em></span><span class="amp-wp-8880ce2"><strong>def </strong></span>bounding_box(image_raw_data):
    <span class="amp-wp-8880ce2"><strong>with </strong></span>tf.Session() <span class="amp-wp-8880ce2"><strong>as </strong></span><span class="amp-wp-6b7fa96">sess</span>:

        image_data = tf.image.decode_jpeg(image_raw_data)
        <span class="amp-wp-6b7fa96"><em># crop_to_bounding_box(image, offset_height, offset_width, target_height,arget_width) </em></span><span class="amp-wp-6b7fa96"><em> #第二个第三个参数是起始点的坐标， 四五是宽高 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>box_croped = tf.image.crop_to_bounding_box(image_data, <span class="amp-wp-93316a4">100</span>, <span class="amp-wp-93316a4">100</span>, <span class="amp-wp-93316a4">300</span>, <span class="amp-wp-93316a4">300</span>)
        <span class="amp-wp-6b7fa96"><em># 二三是原始图像在目标图像上所在的起始坐标，四五是目标图像的大小 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>box_padded = tf.image.pad_to_bounding_box(image_data,<span class="amp-wp-93316a4">100</span>, <span class="amp-wp-93316a4">100</span>, <span class="amp-wp-93316a4">3000</span>, <span class="amp-wp-93316a4">3000</span>)
        plt.imshow(box_croped.eval())
        plt.show()
        plt.imshow(box_padded.eval())
        plt.show()</pre>
</div>
<div>
   3、图像翻转
  </div>

<pre class="amp-wp-323ff77"><span class="amp-wp-6b7fa96"><em>#图像翻转 </em></span><span class="amp-wp-8880ce2"><strong>def </strong></span>flip(image_raw_data):
    <span class="amp-wp-8880ce2"><strong>with </strong></span>tf.Session() <span class="amp-wp-8880ce2"><strong>as </strong></span><span class="amp-wp-6b7fa96">sess</span>:
        image_data = tf.image.decode_jpeg(image_raw_data)
        <span class="amp-wp-6b7fa96"><em>#上下翻转 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>flipped_up = tf.image.flip_up_down(image_data)
        <span class="amp-wp-6b7fa96"><em>#左右翻转 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>flipped_left = tf.image.flip_left_right(image_data)
        <span class="amp-wp-6b7fa96"><em>#对角翻转 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>transposed = tf.image.transpose_image(image_data)

        plt.imshow(flipped_up.eval())
        plt.show()
        plt.imshow(flipped_left.eval())
        plt.show()
        plt.imshow(transposed.eval())
        plt.show()

        <span class="amp-wp-6b7fa96"><em>#以50%的概率上下翻转图像 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>flipped_up_random = tf.image.random_flip_up_down(image_data)
        <span class="amp-wp-6b7fa96"><em>#以50%的概率左右翻转图像 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>flipped_left_random = tf.image.random_flip_left_right(image_data)

        plt.imshow(flipped_up_random.eval())
        plt.show()
        plt.imshow(flipped_left_random.eval())
        plt.show()</pre>
<div>
   <amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180611163903276?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2Mzg3Njgz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="756" height="364" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180611163903276?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2Mzg3Njgz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="756" height="364" class=""></noscript></amp-img>
  </div>
<div>
   4、图像色彩调整
  </div>
<pre class="amp-wp-323ff77"><span class="amp-wp-6b7fa96"><em>#图像亮度调整 </em></span><span class="amp-wp-8880ce2"><strong>def </strong></span>brightness(image_raw_data):
    <span class="amp-wp-8880ce2"><strong>with </strong></span>tf.Session() <span class="amp-wp-8880ce2"><strong>as </strong></span><span class="amp-wp-6b7fa96">sess</span>:
        image_data = tf.image.decode_jpeg(image_raw_data)
        <span class="amp-wp-6b7fa96"><em>#将图像的亮度-0.5 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>adjusted = tf.image.adjust_brightness(image_data,-<span class="amp-wp-93316a4">0.5</span>)
        <span class="amp-wp-6b7fa96"><em>#为了防止像素超出，要进行截断处理 </em></span><span class="amp-wp-6b7fa96"><em> # adjusted = tf.clip_by_value(adjusted, 0.0, 1.0) </em></span><span class="amp-wp-6b7fa96"><em> </em></span><span class="amp-wp-6b7fa96"><em> </em></span>plt.imshow(adjusted.eval())
        plt.show()

        <span class="amp-wp-6b7fa96"><em>#将图像亮度+0.5 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>adjusted = tf.image.adjust_brightness(image_data, <span class="amp-wp-93316a4">0.5</span>)
        plt.imshow(adjusted.eval())
        plt.show()

        <span class="amp-wp-6b7fa96"><em>#在【max_delta, max_delax】的范围内随机调整 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>adjusted = tf.image.random_brightness(image_data,<span class="amp-wp-93316a4">0.5</span>)
        plt.imshow(adjusted.eval())
        plt.show()</pre>
<div>
   图像对比度
  </div>
<div>
<pre class="amp-wp-323ff77"><span class="amp-wp-6b7fa96"><em>#调整图像的对比度 </em></span><span class="amp-wp-8880ce2"><strong>def </strong></span>contrast(image_raw_data):
    <span class="amp-wp-8880ce2"><strong>with </strong></span>tf.Session() <span class="amp-wp-8880ce2"><strong>as </strong></span><span class="amp-wp-6b7fa96">sess</span>:

        image_data = tf.image.decode_jpeg(image_raw_data)

        <span class="amp-wp-6b7fa96"><em>#将图像的对比度减少到0.5 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>adjusted = tf.image.adjust_contrast(image_data, <span class="amp-wp-93316a4">0.5</span>)
        plt.imshow(adjusted.eval())
        plt.show()

        <span class="amp-wp-6b7fa96"><em>#将图像的对比度增加5倍 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>adjusted = tf.image.adjust_contrast(image_data, <span class="amp-wp-93316a4">5</span>)
        plt.imshow(adjusted.eval())
        plt.show()

        <span class="amp-wp-6b7fa96"><em>#在【lower, upper】之间随机调整 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>adjusted = tf.image.random_contrast(image_data, <span class="amp-wp-93316a4">0.5</span>, <span class="amp-wp-93316a4">5</span>)
        plt.imshow(adjusted.eval())
        plt.show()</pre>
</div>
<div>
   图像色相
  </div>
<pre class="amp-wp-323ff77"><span class="amp-wp-6b7fa96"><em>#调整图像色相 </em></span><span class="amp-wp-8880ce2"><strong>def </strong></span>hue(image_data):
    <span class="amp-wp-8880ce2"><strong>with </strong></span>tf.Session() <span class="amp-wp-8880ce2"><strong>as </strong></span><span class="amp-wp-6b7fa96">sess</span>:
        plt.subplot(<span class="amp-wp-93316a4">231</span>),plt.imshow(image_data.eval()),plt.title(<span class="amp-wp-055ec14"><strong>'original'</strong></span>)
        <span class="amp-wp-6b7fa96"><em>#色相加0.1 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>adjusted = tf.image.adjust_hue(image_data, <span class="amp-wp-93316a4">0.1</span>)
        plt.subplot(<span class="amp-wp-93316a4">232</span>),plt.imshow(adjusted.eval()),plt.title(<span class="amp-wp-055ec14"><strong>'+0.1'</strong></span>)
        adjusted = tf.image.adjust_hue(image_data, <span class="amp-wp-93316a4">0.3</span>)
        plt.subplot(<span class="amp-wp-93316a4">233</span>), plt.imshow(adjusted.eval()), plt.title(<span class="amp-wp-055ec14"><strong>'+0.3'</strong></span>)
        adjusted = tf.image.adjust_hue(image_data, <span class="amp-wp-93316a4">0.6</span>)
        plt.subplot(<span class="amp-wp-93316a4">234</span>), plt.imshow(adjusted.eval()), plt.title(<span class="amp-wp-055ec14"><strong>'+0.6'</strong></span>)
        adjusted = tf.image.adjust_hue(image_data, <span class="amp-wp-93316a4">0.9</span>)
        plt.subplot(<span class="amp-wp-93316a4">235</span>), plt.imshow(adjusted.eval()), plt.title(<span class="amp-wp-055ec14"><strong>'+0.9'</strong></span>)
        plt.show()

        <span class="amp-wp-6b7fa96"><em>#max_delta 的取值在[0， 0.5]之间 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>adjusted = tf.image.random_hue(image_data, <span class="amp-wp-93316a4">0.5</span>)
        plt.subplot(<span class="amp-wp-93316a4">236</span>), plt.imshow(adjusted.eval()), plt.title(<span class="amp-wp-055ec14"><strong>'random'</strong></span>)
        plt.show()</pre>
<div>
   图像饱和度
  </div>
<div>
<pre class="amp-wp-323ff77"><span class="amp-wp-6b7fa96"><em>#调整饱和度 </em></span><span class="amp-wp-8880ce2"><strong>def </strong></span>saturation(image_data):
    <span class="amp-wp-8880ce2"><strong>with </strong></span>tf.Session() <span class="amp-wp-8880ce2"><strong>as </strong></span><span class="amp-wp-6b7fa96">sess</span>:
        plt.subplot(<span class="amp-wp-93316a4">221</span>), plt.imshow(image_data.eval()), plt.title(<span class="amp-wp-055ec14"><strong>'original'</strong></span>)
        <span class="amp-wp-6b7fa96"><em>#图像饱和度减5 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>adjusted = tf.image.adjust_saturation(image_data, -<span class="amp-wp-93316a4">5</span>)
        plt.subplot(<span class="amp-wp-93316a4">222</span>), plt.imshow(adjusted.eval()), plt.title(<span class="amp-wp-055ec14"><strong>'-5'</strong></span>)
        <span class="amp-wp-6b7fa96"><em>#图像饱和度加5 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>adjusted = tf.image.adjust_saturation(image_data, <span class="amp-wp-93316a4">5</span>)
        plt.subplot(<span class="amp-wp-93316a4">223</span>), plt.imshow(adjusted.eval()), plt.title(<span class="amp-wp-055ec14"><strong>'5'</strong></span>)
        <span class="amp-wp-6b7fa96"><em>#在[lower，upper]的范围内随机调整图像的饱和度 lower must be non-negative </em></span><span class="amp-wp-6b7fa96"><em> </em></span>adjusted = tf.image.random_saturation(image_data, <span class="amp-wp-93316a4">0.</span>, <span class="amp-wp-93316a4">5.</span>)
        plt.subplot(<span class="amp-wp-93316a4">224</span>), plt.imshow(adjusted.eval()), plt.title(<span class="amp-wp-055ec14"><strong>'random'</strong></span>)
        plt.show()</pre>
</div>
<div>
   图片gamma校正
  </div>
<pre class="amp-wp-323ff77"><span class="amp-wp-6b7fa96"><em>#图像gamma校正 </em></span><span class="amp-wp-8880ce2"><strong>def </strong></span>mamma(image_data):
    <span class="amp-wp-8880ce2"><strong>with </strong></span>tf.Session() <span class="amp-wp-8880ce2"><strong>as </strong></span><span class="amp-wp-6b7fa96">sess</span>:
        image_data = tf.image.convert_image_dtype(image_data, <span class="amp-wp-4ed290b">dtype</span>=tf.float32)
        adjusted = tf.image.adjust_gamma(image_data, <span class="amp-wp-4ed290b">gain</span>=<span class="amp-wp-93316a4">1.0</span>, <span class="amp-wp-4ed290b">gamma</span>=<span class="amp-wp-93316a4">4.0</span>)
        plt.imshow(adjusted.eval())
        plt.show()</pre>
<div>
   图像标准化
  </div>
<div>
<pre class="amp-wp-323ff77"><span class="amp-wp-6b7fa96"><em>#图像标准化 </em></span><span class="amp-wp-8880ce2"><strong>def </strong></span>standardization(image_data):
    <span class="amp-wp-8880ce2"><strong>with </strong></span>tf.Session() <span class="amp-wp-8880ce2"><strong>as </strong></span><span class="amp-wp-6b7fa96">sess</span>:
        <span class="amp-wp-8880ce2">print</span>(image_data)
        h,w = tf.shape(image_data).eval()[:<span class="amp-wp-93316a4">2</span>]
        <span class="amp-wp-6b7fa96"><em>#将输入图像 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>reshaped = tf.reshape(image_data.eval(), [h*w, -<span class="amp-wp-93316a4">1</span>])
        <span class="amp-wp-8880ce2">print</span>(reshaped.eval())
        plt.subplot(<span class="amp-wp-93316a4">211</span>),plt.hist(reshaped.eval()),plt.title(<span class="amp-wp-055ec14"><strong>'original'</strong></span>)
        <span class="amp-wp-6b7fa96"><em>#图像标准化 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>adjusted = tf.image.per_image_standardization(image_data)
        adjusted_reshaped = tf.reshape(adjusted.eval(), [h*w, -<span class="amp-wp-93316a4">1</span>])
        plt.subplot(<span class="amp-wp-93316a4">212</span>), plt.hist(adjusted_reshaped.eval()), plt.title(<span class="amp-wp-055ec14"><strong>'adjusted'</strong></span>)
        plt.show()</pre>
</div>
<div>
   图像预处理完整样例
  </div>
<pre class="amp-wp-323ff77"><span class="amp-wp-8880ce2"><strong>import </strong></span>tensorflow <span class="amp-wp-8880ce2"><strong>as </strong></span>tf
<span class="amp-wp-8880ce2"><strong>import </strong></span>numpy <span class="amp-wp-8880ce2"><strong>as </strong></span>np
<span class="amp-wp-8880ce2"><strong>import </strong></span>matplotlib.pyplot <span class="amp-wp-8880ce2"><strong>as </strong></span>plt

<span class="amp-wp-8880ce2"><strong>def </strong></span>distort_color(image, color_orderding=<span class="amp-wp-93316a4">0</span>):
    <span class="amp-wp-8880ce2"><strong>if </strong></span>color_orderding == <span class="amp-wp-93316a4">0</span>:
        image = tf.image.random_brightness(image, <span class="amp-wp-4ed290b">max_delta</span>= <span class="amp-wp-93316a4">32. </span>/ <span class="amp-wp-93316a4">255.</span>)
        image = tf.image.random_saturation(image, <span class="amp-wp-4ed290b">lower</span>=<span class="amp-wp-93316a4">0.5</span>, <span class="amp-wp-4ed290b">upper</span>=<span class="amp-wp-93316a4">1.5</span>)
        image = tf.image.random_hue(image, <span class="amp-wp-4ed290b">max_delta</span>=<span class="amp-wp-93316a4">0.2</span>)
        image = tf.image.random_contrast(image, <span class="amp-wp-4ed290b">lower</span>=<span class="amp-wp-93316a4">0.5</span>, <span class="amp-wp-4ed290b">upper</span>=<span class="amp-wp-93316a4">1.5</span>)
    <span class="amp-wp-8880ce2"><strong>elif </strong></span>color_orderding == <span class="amp-wp-93316a4">1</span>:
        image = tf.image.random_saturation(image, <span class="amp-wp-4ed290b">lower</span>=<span class="amp-wp-93316a4">0.5</span>, <span class="amp-wp-4ed290b">upper</span>=<span class="amp-wp-93316a4">1.5</span>)
        image = tf.image.random_brightness(image, <span class="amp-wp-4ed290b">max_delta</span>= <span class="amp-wp-93316a4">32. </span>/<span class="amp-wp-93316a4">255.</span>)
        image = tf.image.random_contrast(image, <span class="amp-wp-4ed290b">lower</span>=<span class="amp-wp-93316a4">0.5</span>, <span class="amp-wp-4ed290b">upper</span>=<span class="amp-wp-93316a4">1.5</span>)
        image = tf.image.random_hue(image, <span class="amp-wp-4ed290b">max_delta</span>=<span class="amp-wp-93316a4">0.2</span>)
    <span class="amp-wp-8880ce2"><strong>elif </strong></span>color_orderding == <span class="amp-wp-93316a4">2</span>:
        image = tf.image.random_contrast(image, <span class="amp-wp-4ed290b">lower</span>=<span class="amp-wp-93316a4">0.5</span>, <span class="amp-wp-4ed290b">upper</span>=<span class="amp-wp-93316a4">1.5</span>)
        image = tf.image.random_saturation(image, <span class="amp-wp-4ed290b">lower</span>=<span class="amp-wp-93316a4">0.5</span>, <span class="amp-wp-4ed290b">upper</span>=<span class="amp-wp-93316a4">1.5</span>)
        image = tf.image.random_brightness(image, <span class="amp-wp-4ed290b">max_delta</span>=<span class="amp-wp-93316a4">32. </span>/ <span class="amp-wp-93316a4">255.</span>)
        image = tf.image.random_hue(image, <span class="amp-wp-4ed290b">max_delta</span>=<span class="amp-wp-93316a4">0.2</span>)
    <span class="amp-wp-8880ce2"><strong>elif </strong></span>color_orderding == <span class="amp-wp-93316a4">3</span>:
        image = tf.image.random_hue(image, <span class="amp-wp-4ed290b">max_delta</span>=<span class="amp-wp-93316a4">0.2</span>)
        image = tf.image.random_contrast(image, <span class="amp-wp-4ed290b">lower</span>=<span class="amp-wp-93316a4">0.5</span>, <span class="amp-wp-4ed290b">upper</span>=<span class="amp-wp-93316a4">1.5</span>)
        image = tf.image.random_saturation(image, <span class="amp-wp-4ed290b">lower</span>=<span class="amp-wp-93316a4">0.5</span>, <span class="amp-wp-4ed290b">upper</span>=<span class="amp-wp-93316a4">1.5</span>)
        image = tf.image.random_brightness(image, <span class="amp-wp-4ed290b">max_delta</span>=<span class="amp-wp-93316a4">32. </span>/ <span class="amp-wp-93316a4">255.</span>)
    <span class="amp-wp-8880ce2"><strong>else</strong></span>:
        image = tf.image.random_hue(image, <span class="amp-wp-4ed290b">max_delta</span>=<span class="amp-wp-93316a4">0.2</span>)
        image = tf.image.random_saturation(image, <span class="amp-wp-4ed290b">lower</span>=<span class="amp-wp-93316a4">0.5</span>, <span class="amp-wp-4ed290b">upper</span>=<span class="amp-wp-93316a4">1.5</span>)
        image = tf.image.random_contrast(image, <span class="amp-wp-4ed290b">lower</span>=<span class="amp-wp-93316a4">0.5</span>, <span class="amp-wp-4ed290b">upper</span>=<span class="amp-wp-93316a4">1.5</span>)
        image = tf.image.random_brightness(image, <span class="amp-wp-4ed290b">max_delta</span>=<span class="amp-wp-93316a4">32. </span>/ <span class="amp-wp-93316a4">255.</span>)
    <span class="amp-wp-8880ce2"><strong>return </strong></span>tf.clip_by_value(image, <span class="amp-wp-93316a4">0.0</span>, <span class="amp-wp-93316a4">1.0</span>) <span class="amp-wp-6b7fa96"><em># 进行像素截断，防止越界 </em></span><span class="amp-wp-6b7fa96"><em> </em></span><span class="amp-wp-6b7fa96"><em> </em></span><span class="amp-wp-8880ce2"><strong>def </strong></span>perprocess_for_train(image, height, width, bbox):
    <span class="amp-wp-8880ce2"><strong>if </strong></span>bbox <span class="amp-wp-8880ce2"><strong>is None</strong></span>:
        bbox = tf.constant([<span class="amp-wp-93316a4">0.0</span>, <span class="amp-wp-93316a4">0.0</span>, <span class="amp-wp-93316a4">1.0</span>, <span class="amp-wp-93316a4">1.0</span>], <span class="amp-wp-4ed290b">dtype</span>=tf.float32, <span class="amp-wp-4ed290b">shape</span>=[<span class="amp-wp-93316a4">1</span>, <span class="amp-wp-93316a4">1</span>, <span class="amp-wp-93316a4">4</span>])
    <span class="amp-wp-6b7fa96"><em>#转换图像的张量类型 </em></span><span class="amp-wp-6b7fa96"><em> </em></span><span class="amp-wp-8880ce2"><strong>if </strong></span>image.dtype != tf.float32:
        image = tf.image.convert_image_dtype(image, <span class="amp-wp-4ed290b">dtype</span>=tf.float32)

    <span class="amp-wp-6b7fa96"><em># 随机截取图像，减小需要关注物体大小对图像识别算法的影响 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>bbox_begin, bbox_size, _ = tf.image.sample_distorted_bounding_box(tf.shape(image),<span class="amp-wp-4ed290b">bounding_boxes</span>=bbox)
    distorted_image = tf.slice(image, bbox_begin, bbox_size)

    <span class="amp-wp-6b7fa96"><em>#将随机截取的图像调整为神经网络输入层的大小 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>distorted_image = tf.image.resize_images(distorted_image, [height, width], <span class="amp-wp-4ed290b">method</span>=np.random.randint(<span class="amp-wp-93316a4">4</span>))

    <span class="amp-wp-6b7fa96"><em>#随机左右翻转图片 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>distorted_image = tf.image.random_flip_left_right(distorted_image)

    <span class="amp-wp-6b7fa96"><em>#使用一种随机的顺序调整颜色图像 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>distorted_image = distort_color(distorted_image, np.random.randint(<span class="amp-wp-93316a4">5</span>))
    <span class="amp-wp-8880ce2"><strong>return </strong></span>distorted_image

image_raw_data = tf.gfile.FastGFile(<span class="amp-wp-055ec14"><strong>'images/image_0043.jpg'</strong></span>, <span class="amp-wp-055ec14"><strong>'rb'</strong></span>).read()
<span class="amp-wp-8880ce2"><strong>with </strong></span>tf.Session() <span class="amp-wp-8880ce2"><strong>as </strong></span>sess:
    image_data = tf.image.decode_jpeg(image_raw_data)
    boxes = tf.constant([[[<span class="amp-wp-93316a4">0.05</span>, <span class="amp-wp-93316a4">0.05</span>, <span class="amp-wp-93316a4">0.9</span>, <span class="amp-wp-93316a4">0.7</span>], [<span class="amp-wp-93316a4">0.34</span>, <span class="amp-wp-93316a4">0.47</span>, <span class="amp-wp-93316a4">0.5</span>, <span class="amp-wp-93316a4">0.56</span>]]])
    <span class="amp-wp-6b7fa96"><em># print(image_data) </em></span><span class="amp-wp-6b7fa96"><em> #运行6次获得6种不同的图像 </em></span><span class="amp-wp-6b7fa96"><em> </em></span>step = <span class="amp-wp-93316a4">230
</span><span class="amp-wp-93316a4">    </span><span class="amp-wp-8880ce2"><strong>for </strong></span>i <span class="amp-wp-8880ce2"><strong>in </strong></span><span class="amp-wp-8880ce2">range</span>(<span class="amp-wp-93316a4">6</span>):
        result = perprocess_for_train(image_data,<span class="amp-wp-93316a4">300</span>, <span class="amp-wp-93316a4">300</span>, boxes)
        step = step+<span class="amp-wp-93316a4">1
</span><span class="amp-wp-93316a4">        </span>plt.subplot(step)
        plt.imshow(result.eval())
    plt.show()
</pre>
<p>  <amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180611164328779?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2Mzg3Njgz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="700" height="514" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180611164328779?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2Mzg3Njgz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="" width="700" height="514" class=""></noscript></amp-img></p>




<div>
   
  </div>
</div>
</div>
	</div>

	<footer class="amp-wp-article-footer">
			<div class="amp-wp-meta amp-wp-tax-category">
		Categories: <a href="https://uzzz.org/category/jiqixuexi/" rel="category tag">机器学习</a>	</div>

	</footer>
</article>

<footer class="amp-wp-footer">
	<div>
		<h2>有组织在!</h2>
		<a href="#top" class="back-to-top">Back to top</a>
	</div>
</footer>



</body>
</html>
