<!DOCTYPE html>
<html amp lang="en-US">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1">
	<script type="application/ld+json" class="yoast-schema-graph yoast-schema-graph--main">{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://uzzz.org/#website","url":"https://uzzz.org/","name":"\u6709\u7ec4\u7ec7\u5728!","potentialAction":{"@type":"SearchAction","target":"https://uzzz.org/?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"ImageObject","@id":"https://uzzz.org/article/3056/#primaryimage","url":"https://uzshare.com/_p?https://img-blog.csdn.net/20180917165109285?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tra2traWtv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70"},{"@type":"WebPage","@id":"https://uzzz.org/article/3056/#webpage","url":"https://uzzz.org/article/3056/","inLanguage":"en-US","name":"\u6df1\u5ea6\u5b66\u4e60\u7b14\u8bb0(4)\uff1a1.1-1.3 \u8fb9\u7f18\u68c0\u6d4b(edge detection) - \u6709\u7ec4\u7ec7\u5728!","isPartOf":{"@id":"https://uzzz.org/#website"},"primaryImageOfPage":{"@id":"https://uzzz.org/article/3056/#primaryimage"},"datePublished":"2018-09-17T15:19:20+00:00","dateModified":"2018-09-17T15:19:20+00:00","author":{"@id":"https://uzzz.org/#/schema/person/29673f1347b0abda5882803c72ee5a3f"}},{"@type":["Person"],"@id":"https://uzzz.org/#/schema/person/29673f1347b0abda5882803c72ee5a3f","name":"fandyvon","sameAs":[]}]}</script>
	<title>深度学习笔记(4)：1.1-1.3 边缘检测(edge detection) - 有组织在!</title>
		<link rel="canonical" href="https://uzzz.org/article/3056/">
	<script type="text/javascript" src="https://cdn.ampproject.org/v0.js" async></script>
<style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>
	<style amp-custom>
		/* Generic WP styling */

.alignright {
	float: right;
}

.alignleft {
	float: left;
}

.aligncenter {
	display: block;
	text-align: center;
	margin-left: auto;
	margin-right: auto;
}

.amp-wp-enforced-sizes {
	/** Our sizes fallback is 100vw, and we have a padding on the container; the max-width here prevents the element from overflowing. **/
	max-width: 100%;
	margin: 0 auto;
}


/*
 * Prevent cases of amp-img converted from img to appear with stretching by using object-fit to scale.
 * See <https://github.com/ampproject/amphtml/issues/21371#issuecomment-475443219>.
 * Also use object-fit:contain in worst case scenario when we can't figure out dimensions for an image.
 * Additionally, in side of \AMP_Img_Sanitizer::determine_dimensions() it could $amp_img->setAttribute( 'object-fit', 'contain' )
 * so that the following rules wouldn't be needed.
 */
amp-img.amp-wp-enforced-sizes[layout="intrinsic"] > img,
amp-anim.amp-wp-enforced-sizes[layout="intrinsic"] > img {
	object-fit: contain;
}

amp-fit-text blockquote,
amp-fit-text h1,
amp-fit-text h2,
amp-fit-text h3,
amp-fit-text h4,
amp-fit-text h5,
amp-fit-text h6 {
	font-size: inherit;
}

/**
 * Override a style rule in Twenty Sixteen and Twenty Seventeen.
 * It set display:none for audio elements.
 * This selector is the same, though it adds body and uses amp-audio instead of audio.
 */
body amp-audio:not([controls]) {
	display: inline-block;
	height: auto;
}

/*
 * Style the default template messages for submit-success, submit-error, and submitting. These elements are inserted
 * by the form sanitizer when a POST form lacks the action-xhr attribute.
 */
.amp-wp-default-form-message > p {
	margin: 1em 0;
	padding: 0.5em;
}

.amp-wp-default-form-message[submitting] > p,
.amp-wp-default-form-message[submit-success] > p.amp-wp-form-redirecting {
	font-style: italic;
}

.amp-wp-default-form-message[submit-success] > p:not(.amp-wp-form-redirecting) {
	border: solid 1px #008000;
	background-color: #90ee90;
	color: #000;
}

.amp-wp-default-form-message[submit-error] > p {
	border: solid 1px #f00;
	background-color: #ffb6c1;
	color: #000;
}

/* Prevent showing empty success message in the case of an AMP-Redirect-To response header. */
.amp-wp-default-form-message[submit-success] > p:empty {
	display: none;
}

amp-carousel .amp-wp-gallery-caption {
	position: absolute;
	bottom: 0;
	left: 0;
	right: 0;
	text-align: center;
	background-color: rgba(0, 0, 0, 0.5);
	color: #fff;
	padding: 1rem;
}

.wp-block-gallery[data-amp-carousel="true"] {
	display: block;
	flex-wrap: unset;
}

/* Template Styles */

.amp-wp-content,
.amp-wp-title-bar div {
		margin: 0 auto;
	max-width: 840px;
	}

html {
	background: #0a89c0;
}

body {
	background: #fff;
	color: #353535;
	font-family: Georgia, 'Times New Roman', Times, Serif;
	font-weight: 300;
	line-height: 1.75em;
}

p,
ol,
ul,
figure {
	margin: 0 0 1em;
	padding: 0;
}

a,
a:visited {
	color: #0a89c0;
}

a:hover,
a:active,
a:focus {
	color: #353535;
}

/* Quotes */

blockquote {
	color: #353535;
	background: rgba(127,127,127,.125);
	border-left: 2px solid #0a89c0;
	margin: 8px 0 24px 0;
	padding: 16px;
}

blockquote p:last-child {
	margin-bottom: 0;
}

/* UI Fonts */

.amp-wp-meta,
.amp-wp-header div,
.amp-wp-title,
.wp-caption-text,
.amp-wp-tax-category,
.amp-wp-tax-tag,
.amp-wp-comments-link,
.amp-wp-footer p,
.back-to-top {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen-Sans", "Ubuntu", "Cantarell", "Helvetica Neue", sans-serif;
}

/* Header */

.amp-wp-header {
	background-color: #0a89c0;
}

.amp-wp-header div {
	color: #fff;
	font-size: 1em;
	font-weight: 400;
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: .875em 16px;
	position: relative;
}

.amp-wp-header a {
	color: #fff;
	text-decoration: none;
}


.amp-wp-header .amp-wp-site-icon {
	/** site icon is 32px **/
	background-color: #fff;
	border: 1px solid #fff;
	border-radius: 50%;
	position: absolute;
	right: 18px;
	top: 10px;
}

/* Article */

.amp-wp-article {
	color: #353535;
	font-weight: 400;
	margin: 1.5em auto;
	max-width: 840px;
	overflow-wrap: break-word;
	word-wrap: break-word;
}

/* Article Header */

.amp-wp-article-header {
	align-items: center;
	align-content: stretch;
	display: flex;
	flex-wrap: wrap;
	justify-content: space-between;
	margin: 1.5em 16px 0;
}

.amp-wp-title {
	color: #353535;
	display: block;
	flex: 1 0 100%;
	font-weight: 900;
	margin: 0 0 .625em;
	width: 100%;
}

/* Article Meta */

.amp-wp-meta {
	color: #696969;
	display: inline-block;
	flex: 2 1 50%;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0 0 1.5em;
	padding: 0;
}

.amp-wp-article-header .amp-wp-meta:last-of-type {
	text-align: right;
}

.amp-wp-article-header .amp-wp-meta:first-of-type {
	text-align: left;
}

.amp-wp-byline amp-img,
.amp-wp-byline .amp-wp-author {
	display: inline-block;
	vertical-align: middle;
}

.amp-wp-byline amp-img {
	border: 1px solid #0a89c0;
	border-radius: 50%;
	position: relative;
	margin-right: 6px;
}

.amp-wp-posted-on {
	text-align: right;
}

/* Featured image */

.amp-wp-article-featured-image {
	margin: 0 0 1em;
}
.amp-wp-article-featured-image amp-img {
	margin: 0 auto;
}
.amp-wp-article-featured-image.wp-caption .wp-caption-text {
	margin: 0 18px;
}

/* Article Content */

.amp-wp-article-content {
	margin: 0 16px;
}

.amp-wp-article-content ul,
.amp-wp-article-content ol {
	margin-left: 1em;
}

.amp-wp-article-content .wp-caption {
	max-width: 100%;
}

.amp-wp-article-content amp-img {
	margin: 0 auto;
}

.amp-wp-article-content amp-img.alignright {
	margin: 0 0 1em 16px;
}

.amp-wp-article-content amp-img.alignleft {
	margin: 0 16px 1em 0;
}

/* Captions */

.wp-caption {
	padding: 0;
}

.wp-caption.alignleft {
	margin-right: 16px;
}

.wp-caption.alignright {
	margin-left: 16px;
}

.wp-caption .wp-caption-text {
	border-bottom: 1px solid #c2c2c2;
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0;
	padding: .66em 10px .75em;
}

/* AMP Media */

.alignwide,
.alignfull {
	clear: both;
}

amp-carousel {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}
amp-iframe,
amp-youtube,
amp-instagram,
amp-vine {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}

.amp-wp-article-content amp-carousel amp-img {
	border: none;
}

amp-carousel > amp-img > img {
	object-fit: contain;
}

.amp-wp-iframe-placeholder {
	background: #c2c2c2 url( https://uzzz.org/wp-content/plugins/amp/assets/images/placeholder-icon.png ) no-repeat center 40%;
	background-size: 48px 48px;
	min-height: 48px;
}

/* Article Footer Meta */

.amp-wp-article-footer .amp-wp-meta {
	display: block;
}

.amp-wp-tax-category,
.amp-wp-tax-tag {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 1.5em 16px;
}

.amp-wp-comments-link {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	text-align: center;
	margin: 2.25em 0 1.5em;
}

.amp-wp-comments-link a {
	border-style: solid;
	border-color: #c2c2c2;
	border-width: 1px 1px 2px;
	border-radius: 4px;
	background-color: transparent;
	color: #0a89c0;
	cursor: pointer;
	display: block;
	font-size: 14px;
	font-weight: 600;
	line-height: 18px;
	margin: 0 auto;
	max-width: 200px;
	padding: 11px 16px;
	text-decoration: none;
	width: 50%;
	-webkit-transition: background-color 0.2s ease;
			transition: background-color 0.2s ease;
}

/* AMP Footer */

.amp-wp-footer {
	border-top: 1px solid #c2c2c2;
	margin: calc(1.5em - 1px) 0 0;
}

.amp-wp-footer div {
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: 1.25em 16px 1.25em;
	position: relative;
}

.amp-wp-footer h2 {
	font-size: 1em;
	line-height: 1.375em;
	margin: 0 0 .5em;
}

.amp-wp-footer p {
	color: #696969;
	font-size: .8em;
	line-height: 1.5em;
	margin: 0 85px 0 0;
}

.amp-wp-footer a {
	text-decoration: none;
}

.back-to-top {
	bottom: 1.275em;
	font-size: .8em;
	font-weight: 600;
	line-height: 2em;
	position: absolute;
	right: 16px;
}
		/* Inline stylesheets */
.htmledit_views{font-family:-apple-system,SF UI Text,Arial,PingFang SC,Hiragino Sans GB,Microsoft YaHei,WenQuanYi Micro Hei,sans-serif,SimHei,SimSun}.htmledit_views a>amp-img{padding:1px;margin:1px;border:none;outline:#0782c1 solid 1px}.htmledit_views p{font-size:16px;color:#4d4d4d;font-weight:400;line-height:26px;margin:0 0 16px;overflow-x:auto}.htmledit_views amp-img{max-width:100%}.htmledit_views *{box-sizing:border-box}.htmledit_views h2{color:#4f4f4f;margin:8px 0 16px;font-weight:700}.htmledit_views h2{font-size:24px;line-height:32px}.htmledit_views a{color:#4ea1db;text-decoration:none}.htmledit_views a:focus,.htmledit_views a:hover{color:#ca0c16}.htmledit_views a:visited{color:#6795b5}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-539b047{text-align:center}	</style>
</head>

<body class="">

<header id="top" class="amp-wp-header">
	<div>
		<a href="https://uzzz.org/">
										<amp-img src="https://uzzz.org/wp-content/uploads/2019/10/cropped-icon-32x32.png" width="32" height="32" class="amp-wp-site-icon"></amp-img>
						<span class="amp-site-title">
				有组织在!			</span>
		</a>

					</div>
</header>

<article class="amp-wp-article">
	<header class="amp-wp-article-header">
		<h1 class="amp-wp-title">深度学习笔记(4)：1.1-1.3 边缘检测(edge detection)</h1>
			<div class="amp-wp-meta amp-wp-byline">
					<amp-img src="https://secure.gravatar.com/avatar/e786821a74ef0467825a7d60183307bc?s=24&d=mm&r=g" alt="fandyvon" width="24" height="24" layout="fixed"></amp-img>
				<span class="amp-wp-author author vcard">fandyvon</span>
	</div>
<div class="amp-wp-meta amp-wp-posted-on">
	<time datetime="2018-09-17T23:19:20+00:00">
		1 year ago	</time>
</div>
	</header>

	
	<div class="amp-wp-article-content">
		<div id="article_content" class="article_content clearfix">
 <br>
 
 
 
<div class="htmledit_views" id="content_views">
<p>第四课开始，我们开始学习卷积神经网络。</p>
<h2>1.1 计算机视觉(computer vision)</h2>
<p>深度学习在计算机视觉方面的应用非常振奋人心，一方面是该应用使许多不可能变成了可能，另一方面是深度学习在计算机视觉方面的应用能够给深度学习在其他方面的应用带来一些方法的改进和思考，比如语音识别等。</p>
<p>计算机视觉包含哪些问题呢？如下图所示：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180917165109285?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tra2traWtv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="860" height="473" layout="intrinsic"><noscript><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180917165109285?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tra2traWtv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="860" height="473"></noscript></amp-img></p>
<p>比如图片分类，判断一个图片是否是猫；或者目标识别，比如在无人驾驶任务中，识别路上其他的车以及距离，以便无人驾驶能够安全执行；还有就是图片风格转化，比如我们有一个美女的照片(是吴老师的妻子，哈哈)和一个毕加索的绘画，把二者融合起来，就可以得到人像的轮廓和毕加索的风格。</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180917165124671?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tra2traWtv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="848" height="470" layout="intrinsic"><noscript><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180917165124671?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tra2traWtv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="848" height="470"></noscript></amp-img></p>
<p>比如在图片分类中，我们使用的图片可能是小图片，比如像素是64*64，加上颜色的三个channel(RGB channels)，该图片作为输入是一个64*64*3=12288维的向量，还好。但若是大图片呢？比如一个像素为1000*1000的图片，那该图片作为输入就是3m(3百万)维的向量，假设第一层隐藏节点有1000个，且在完全连接的情况下，第一层的权重矩阵就是1000*3m维的矩阵，相当于第一层有30亿的权重，这时很难有足够多的样本去训练这么多的权重，容易发生过拟合，同时这么多的权重还会对内存有一定要求，而且我们不想仅限于处理小图片。为了解决衍生出来的这么多问题，我们需要使用卷积运算，见下节。</p>
<h2>1.2 边缘检测例子(edge detection example)</h2>
<p>卷积运算是卷积神经网络最基本的组成部分。这节课我们通过边缘检测例子来学习卷积运算，如下图所示：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180917165213585?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tra2traWtv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="853" height="468" layout="intrinsic"><noscript><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180917165213585?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tra2traWtv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="853" height="468"></noscript></amp-img></p>
<p>在神经网络模型中，前几层神经网络能检测到边界，后几层可能检测到物体小部分，再后面几层可能检测到具体的物体，在这个例子中就是人脸。接下来我们讲如何在图片中识别边界，也就是为何神经网络前几层能够检测到图片中的边界。</p>
<p>假设我们有上图中这样一个照片，我们可以通过垂直边缘检测器和水平边缘检测器分别检测出图片中的垂直和水平边缘，检测器检测出的结果如上图所示。但是这些检测器是如何工作的呢？我们以垂直检测器为例。在介绍垂直检测器之前，我们先介绍一种运算，卷积运算(Convolution operation)，如下图所示：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180917165236939?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tra2traWtv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="856" height="473" layout="intrinsic"><noscript><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180917165236939?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tra2traWtv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="856" height="473"></noscript></amp-img></p>
<p>假设我们的图片如上图左侧矩阵所示，这是一个6*6的矩阵，因为我们没有考虑彩色，这仅仅是一个黑白图片，所以不存在RGB通道，这里图片是6*6*1的向量，接下来我们对其作卷积运算。</p>
<p>首先介绍一下中间的3*3矩阵，我们称之为‘核(kernel)’或‘过滤器(filter)’，中间‘*’号表示卷积运算，这与我们在程序中使用方法不同，一般‘*’在程序中都表示乘法，或者说是element-wise的乘法。</p>
<p>那么卷积运算怎么做呢？我曾在深度学习书中看过这样一种比喻，我觉得比较恰当，在这里跟大家分析一下，想象你是一个探险家，在黑暗中找到一幅画卷，为了仔细看清画卷内容，于是你打开手电筒从画的左上角还是扫描直至画的右下角，过滤器做的就是类似手电筒的工作。计算也非常简单，就是element-wise，首先将filter对应于左上角九宫格，然后按上图中红色式子进行计算，就是对这两个3*3矩阵进行element-wise乘法再求和，我们得到-5，写于右侧矩阵的(1，1)位置，就这样从左到右，从上到下，最终得到一个4*4的矩阵，其中最后(4,4)位置对应的-16是由左侧紫色框内矩阵和filter做卷积计算所得。</p>
<p>了解了卷积运算，接下来我们介绍垂直边缘检测器，如下图所示：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180917165259337?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tra2traWtv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="862" height="472" layout="intrinsic"><noscript><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180917165259337?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tra2traWtv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="862" height="472"></noscript></amp-img></p>
<p>同样是做卷积运算，不过我们在这里对filter做了‘手脚’，使其能够检测出图片中的垂直边界，怎么说呢？</p>
<p>在原图中，也就是左矩阵中，我们用0来表示灰色(或者你认为黑色都可以)，10来表示白色，即数值越大颜色越亮，我们想检测出白色和灰色中间那条边界，怎么做呢？我们使用了一个3*3的filter，它的第一列都为1，第二列为0，第三列为-1，经过卷积运算我们得到了一个4*4的矩阵，中间两列值都为30，两边为0，即我们清晰地找出了边界。</p>
<p>首先为什么能够找出边界，背后的思想我们可以这样认为，边界两侧的数值肯定是有很大差异的，不是边界的数值差异不大，所以kernel这样取值就能使数值差异不大的地方通过卷积运算得出来的值近似为0，而当数值有很大差异时，使用该kernel就无法抵消，这样就可以找出边界，当然这里要注意我们设置kernel的维度要注意原图的维度以及边界的宽度，比如这里最后的出来的边界看起来很宽，那是因为原图太小了，仅仅是6*6，如果是1000*1000，边界效果就会很好了。</p>
<h2>1.3 更多边缘检测内容(more edge detection)</h2>
<p>这小节我们将学习更多边缘检测的内容，比如学会如何区分正边和反边，也就是区分由亮到暗和由暗到亮的区别，如下图所示：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180917223759583?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tra2traWtv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="863" height="478" layout="intrinsic"><noscript><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180917223759583?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tra2traWtv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="863" height="478"></noscript></amp-img></p>
<p>还是之前那个例子，假设我们将图片左右翻转一下，现在左侧是暗的，右侧是亮的，但是我们还使用同一个filter，所以自然会得到一个相反的数值，如上图所示，表示边界的值由30变为-30，这里数值的变化就就能够告知我们一些准确的信息，比如30告诉我们这个边界是正边，即颜色是由亮到暗，而-30就告诉我们这个边界是负边，及颜色是由暗到亮，当然如果你不care正边还是负边可以直接对卷积计算结果取绝对值，即只确定边界并不考虑其颜色是如何变化的。</p>
<p>除了垂直边缘检测，我们还可以进行水平边缘检测，如下图所示：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" src="https://uzshare.com/_p?https://img-blog.csdn.net/2018091722443526?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tra2traWtv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="853" height="474" layout="intrinsic"><noscript><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdn.net/2018091722443526?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tra2traWtv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="853" height="474"></noscript></amp-img></p>
<p>思想很简单，将垂直边缘检测的kernel作转置我们就可以得到水平边缘检测的kernel了。套用在例子中如上图所示，假设我们现在有一个这样的6*6矩阵，其对应图片为左下部和右上部偏暗，显然这个图片既存在水平边缘也存在垂直边缘，现在我们使用水平边缘检测的kernel去检测水平边缘，结果如上图所示，10和-10的出现在这里是因为垂直边缘的影响，同样，因为我们这里举例子的图片太小(6*6)，所以这里显得10和-10占了很大比重，如果我们是1000*1000的图片，结果就可以不考虑10和-10的影响了。</p>
<p>对于kernel中的数值选取，很多学者在文献中公平地讨论过该如何搭配数据才是合理的，如下图所示：</p>
<p class="amp-wp-539b047"><amp-img alt="" class="has amp-wp-enforced-sizes" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180917230212372?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tra2traWtv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="854" height="469" layout="intrinsic"><noscript><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdn.net/20180917230212372?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2tra2traWtv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="854" height="469"></noscript></amp-img></p>
<p>除了第一列都是1，第三列都是-1这种filter，我们还可以对数据做其他改变，比如第二行都乘上2，我们称之为sobel filter，相当于在原来基础上进行了加权，它的优点在于增加了中间一行的权重，也就是处在中间的像素，这样可以增加结果的鲁棒性(robust)，还有另一种filter，将第一行和第三行都乘上3，第二行乘上10，我们称之为scharr filter，这样改变也会改进一些性能。</p>
<p>但实际中，我们一般将这九个值设为九个参数，然后通过神经网络的反向传播去学习，为啥呢么这样做呢？首先是之前的filter过于简单，针对的仅仅是垂直或水平边缘的情况，即90度，且数值是实验前已经设定好的，不一定适合每个问题，而实际问题要复杂得多，比如上图中所示的情况，所以我们希望filter中的数值能够作为参数从数据集中学习而得到，这样一方面是准确，一方面是我们可以应对任何复杂的情况，不论是45度、70度或是73度的边缘我们都可以检测出来。</p>
<p>通过反向传播去学习kernel中的参数已经成为计算机视觉中最有效的思想之一。接下来我们会学习如何使用反向出传播去学习这九个参数，但在此之前，我们会先学习一下有关卷积运算的基础知识，详见下节。</p>
<p> </p>
<p>版权声明：尊重博主原创文章，转载请注明出处<a href="https://blog.csdn.net/kkkkkiko/article/details/81812841" rel="nofollow" data-token="e76b2a0cfcba6f7a120f250c14dcc2a0">https://blog.csdn.net/kkkkkiko/article/details/81812841</a></p>
</div>
</div>
	</div>

	<footer class="amp-wp-article-footer">
			<div class="amp-wp-meta amp-wp-tax-category">
		Categories: <a href="https://uzzz.org/category/deeplearning/" rel="category tag">DeepLearning</a>	</div>

	</footer>
</article>

<footer class="amp-wp-footer">
	<div>
		<h2>有组织在!</h2>
		<a href="#top" class="back-to-top">Back to top</a>
	</div>
</footer>



</body>
</html>
