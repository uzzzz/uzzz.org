<!DOCTYPE html>
<html amp lang="en-US">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1">
	<script type="application/ld+json" class="yoast-schema-graph yoast-schema-graph--main">{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://uzzz.org/#website","url":"https://uzzz.org/","name":"\u6709\u7ec4\u7ec7\u5728!","potentialAction":{"@type":"SearchAction","target":"https://uzzz.org/?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"ImageObject","@id":"https://uzzz.org/article/2970/#primaryimage","url":"https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203095643712.png"},{"@type":"WebPage","@id":"https://uzzz.org/article/2970/#webpage","url":"https://uzzz.org/article/2970/","inLanguage":"en-US","name":"\u4f4e\u7167\u5ea6\u589e\u5f3a\u76f8\u5173\u7b97\u6cd5 - \u6709\u7ec4\u7ec7\u5728!","isPartOf":{"@id":"https://uzzz.org/#website"},"primaryImageOfPage":{"@id":"https://uzzz.org/article/2970/#primaryimage"},"datePublished":"2018-12-03T02:37:25+00:00","dateModified":"2018-12-03T02:37:25+00:00","author":{"@id":"https://uzzz.org/#/schema/person/29673f1347b0abda5882803c72ee5a3f"}},{"@type":["Person"],"@id":"https://uzzz.org/#/schema/person/29673f1347b0abda5882803c72ee5a3f","name":"fandyvon","sameAs":[]}]}</script>
	<title>低照度增强相关算法 - 有组织在!</title>
		<link rel="canonical" href="https://uzzz.org/article/2970/">
	<script type="text/javascript" src="https://cdn.ampproject.org/v0.js" async></script>
<style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>
	<style amp-custom>
		/* Generic WP styling */

.alignright {
	float: right;
}

.alignleft {
	float: left;
}

.aligncenter {
	display: block;
	text-align: center;
	margin-left: auto;
	margin-right: auto;
}

.amp-wp-enforced-sizes {
	/** Our sizes fallback is 100vw, and we have a padding on the container; the max-width here prevents the element from overflowing. **/
	max-width: 100%;
	margin: 0 auto;
}


/*
 * Prevent cases of amp-img converted from img to appear with stretching by using object-fit to scale.
 * See <https://github.com/ampproject/amphtml/issues/21371#issuecomment-475443219>.
 * Also use object-fit:contain in worst case scenario when we can't figure out dimensions for an image.
 * Additionally, in side of \AMP_Img_Sanitizer::determine_dimensions() it could $amp_img->setAttribute( 'object-fit', 'contain' )
 * so that the following rules wouldn't be needed.
 */
amp-img.amp-wp-enforced-sizes[layout="intrinsic"] > img,
amp-anim.amp-wp-enforced-sizes[layout="intrinsic"] > img {
	object-fit: contain;
}

amp-fit-text blockquote,
amp-fit-text h1,
amp-fit-text h2,
amp-fit-text h3,
amp-fit-text h4,
amp-fit-text h5,
amp-fit-text h6 {
	font-size: inherit;
}

/**
 * Override a style rule in Twenty Sixteen and Twenty Seventeen.
 * It set display:none for audio elements.
 * This selector is the same, though it adds body and uses amp-audio instead of audio.
 */
body amp-audio:not([controls]) {
	display: inline-block;
	height: auto;
}

/*
 * Style the default template messages for submit-success, submit-error, and submitting. These elements are inserted
 * by the form sanitizer when a POST form lacks the action-xhr attribute.
 */
.amp-wp-default-form-message > p {
	margin: 1em 0;
	padding: 0.5em;
}

.amp-wp-default-form-message[submitting] > p,
.amp-wp-default-form-message[submit-success] > p.amp-wp-form-redirecting {
	font-style: italic;
}

.amp-wp-default-form-message[submit-success] > p:not(.amp-wp-form-redirecting) {
	border: solid 1px #008000;
	background-color: #90ee90;
	color: #000;
}

.amp-wp-default-form-message[submit-error] > p {
	border: solid 1px #f00;
	background-color: #ffb6c1;
	color: #000;
}

/* Prevent showing empty success message in the case of an AMP-Redirect-To response header. */
.amp-wp-default-form-message[submit-success] > p:empty {
	display: none;
}

amp-carousel .amp-wp-gallery-caption {
	position: absolute;
	bottom: 0;
	left: 0;
	right: 0;
	text-align: center;
	background-color: rgba(0, 0, 0, 0.5);
	color: #fff;
	padding: 1rem;
}

.wp-block-gallery[data-amp-carousel="true"] {
	display: block;
	flex-wrap: unset;
}

/* Template Styles */

.amp-wp-content,
.amp-wp-title-bar div {
		margin: 0 auto;
	max-width: 840px;
	}

html {
	background: #0a89c0;
}

body {
	background: #fff;
	color: #353535;
	font-family: Georgia, 'Times New Roman', Times, Serif;
	font-weight: 300;
	line-height: 1.75em;
}

p,
ol,
ul,
figure {
	margin: 0 0 1em;
	padding: 0;
}

a,
a:visited {
	color: #0a89c0;
}

a:hover,
a:active,
a:focus {
	color: #353535;
}

/* Quotes */

blockquote {
	color: #353535;
	background: rgba(127,127,127,.125);
	border-left: 2px solid #0a89c0;
	margin: 8px 0 24px 0;
	padding: 16px;
}

blockquote p:last-child {
	margin-bottom: 0;
}

/* UI Fonts */

.amp-wp-meta,
.amp-wp-header div,
.amp-wp-title,
.wp-caption-text,
.amp-wp-tax-category,
.amp-wp-tax-tag,
.amp-wp-comments-link,
.amp-wp-footer p,
.back-to-top {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen-Sans", "Ubuntu", "Cantarell", "Helvetica Neue", sans-serif;
}

/* Header */

.amp-wp-header {
	background-color: #0a89c0;
}

.amp-wp-header div {
	color: #fff;
	font-size: 1em;
	font-weight: 400;
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: .875em 16px;
	position: relative;
}

.amp-wp-header a {
	color: #fff;
	text-decoration: none;
}


.amp-wp-header .amp-wp-site-icon {
	/** site icon is 32px **/
	background-color: #fff;
	border: 1px solid #fff;
	border-radius: 50%;
	position: absolute;
	right: 18px;
	top: 10px;
}

/* Article */

.amp-wp-article {
	color: #353535;
	font-weight: 400;
	margin: 1.5em auto;
	max-width: 840px;
	overflow-wrap: break-word;
	word-wrap: break-word;
}

/* Article Header */

.amp-wp-article-header {
	align-items: center;
	align-content: stretch;
	display: flex;
	flex-wrap: wrap;
	justify-content: space-between;
	margin: 1.5em 16px 0;
}

.amp-wp-title {
	color: #353535;
	display: block;
	flex: 1 0 100%;
	font-weight: 900;
	margin: 0 0 .625em;
	width: 100%;
}

/* Article Meta */

.amp-wp-meta {
	color: #696969;
	display: inline-block;
	flex: 2 1 50%;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0 0 1.5em;
	padding: 0;
}

.amp-wp-article-header .amp-wp-meta:last-of-type {
	text-align: right;
}

.amp-wp-article-header .amp-wp-meta:first-of-type {
	text-align: left;
}

.amp-wp-byline amp-img,
.amp-wp-byline .amp-wp-author {
	display: inline-block;
	vertical-align: middle;
}

.amp-wp-byline amp-img {
	border: 1px solid #0a89c0;
	border-radius: 50%;
	position: relative;
	margin-right: 6px;
}

.amp-wp-posted-on {
	text-align: right;
}

/* Featured image */

.amp-wp-article-featured-image {
	margin: 0 0 1em;
}
.amp-wp-article-featured-image amp-img {
	margin: 0 auto;
}
.amp-wp-article-featured-image.wp-caption .wp-caption-text {
	margin: 0 18px;
}

/* Article Content */

.amp-wp-article-content {
	margin: 0 16px;
}

.amp-wp-article-content ul,
.amp-wp-article-content ol {
	margin-left: 1em;
}

.amp-wp-article-content .wp-caption {
	max-width: 100%;
}

.amp-wp-article-content amp-img {
	margin: 0 auto;
}

.amp-wp-article-content amp-img.alignright {
	margin: 0 0 1em 16px;
}

.amp-wp-article-content amp-img.alignleft {
	margin: 0 16px 1em 0;
}

/* Captions */

.wp-caption {
	padding: 0;
}

.wp-caption.alignleft {
	margin-right: 16px;
}

.wp-caption.alignright {
	margin-left: 16px;
}

.wp-caption .wp-caption-text {
	border-bottom: 1px solid #c2c2c2;
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0;
	padding: .66em 10px .75em;
}

/* AMP Media */

.alignwide,
.alignfull {
	clear: both;
}

amp-carousel {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}
amp-iframe,
amp-youtube,
amp-instagram,
amp-vine {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}

.amp-wp-article-content amp-carousel amp-img {
	border: none;
}

amp-carousel > amp-img > img {
	object-fit: contain;
}

.amp-wp-iframe-placeholder {
	background: #c2c2c2 url( https://uzzz.org/wp-content/plugins/amp/assets/images/placeholder-icon.png ) no-repeat center 40%;
	background-size: 48px 48px;
	min-height: 48px;
}

/* Article Footer Meta */

.amp-wp-article-footer .amp-wp-meta {
	display: block;
}

.amp-wp-tax-category,
.amp-wp-tax-tag {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 1.5em 16px;
}

.amp-wp-comments-link {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	text-align: center;
	margin: 2.25em 0 1.5em;
}

.amp-wp-comments-link a {
	border-style: solid;
	border-color: #c2c2c2;
	border-width: 1px 1px 2px;
	border-radius: 4px;
	background-color: transparent;
	color: #0a89c0;
	cursor: pointer;
	display: block;
	font-size: 14px;
	font-weight: 600;
	line-height: 18px;
	margin: 0 auto;
	max-width: 200px;
	padding: 11px 16px;
	text-decoration: none;
	width: 50%;
	-webkit-transition: background-color 0.2s ease;
			transition: background-color 0.2s ease;
}

/* AMP Footer */

.amp-wp-footer {
	border-top: 1px solid #c2c2c2;
	margin: calc(1.5em - 1px) 0 0;
}

.amp-wp-footer div {
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: 1.25em 16px 1.25em;
	position: relative;
}

.amp-wp-footer h2 {
	font-size: 1em;
	line-height: 1.375em;
	margin: 0 0 .5em;
}

.amp-wp-footer p {
	color: #696969;
	font-size: .8em;
	line-height: 1.5em;
	margin: 0 85px 0 0;
}

.amp-wp-footer a {
	text-decoration: none;
}

.back-to-top {
	bottom: 1.275em;
	font-size: .8em;
	font-weight: 600;
	line-height: 2em;
	position: absolute;
	right: 16px;
}
		/* Inline stylesheets */
:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-3d30430{margin-left:0cm}	</style>
</head>

<body class="">

<header id="top" class="amp-wp-header">
	<div>
		<a href="https://uzzz.org/">
										<amp-img src="https://uzzz.org/wp-content/uploads/2019/10/cropped-icon-32x32.png" width="32" height="32" class="amp-wp-site-icon"></amp-img>
						<span class="amp-site-title">
				有组织在!			</span>
		</a>

					</div>
</header>

<article class="amp-wp-article">
	<header class="amp-wp-article-header">
		<h1 class="amp-wp-title">低照度增强相关算法</h1>
			<div class="amp-wp-meta amp-wp-byline">
					<amp-img src="https://secure.gravatar.com/avatar/e786821a74ef0467825a7d60183307bc?s=24&d=mm&r=g" alt="fandyvon" width="24" height="24" layout="fixed"></amp-img>
				<span class="amp-wp-author author vcard">fandyvon</span>
	</div>
<div class="amp-wp-meta amp-wp-posted-on">
	<time datetime="2018-12-03T10:37:25+00:00">
		1 year ago	</time>
</div>
	</header>

	
	<div class="amp-wp-article-content">
		<div id="article_content" class="article_content clearfix">
 <br>
 
 
 
<div class="htmledit_views" id="content_views">
<h1 class="amp-wp-3d30430">低照度增强调研情况</h1>
<p class="amp-wp-3d30430">目前使用的低照度增强方法主要包括四种：基于直方图均衡化的方法（HE）；基于Retinex理论的方法；基于去雾模型的方法以及基于深度学习的方法。这些方法都是基本的方法，对于其他的一些方法大都是基于这些方法进行改进得到的。</p>
<h2 class="amp-wp-3d30430">基于直方图均衡的方法</h2>
<p class="amp-wp-3d30430">直方图均衡化的思想就是将图像的灰度直方图从较为集中的某灰度区间拉伸至全部灰度范围内，用以扩大图像灰度值的范围，提升图像对比度并突出部分细节效果。对于一副图片来说其直方图可以用来表示灰度值的分布。其中如果大部分像素集中在低灰度区间则图片整体较暗，相反则图片较亮。所以我们可以对于灰度分布图采用均衡化的方法将其灰度的分布范围在整个区域平均化，这样就相当于减少了低灰度的像素个数，整个图片就会变亮一些。</p>
<h2 class="amp-wp-3d30430">基于Retinex的方法</h2>
<p class="amp-wp-3d30430">Retinex方法主要是基于人类的视觉系统可以不受光源强度和照射不均匀等不确定因素的干扰而准确感知物体的颜色和亮度这一理论提出的。提出这一理论主要是基于真实世界中物体的颜色由光与物体的相互作用产生的，其本身是无颜色的；构成颜色的基本单元是红、绿、蓝三原色光波、单位区域的颜色由红绿蓝三原色光波决定这几个理论。</p>
<p class="amp-wp-3d30430">根据上述理论，我们可以得出物体的颜色不受反射光强和非均匀光照的影响仅有物体的反射光线决定。基于此，我们假设如下公式：<amp-img alt="" class="has amp-wp-enforced-sizes" height="53" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203095643712.png" width="271" layout="intrinsic"><noscript><img alt="" class="has" height="53" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203095643712.png" width="271"></noscript></amp-img>，其中<amp-img alt="" class="has amp-wp-enforced-sizes" height="33" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203095704886.png" width="72" layout="intrinsic"><noscript><img alt="" class="has" height="33" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203095704886.png" width="72"></noscript></amp-img>表示视觉系统最终的图片（人看到的图片），<amp-img alt="" class="has amp-wp-enforced-sizes" height="25" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203095724141.png" width="78" layout="intrinsic"><noscript><img alt="" class="has" height="25" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203095724141.png" width="78"></noscript></amp-img>表示物体特有的性质称为物体的反射特性，<amp-img alt="" class="has amp-wp-enforced-sizes" height="41" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203095745349.png" width="78" layout="intrinsic"><noscript><img alt="" class="has" height="41" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203095745349.png" width="78"></noscript></amp-img>表示入射光的影响。根据公式我们需要的是，已知的是<amp-img alt="" class="has amp-wp-enforced-sizes" height="36" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2018120309580528.png" width="68" layout="intrinsic"><noscript><img alt="" class="has" height="36" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2018120309580528.png" width="68"></noscript></amp-img>，需要估计的是<amp-img alt="" class="has amp-wp-enforced-sizes" height="44" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203095818846.png" width="83" layout="intrinsic"><noscript><img alt="" class="has" height="44" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203095818846.png" width="83"></noscript></amp-img>。</p>
<p class="amp-wp-3d30430">为了简化计算，我们对上式两边同时取对数（乘除变加减）则可以得到：</p>
<p class="amp-wp-3d30430"><amp-img alt="" class="has amp-wp-enforced-sizes" height="45" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203101714372.png" width="544" layout="intrinsic"><noscript><img alt="" class="has" height="45" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203101714372.png" width="544"></noscript></amp-img></p>
<p class="amp-wp-3d30430">由上式可知，我们只需要估计出<amp-img alt="" class="has amp-wp-enforced-sizes" height="36" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203101736635.png" width="83" layout="intrinsic"><noscript><img alt="" class="has" height="36" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203101736635.png" width="83"></noscript></amp-img>就可以得到对应的<amp-img alt="" class="has amp-wp-enforced-sizes" height="33" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102403276.png" width="78" layout="intrinsic"><noscript><img alt="" class="has" height="33" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102403276.png" width="78"></noscript></amp-img>。对于<amp-img alt="" class="has amp-wp-enforced-sizes" height="42" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102413728.png" width="84" layout="intrinsic"><noscript><img alt="" class="has" height="42" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102413728.png" width="84"></noscript></amp-img>的估计采用高斯卷积函数进行：</p>
<p class="amp-wp-3d30430"><amp-img alt="" class="has amp-wp-enforced-sizes" height="41" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102440254.png" width="279" layout="intrinsic"><noscript><img alt="" class="has" height="41" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102440254.png" width="279"></noscript></amp-img></p>
<p class="amp-wp-3d30430">其中<amp-img alt="" class="has amp-wp-enforced-sizes" height="40" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102450548.png" width="84" layout="intrinsic"><noscript><img alt="" class="has" height="40" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102450548.png" width="84"></noscript></amp-img>表示的是高斯函数，*表示卷积运算。<amp-img alt="" class="has amp-wp-enforced-sizes" height="32" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102504671.png" width="84" layout="intrinsic"><noscript><img alt="" class="has" height="32" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102504671.png" width="84"></noscript></amp-img>的表达式为：</p>
<p class="amp-wp-3d30430"><amp-img alt="" class="has amp-wp-enforced-sizes" height="75" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102514967.png" width="254" layout="intrinsic"><noscript><img alt="" class="has" height="75" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102514967.png" width="254"></noscript></amp-img></p>
<p class="amp-wp-3d30430"><amp-img alt="" class="has amp-wp-enforced-sizes" height="35" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102546505.png" width="28" layout="intrinsic"><noscript><img alt="" class="has" height="35" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102546505.png" width="28"></noscript></amp-img>表示的是一个尺度，<amp-img alt="" class="has amp-wp-enforced-sizes" height="23" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102555682.png" width="29" layout="intrinsic"><noscript><img alt="" class="has" height="23" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102555682.png" width="29"></noscript></amp-img>表示高斯函数的尺度选择，其满足<amp-img alt="" class="has amp-wp-enforced-sizes" height="55" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102605479.png" width="204" layout="intrinsic"><noscript><img alt="" class="has" height="55" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102605479.png" width="204"></noscript></amp-img>。该式中<amp-img alt="" class="has amp-wp-enforced-sizes" height="27" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102618349.png" width="22" layout="intrinsic"><noscript><img alt="" class="has" height="27" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102618349.png" width="22"></noscript></amp-img>是需要求的。因此对于一个彩色通道的图片，其某一通道<amp-img alt="" class="has amp-wp-enforced-sizes" height="20" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102631594.png" width="16" layout="intrinsic"><noscript><img alt="" class="has" height="20" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102631594.png" width="16"></noscript></amp-img>对应的图像变换后为：</p>
<p class="amp-wp-3d30430"><amp-img alt="" class="has amp-wp-enforced-sizes" height="52" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102644939.png" width="536" layout="intrinsic"><noscript><img alt="" class="has" height="52" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102644939.png" width="536"></noscript></amp-img></p>
<p class="amp-wp-3d30430">然后在利用<amp-img alt="" class="has amp-wp-enforced-sizes" height="29" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102704354.png" width="198" layout="intrinsic"><noscript><img alt="" class="has" height="29" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102704354.png" width="198"></noscript></amp-img>就可以求出每一个通道的值。最终就得到了每个通道处理后的值进而得到处理后的图片。</p>
<p class="amp-wp-3d30430">上述方法采用了一个高斯核，因此一般被称为单尺度Retinex方法（SSR）。现在假设整个过程采用了<amp-img alt="" class="has amp-wp-enforced-sizes" height="23" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102729880.png" width="21" layout="intrinsic"><noscript><img alt="" class="has" height="23" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102729880.png" width="21"></noscript></amp-img>个高斯核，则每个<amp-img alt="" class="has amp-wp-enforced-sizes" height="23" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102747483.png" width="17" layout="intrinsic"><noscript><img alt="" class="has" height="23" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102747483.png" width="17"></noscript></amp-img>在评估的时候就会出现<amp-img alt="" class="has amp-wp-enforced-sizes" height="21" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102800168.png" width="16" layout="intrinsic"><noscript><img alt="" class="has" height="21" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102800168.png" width="16"></noscript></amp-img>个不同的值，如果把这些值综合起来就行成了多尺度的Retinex方法（MSR），其具体公式如下：<amp-img alt="" class="has amp-wp-enforced-sizes" height="25" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102815689.png" width="24" layout="intrinsic"><noscript><img alt="" class="has" height="25" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102815689.png" width="24"></noscript></amp-img>表示权重。</p>
<p class="amp-wp-3d30430"><amp-img alt="" class="has amp-wp-enforced-sizes" height="58" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102832467.png" width="255" layout="intrinsic"><noscript><img alt="" class="has" height="58" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102832467.png" width="255"></noscript></amp-img></p>
<p class="amp-wp-3d30430">由于MSR会存在色差，有人提出来在通道上加入调节因子来消除色差，其具体如下：</p>
<p class="amp-wp-3d30430"><amp-img alt="" class="has amp-wp-enforced-sizes" height="47" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102847486.png" width="272" layout="intrinsic"><noscript><img alt="" class="has" height="47" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102847486.png" width="272"></noscript></amp-img></p>
<p class="amp-wp-3d30430"><amp-img alt="" class="has amp-wp-enforced-sizes" height="30" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102857660.png" width="25" layout="intrinsic"><noscript><img alt="" class="has" height="30" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102857660.png" width="25"></noscript></amp-img>表示的是调节因子，其对应的取值方式不同往往会产生不同的效果。现在常用的有基于其各通道的均值 ，方差计算出最小值和最大值，然后用最小值和最大值进行归一化。</p>
<p class="amp-wp-3d30430"><amp-img alt="" class="has amp-wp-enforced-sizes" height="38" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102909296.png" width="309" layout="intrinsic"><noscript><img alt="" class="has" height="38" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102909296.png" width="309"></noscript></amp-img></p>
<p class="amp-wp-3d30430"><amp-img alt="" class="has amp-wp-enforced-sizes" height="176" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102921432.png" width="465" layout="intrinsic"><noscript><img alt="" class="has" height="176" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102921432.png" width="465"></noscript></amp-img></p>
<p class="amp-wp-3d30430"> </p>
<p class="amp-wp-3d30430">其中取值越小，增强效果越明显，一般取2-3最适宜。</p>
<h2 class="amp-wp-3d30430">基于去雾模型的图片增强</h2>
<p class="amp-wp-3d30430">去雾模型一般是针对雾霾或者大雾天气，考虑到空气中的悬浮物导致的图片效果不佳时需要采用的方法。该方法假设：</p>
<p class="amp-wp-3d30430"><amp-img alt="" class="has amp-wp-enforced-sizes" height="43" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/201812031029411.png" width="295" layout="intrinsic"><noscript><img alt="" class="has" height="43" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/201812031029411.png" width="295"></noscript></amp-img></p>
<p class="amp-wp-3d30430">其中<amp-img alt="" class="has amp-wp-enforced-sizes" height="28" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102951322.png" width="49" layout="intrinsic"><noscript><img alt="" class="has" height="28" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203102951322.png" width="49"></noscript></amp-img>表示待去雾的图像，<amp-img alt="" class="has amp-wp-enforced-sizes" height="35" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103106953.png" width="56" layout="intrinsic"><noscript><img alt="" class="has" height="35" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103106953.png" width="56"></noscript></amp-img>表示无雾图像，<amp-img alt="" class="has amp-wp-enforced-sizes" height="24" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103116891.png" width="21" layout="intrinsic"><noscript><img alt="" class="has" height="24" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103116891.png" width="21"></noscript></amp-img>表示全球大气光成分，<amp-img alt="" class="has amp-wp-enforced-sizes" height="19" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103127667.png" width="19" layout="intrinsic"><noscript><img alt="" class="has" height="19" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103127667.png" width="19"></noscript></amp-img>表示折射率（大气传递系数）。在使用过程中<amp-img alt="" class="has amp-wp-enforced-sizes" height="31" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103140379.png" width="49" layout="intrinsic"><noscript><img alt="" class="has" height="31" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103140379.png" width="49"></noscript></amp-img>是要求的，<amp-img alt="" class="has amp-wp-enforced-sizes" height="27" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103151642.png" width="46" layout="intrinsic"><noscript><img alt="" class="has" height="27" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103151642.png" width="46"></noscript></amp-img>为输入的，<amp-img alt="" class="has amp-wp-enforced-sizes" height="22" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103224241.png" width="18" layout="intrinsic"><noscript><img alt="" class="has" height="22" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103224241.png" width="18"></noscript></amp-img>和<amp-img alt="" class="has amp-wp-enforced-sizes" height="19" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103234478.png" width="15" layout="intrinsic"><noscript><img alt="" class="has" height="19" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103234478.png" width="15"></noscript></amp-img>是需要通过暗通道先验来进行估计的。</p>
<p class="amp-wp-3d30430">暗通道先验规律是指每一个图片的局部区域都很有可能有至少一个颜色通道有很低的值。根据这个规律我们定义了暗通道的值如下：</p>
<p class="amp-wp-3d30430"><amp-img alt="" class="has amp-wp-enforced-sizes" height="53" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103249845.png" width="308" layout="intrinsic"><noscript><img alt="" class="has" height="53" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103249845.png" width="308"></noscript></amp-img></p>
<p class="amp-wp-3d30430">通过上式可以看出，求暗通道的值首先是求出通道的最小值。在根据通道最小值求出区域内的最小值。</p>
<p class="amp-wp-3d30430">根据暗通道的值我们可以估计大气折射率：</p>
<p class="amp-wp-3d30430"><amp-img alt="" class="has amp-wp-enforced-sizes" height="69" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103303723.png" width="302" layout="intrinsic"><noscript><img alt="" class="has" height="69" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103303723.png" width="302"></noscript></amp-img></p>
<p class="amp-wp-3d30430">根据暗通道的值估计大气光：</p>
<p class="amp-wp-3d30430">（1）：选取暗通道图像中暗通道最亮的0.1%。</p>
<p class="amp-wp-3d30430">（2）：在取出的位置中，对应到原图找出最高亮度点的值作为大气光。</p>
<p class="amp-wp-3d30430">然后回带到开始的式子中就可以求出对应的去雾图<amp-img alt="" class="has amp-wp-enforced-sizes" height="28" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103322578.png" width="52" layout="intrinsic"><noscript><img alt="" class="has" height="28" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103322578.png" width="52"></noscript></amp-img>：</p>
<p class="amp-wp-3d30430"><amp-img alt="" class="has amp-wp-enforced-sizes" height="79" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2018120310333434.png" width="265" layout="intrinsic"><noscript><img alt="" class="has" height="79" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2018120310333434.png" width="265"></noscript></amp-img></p>
<h2 class="amp-wp-3d30430">基于深度学习</h2>
<p class="amp-wp-3d30430">使用卷积神经网络来进行低照度增强的资料较少，目前只发现了一种方式，并且也没有固定的官方模型，只是一个简单的7层卷积网络，由于图片增强的目的是把亮度低的地方亮度变高，所以该模型要求输出的大小和原来的相同，因此该网络没有池化层。其具体结构如下：</p>
<p class="amp-wp-3d30430"><amp-img alt="" class="has amp-wp-enforced-sizes" height="129" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103352334.png" width="364" layout="intrinsic"><noscript><img alt="" class="has" height="129" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103352334.png" width="364"></noscript></amp-img></p>
<p class="amp-wp-3d30430">上述就是采用的网络结构，由于图片增强的目的只是为了提高亮度，同时并不希望色彩方面的值发生改变而引起不必要的色彩差异。因此本次采用的是将RGB色彩空间转化为HSI空间，然后再对I分量进行卷积处理，最后再转换成RGB空间合成最后的图片。其具体流程如下：</p>
<p class="amp-wp-3d30430"><amp-img alt="" class="has amp-wp-enforced-sizes" height="185" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103407346.png" width="233" layout="intrinsic"><noscript><img alt="" class="has" height="185" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181203103407346.png" width="233"></noscript></amp-img></p>
<h1 class="amp-wp-3d30430">各方法的优劣</h1>
<p class="amp-wp-3d30430">上述方法是最近看到的低照度增强使用较多的方法，其各有优缺。现在将其总结如下：</p>
<p class="amp-wp-3d30430">直方图法可以有效的提高对比度，并且处理速度快。但是容易出现色差并且灰度级的合并会丢失细节信息。</p>
<p class="amp-wp-3d30430">SSR方法假设光照是缓慢变化的，但是真是情况下光照是不平滑的，因此采用这种方法在亮度差异大的区域会产生光晕。</p>
<p class="amp-wp-3d30430">MSR方法能够较好的提高图片的对比度和亮度，但是图片边缘锐化不足，容易出现光晕或者图片泛白。</p>
<p class="amp-wp-3d30430">去雾模型虽然能够在一定程度上提高视觉质量，但是增强后的图像往往不符合场景，因为我们的场景是光线不够导致的图像变暗，而不是由于悬浮物遮挡导致的。</p>
<p class="amp-wp-3d30430">基于深度学习的方法能够避免传统方法的参数调节问题，也能够使色彩更加协调，但是缺乏训练样本，在训练时我们必须要给出同样场景只有照度不同的图片，因此该方法也比较难实现。</p>
<h1 class="amp-wp-3d30430"> </h1>
<p>参考文献</p>
<p>《基于深度卷积神经网络的低照度图像增强》马红强1 ，马时平1，许悦雷1,2，朱明明1；</p>
<p>《基于卷积神经网络的水下图像增强算法研究》 丁雪研</p>
<p> </p>
<p> </p>
</div>
</div>
	</div>

	<footer class="amp-wp-article-footer">
			<div class="amp-wp-meta amp-wp-tax-category">
		Categories: <a href="https://uzzz.org/category/rengongzhineng/" rel="category tag">人工智能</a>	</div>

	</footer>
</article>

<footer class="amp-wp-footer">
	<div>
		<h2>有组织在!</h2>
		<a href="#top" class="back-to-top">Back to top</a>
	</div>
</footer>



</body>
</html>
