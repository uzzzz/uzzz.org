<!DOCTYPE html>
<html amp lang="en-US">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1">
		<title>TensorFlow学习（十）：图像预处理 – 有组织在!</title>
		<link rel="canonical" href="https://uzzz.org/article/3375/">
	<script type="text/javascript" src="https://cdn.ampproject.org/v0.js" async></script>
<style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>	<script type="application/ld+json">{"@context":"http:\/\/schema.org","publisher":{"@type":"Organization","name":"有组织在!","logo":"https:\/\/uzzz.org\/wp-content\/uploads\/2019\/10\/cropped-icon.png"},"@type":"BlogPosting","mainEntityOfPage":"https:\/\/uzzz.org\/article\/3375\/","headline":"TensorFlow学习（十）：图像预处理","datePublished":"2017-05-26T06:47:43+00:00","dateModified":"2017-05-26T06:47:43+00:00","author":{"@type":"Person","name":"fandyvon"}}</script>
	
	<style amp-custom>
		/* Generic WP styling */

.alignright {
	float: right;
}

.alignleft {
	float: left;
}

.aligncenter {
	display: block;
	text-align: center;
	margin-left: auto;
	margin-right: auto;
}

.amp-wp-enforced-sizes {
	/** Our sizes fallback is 100vw, and we have a padding on the container; the max-width here prevents the element from overflowing. **/
	max-width: 100%;
	margin: 0 auto;
}


/*
 * Prevent cases of amp-img converted from img to appear with stretching by using object-fit to scale.
 * See <https://github.com/ampproject/amphtml/issues/21371#issuecomment-475443219>.
 * Also use object-fit:contain in worst case scenario when we can't figure out dimensions for an image.
 * Additionally, in side of \AMP_Img_Sanitizer::determine_dimensions() it could $amp_img->setAttribute( 'object-fit', 'contain' )
 * so that the following rules wouldn't be needed.
 */
amp-img.amp-wp-enforced-sizes[layout="intrinsic"] > img,
amp-anim.amp-wp-enforced-sizes[layout="intrinsic"] > img {
	object-fit: contain;
}

amp-fit-text blockquote,
amp-fit-text h1,
amp-fit-text h2,
amp-fit-text h3,
amp-fit-text h4,
amp-fit-text h5,
amp-fit-text h6 {
	font-size: inherit;
}

/**
 * Override a style rule in Twenty Sixteen and Twenty Seventeen.
 * It set display:none for audio elements.
 * This selector is the same, though it adds body and uses amp-audio instead of audio.
 */
body amp-audio:not([controls]) {
	display: inline-block;
	height: auto;
}

/*
 * Style the default template messages for submit-success, submit-error, and submitting. These elements are inserted
 * by the form sanitizer when a POST form lacks the action-xhr attribute.
 */
.amp-wp-default-form-message > p {
	margin: 1em 0;
	padding: 0.5em;
}

.amp-wp-default-form-message[submitting] > p,
.amp-wp-default-form-message[submit-success] > p.amp-wp-form-redirecting {
	font-style: italic;
}

.amp-wp-default-form-message[submit-success] > p:not(.amp-wp-form-redirecting) {
	border: solid 1px #008000;
	background-color: #90ee90;
	color: #000;
}

.amp-wp-default-form-message[submit-error] > p {
	border: solid 1px #f00;
	background-color: #ffb6c1;
	color: #000;
}

/* Prevent showing empty success message in the case of an AMP-Redirect-To response header. */
.amp-wp-default-form-message[submit-success] > p:empty {
	display: none;
}

amp-carousel .amp-wp-gallery-caption {
	position: absolute;
	bottom: 0;
	left: 0;
	right: 0;
	text-align: center;
	background-color: rgba(0, 0, 0, 0.5);
	color: #fff;
	padding: 1rem;
}

.wp-block-gallery[data-amp-carousel="true"] {
	display: block;
	flex-wrap: unset;
}

/* Template Styles */

.amp-wp-content,
.amp-wp-title-bar div {
		margin: 0 auto;
	max-width: 840px;
	}

html {
	background: #0a89c0;
}

body {
	background: #fff;
	color: #353535;
	font-family: Georgia, 'Times New Roman', Times, Serif;
	font-weight: 300;
	line-height: 1.75em;
}

p,
ol,
ul,
figure {
	margin: 0 0 1em;
	padding: 0;
}

a,
a:visited {
	color: #0a89c0;
}

a:hover,
a:active,
a:focus {
	color: #353535;
}

/* Quotes */

blockquote {
	color: #353535;
	background: rgba(127,127,127,.125);
	border-left: 2px solid #0a89c0;
	margin: 8px 0 24px 0;
	padding: 16px;
}

blockquote p:last-child {
	margin-bottom: 0;
}

/* UI Fonts */

.amp-wp-meta,
.amp-wp-header div,
.amp-wp-title,
.wp-caption-text,
.amp-wp-tax-category,
.amp-wp-tax-tag,
.amp-wp-comments-link,
.amp-wp-footer p,
.back-to-top {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen-Sans", "Ubuntu", "Cantarell", "Helvetica Neue", sans-serif;
}

/* Header */

.amp-wp-header {
	background-color: #0a89c0;
}

.amp-wp-header div {
	color: #fff;
	font-size: 1em;
	font-weight: 400;
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: .875em 16px;
	position: relative;
}

.amp-wp-header a {
	color: #fff;
	text-decoration: none;
}


.amp-wp-header .amp-wp-site-icon {
	/** site icon is 32px **/
	background-color: #fff;
	border: 1px solid #fff;
	border-radius: 50%;
	position: absolute;
	right: 18px;
	top: 10px;
}

/* Article */

.amp-wp-article {
	color: #353535;
	font-weight: 400;
	margin: 1.5em auto;
	max-width: 840px;
	overflow-wrap: break-word;
	word-wrap: break-word;
}

/* Article Header */

.amp-wp-article-header {
	align-items: center;
	align-content: stretch;
	display: flex;
	flex-wrap: wrap;
	justify-content: space-between;
	margin: 1.5em 16px 0;
}

.amp-wp-title {
	color: #353535;
	display: block;
	flex: 1 0 100%;
	font-weight: 900;
	margin: 0 0 .625em;
	width: 100%;
}

/* Article Meta */

.amp-wp-meta {
	color: #696969;
	display: inline-block;
	flex: 2 1 50%;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0 0 1.5em;
	padding: 0;
}

.amp-wp-article-header .amp-wp-meta:last-of-type {
	text-align: right;
}

.amp-wp-article-header .amp-wp-meta:first-of-type {
	text-align: left;
}

.amp-wp-byline amp-img,
.amp-wp-byline .amp-wp-author {
	display: inline-block;
	vertical-align: middle;
}

.amp-wp-byline amp-img {
	border: 1px solid #0a89c0;
	border-radius: 50%;
	position: relative;
	margin-right: 6px;
}

.amp-wp-posted-on {
	text-align: right;
}

/* Featured image */

.amp-wp-article-featured-image {
	margin: 0 0 1em;
}
.amp-wp-article-featured-image amp-img {
	margin: 0 auto;
}
.amp-wp-article-featured-image.wp-caption .wp-caption-text {
	margin: 0 18px;
}

/* Article Content */

.amp-wp-article-content {
	margin: 0 16px;
}

.amp-wp-article-content ul,
.amp-wp-article-content ol {
	margin-left: 1em;
}

.amp-wp-article-content .wp-caption {
	max-width: 100%;
}

.amp-wp-article-content amp-img {
	margin: 0 auto;
}

.amp-wp-article-content amp-img.alignright {
	margin: 0 0 1em 16px;
}

.amp-wp-article-content amp-img.alignleft {
	margin: 0 16px 1em 0;
}

/* Captions */

.wp-caption {
	padding: 0;
}

.wp-caption.alignleft {
	margin-right: 16px;
}

.wp-caption.alignright {
	margin-left: 16px;
}

.wp-caption .wp-caption-text {
	border-bottom: 1px solid #c2c2c2;
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0;
	padding: .66em 10px .75em;
}

/* AMP Media */

.alignwide,
.alignfull {
	clear: both;
}

amp-carousel {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}
amp-iframe,
amp-youtube,
amp-instagram,
amp-vine {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}

.amp-wp-article-content amp-carousel amp-img {
	border: none;
}

amp-carousel > amp-img > img {
	object-fit: contain;
}

.amp-wp-iframe-placeholder {
	background: #c2c2c2 url( https://uzzz.org/wp-content/plugins/amp/assets/images/placeholder-icon.png ) no-repeat center 40%;
	background-size: 48px 48px;
	min-height: 48px;
}

/* Article Footer Meta */

.amp-wp-article-footer .amp-wp-meta {
	display: block;
}

.amp-wp-tax-category,
.amp-wp-tax-tag {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 1.5em 16px;
}

.amp-wp-comments-link {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	text-align: center;
	margin: 2.25em 0 1.5em;
}

.amp-wp-comments-link a {
	border-style: solid;
	border-color: #c2c2c2;
	border-width: 1px 1px 2px;
	border-radius: 4px;
	background-color: transparent;
	color: #0a89c0;
	cursor: pointer;
	display: block;
	font-size: 14px;
	font-weight: 600;
	line-height: 18px;
	margin: 0 auto;
	max-width: 200px;
	padding: 11px 16px;
	text-decoration: none;
	width: 50%;
	-webkit-transition: background-color 0.2s ease;
			transition: background-color 0.2s ease;
}

/* AMP Footer */

.amp-wp-footer {
	border-top: 1px solid #c2c2c2;
	margin: calc(1.5em - 1px) 0 0;
}

.amp-wp-footer div {
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: 1.25em 16px 1.25em;
	position: relative;
}

.amp-wp-footer h2 {
	font-size: 1em;
	line-height: 1.375em;
	margin: 0 0 .5em;
}

.amp-wp-footer p {
	color: #696969;
	font-size: .8em;
	line-height: 1.5em;
	margin: 0 85px 0 0;
}

.amp-wp-footer a {
	text-decoration: none;
}

.back-to-top {
	bottom: 1.275em;
	font-size: .8em;
	font-weight: 600;
	line-height: 2em;
	position: absolute;
	right: 16px;
}
		/* Inline stylesheets */
:root:not(#_):not(#_):not(#_):not(#_):not(#_):not(#_):not(#_) .markdown_views,:root:not(#_):not(#_):not(#_):not(#_):not(#_):not(#_):not(#_):not(#_) .markdown_views blockquote{word-break:break-word}.markdown_views pre>code.hljs{background-color:#f6f8fa}.markdown_views .hljs{display:block;padding:8px}:root:not(#_):not(#_):not(#_):not(#_):not(#_):not(#_):not(#_) .markdown_views .hljs-preprocessor,:root:not(#_):not(#_):not(#_):not(#_):not(#_):not(#_):not(#_) .markdown_views .hljs-preprocessor *,:root:not(#_):not(#_):not(#_):not(#_):not(#_):not(#_):not(#_) .markdown_views .hljs-string{color:#090}:root:not(#_):not(#_):not(#_):not(#_):not(#_):not(#_):not(#_) .markdown_views .hljs{color:#4f4f4f}:root:not(#_):not(#_):not(#_):not(#_):not(#_):not(#_):not(#_) .markdown_views .hljs-preprocessor,:root:not(#_):not(#_):not(#_):not(#_):not(#_):not(#_):not(#_) .markdown_views .hljs-string{color:#090}.markdown_views pre code{display:block;font-size:14px;line-height:22px;overflow-x:auto;white-space:pre;word-wrap:normal;background-color:#f6f8fa;border-radius:4px}@media screen and (-webkit-min-device-pixel-ratio:0){.markdown_views pre code{min-width:94%}}:root:not(#_):not(#_):not(#_):not(#_):not(#_):not(#_):not(#_):not(#_) .markdown_views pre code{padding:0}.markdown_views .prettyprint,.markdown_views pre.prettyprint{margin:0 0 24px;padding:8px 16px 6px 56px;background-color:#f6f8fa;border:none}.prettyprint{position:relative;overflow-y:hidden;overflow-x:auto}.markdown_views.prism-tomorrow-night pre code{background-color:#1d1f21;color:#c5c8c6}.markdown_views.prism-tomorrow-night pre code.hljs *{color:#c5c8c6}.markdown_views.prism-tomorrow-night .prettyprint,.markdown_views.prism-tomorrow-night pre.prettyprint{background-color:#1d1f21}@font-face{font-family:KaTeX_AMS;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_AMS-Regular.e78e28b.woff2") format("woff2"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_AMS-Regular.7f06b4e.woff") format("woff"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_AMS-Regular.aaf4eee.ttf") format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Caligraphic;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Caligraphic-Bold.4ec58be.woff2") format("woff2"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Caligraphic-Bold.1e802ca.woff") format("woff"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Caligraphic-Bold.021dd4d.ttf") format("truetype");font-weight:700;font-style:normal}@font-face{font-family:KaTeX_Caligraphic;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Caligraphic-Regular.7edb53b.woff2") format("woff2"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Caligraphic-Regular.d3b46c3.woff") format("woff"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Caligraphic-Regular.d49f2d5.ttf") format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Fraktur;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Fraktur-Bold.d5b59ec.woff2") format("woff2"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Fraktur-Bold.c4c8cab.woff") format("woff"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Fraktur-Bold.a31e7cb.ttf") format("truetype");font-weight:700;font-style:normal}@font-face{font-family:KaTeX_Fraktur;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Fraktur-Regular.32a5339.woff2") format("woff2"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Fraktur-Regular.b7d9c46.woff") format("woff"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Fraktur-Regular.a48dad4.ttf") format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Main;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Main-Bold.8e1e01c.woff2") format("woff2"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Main-Bold.22086eb.woff") format("woff"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Main-Bold.9ceff51.ttf") format("truetype");font-weight:700;font-style:normal}@font-face{font-family:KaTeX_Main;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Main-BoldItalic.284a17f.woff2") format("woff2"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Main-BoldItalic.4c57dbc.woff") format("woff"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Main-BoldItalic.e8b44b9.ttf") format("truetype");font-weight:700;font-style:italic}@font-face{font-family:KaTeX_Main;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Main-Italic.e533d5a.woff2") format("woff2"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Main-Italic.99be0e1.woff") format("woff"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Main-Italic.29c8639.ttf") format("truetype");font-weight:400;font-style:italic}@font-face{font-family:KaTeX_Main;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Main-Regular.5c734d7.woff2") format("woff2"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Main-Regular.b741441.woff") format("woff"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Main-Regular.5c94aef.ttf") format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Math;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Math-BoldItalic.d747bd1.woff2") format("woff2"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Math-BoldItalic.b13731e.woff") format("woff"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Math-BoldItalic.9a2834a.ttf") format("truetype");font-weight:700;font-style:italic}@font-face{font-family:KaTeX_Math;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Math-Italic.4ad08b8.woff2") format("woff2"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Math-Italic.f030390.woff") format("woff"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Math-Italic.291e76b.ttf") format("truetype");font-weight:400;font-style:italic}@font-face{font-family:KaTeX_SansSerif;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_SansSerif-Bold.6e0830b.woff2") format("woff2"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_SansSerif-Bold.3fb4195.woff") format("woff"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_SansSerif-Bold.7dc027c.ttf") format("truetype");font-weight:700;font-style:normal}@font-face{font-family:KaTeX_SansSerif;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_SansSerif-Italic.fba01c9.woff2") format("woff2"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_SansSerif-Italic.727a9b0.woff") format("woff"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_SansSerif-Italic.4059868.ttf") format("truetype");font-weight:400;font-style:italic}@font-face{font-family:KaTeX_SansSerif;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_SansSerif-Regular.d929cd6.woff2") format("woff2"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_SansSerif-Regular.2555754.woff") format("woff"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_SansSerif-Regular.5c58d16.ttf") format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Script;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Script-Regular.755e249.woff2") format("woff2"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Script-Regular.d524c9a.woff") format("woff"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Script-Regular.d12ea9e.ttf") format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Size1;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Size1-Regular.048c39c.woff2") format("woff2"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Size1-Regular.08b5f00.woff") format("woff"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Size1-Regular.7342d45.ttf") format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Size2;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Size2-Regular.81d6b8d.woff2") format("woff2"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Size2-Regular.af24b0e.woff") format("woff"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Size2-Regular.eb130dc.ttf") format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Size3;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Size3-Regular.b311ca0.woff2") format("woff2"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Size3-Regular.0d89264.woff") format("woff"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Size3-Regular.7e02a40.ttf") format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Size4;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Size4-Regular.6a3255d.woff2") format("woff2"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Size4-Regular.68895bb.woff") format("woff"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Size4-Regular.ad76725.ttf") format("truetype");font-weight:400;font-style:normal}@font-face{font-family:KaTeX_Typewriter;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Typewriter-Regular.6cc31ea.woff2") format("woff2"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Typewriter-Regular.3fe216d.woff") format("woff"),url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/KaTeX_Typewriter-Regular.2570235.ttf") format("truetype");font-weight:400;font-style:normal}@font-face{font-family:Roboto Mono;font-style:normal;font-weight:400;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/RobotoMono-Regular.0b6a547.woff") format("woff")}@font-face{font-family:Roboto Mono;font-style:normal;font-weight:600;src:url("https://csdnimg.cn/release/phoenix/mdeditor/fonts/RobotoMono-Bold.819f3b2.woff") format("woff")}html{-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%}body{margin:0}.markdown_views *{box-sizing:border-box}code,pre{font-family:monospace,monospace;font-size:1em}a{background-color:transparent;-webkit-text-decoration-skip:objects}strong{font-weight:inherit;font-weight:bolder}amp-img{border-style:none}svg:not(:root){overflow:hidden}::-webkit-file-upload-button{-webkit-appearance:button;font:inherit}.markdown_views,body,html{font-family:-apple-system,SF UI Text,Arial,PingFang SC,Hiragino Sans GB,Microsoft YaHei,WenQuanYi Micro Hei,sans-serif}[hidden]{display:none}body,html{color:rgba(0,0,0,.75);font-variant-ligatures:common-ligatures;line-height:1.625;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;tab-size:4;-moz-tab-size:4;-o-tab-size:4}.markdown_views blockquote,.markdown_views p,.markdown_views pre{margin:1.2em 0}.markdown_views code *,.markdown_views pre *{font-size:inherit}.markdown_views blockquote{color:rgba(0,0,0,.5);padding-left:1.5em}.markdown_views code{padding:2px 4px}.markdown_views pre>code{background-color:rgba(0,0,0,.05);display:block;padding:.5em;-webkit-text-size-adjust:none;overflow-x:auto;white-space:pre}.markdown_views amp-img[src*="#pic_center"]{display:block;margin:auto}.markdown_views p{font-size:16px;color:#4d4d4d;font-weight:400;line-height:26px;margin:0 0 16px}.markdown_views strong{font-weight:700}em{font-style:italic}.markdown_views h2,.markdown_views h3{color:#4f4f4f;margin:8px 0 16px;font-weight:700}.markdown_views amp-img{margin:24px 0;max-width:100%}.markdown_views h2{font-size:24px;line-height:32px}.markdown_views h3{font-size:22px;line-height:30px}.markdown_views h2 code{font-size:24px}.markdown_views h3 code{font-size:22px}.markdown_views blockquote{display:block;padding:16px;margin:0 0 24px;border-left:8px solid #dddfe4;background:#eef0f4;overflow:auto}.markdown_views blockquote p{font-size:14px;line-height:22px;color:#999;font-weight:400;margin-bottom:0}.markdown_views pre{margin-bottom:24px}.markdown_views pre code{color:unset}.markdown_views code,.markdown_views pre{font-family:Source Code Pro,DejaVu Sans Mono,Ubuntu Mono,Anonymous Pro,Droid Sans Mono,Menlo,Monaco,Consolas,Inconsolata,Courier,monospace,PingFang SC,Microsoft YaHei,sans-serif;font-size:14px;line-height:22px;color:#000}.markdown_views code{color:#c7254e;background-color:#f9f2f4;border-radius:2px}.markdown_views a{text-decoration-skip:ink;color:#4ea1db;text-decoration:none}.markdown_views a:focus,.markdown_views a:hover{text-decoration:none;color:#ca0c16}.markdown_views a:visited{color:#6795b5}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-224b51a{display:none}:root:not(#_):not(#_):not(#_):not(#_):not(#_) .amp-wp-7874ad7{-webkit-tap-highlight-color:rgba(0,0,0,0)}	</style>
</head>

<body class="">

<header id="top" class="amp-wp-header">
	<div>
		<a href="https://uzzz.org/">
										<amp-img src="https://uzzz.org/wp-content/uploads/2019/10/cropped-icon-32x32.png" width="32" height="32" class="amp-wp-site-icon"></amp-img>
						<span class="amp-site-title">
				有组织在!			</span>
		</a>

					</div>
</header>

<article class="amp-wp-article">
	<header class="amp-wp-article-header">
		<h1 class="amp-wp-title">TensorFlow学习（十）：图像预处理</h1>
			<div class="amp-wp-meta amp-wp-byline">
					<amp-img src="https://secure.gravatar.com/avatar/e786821a74ef0467825a7d60183307bc?s=24&d=mm&r=g" alt="fandyvon" width="24" height="24" layout="fixed"></amp-img>
				<span class="amp-wp-author author vcard">fandyvon</span>
	</div>
<div class="amp-wp-meta amp-wp-posted-on">
	<time datetime="2017-05-26T14:47:43+00:00">
		3 years ago	</time>
</div>
	</header>

	
	<div class="amp-wp-article-content">
		<div id="article_content" class="article_content clearfix">
 <br>
 
 
<div id="content_views" class="markdown_views prism-tomorrow-night">
  <br>
  <svg xmlns="http://www.w3.org/2000/svg" class="amp-wp-224b51a">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" class="amp-wp-7874ad7"></path>
  </svg> 
<p>更新时间：</p>
<blockquote>
<p>2018.6.2 <br> 增加了通过 <code>tf.image</code> 进行<strong>数据增强</strong>的内容，非常重要，可以直接跳到第四节。</p>
</blockquote>
<p>之前做的一些任务都是从.csv文件里面读取数据来处理，这些元素都已经是处理好的值了，所以很方便。但是更多时候，我们是要从硬盘上的图片直接来做处理，所以，这里需要用到一些基本的图像处理有关的函数了。OpenCV肯定是可以使用的，但是tensorflow本身也提供了一些好用的函数。 <br> 因为通过Tensorflow完成图像有关的任务太多了，所以了解一点Tensorflow中自带的图像处理有关的函数是很有必要的。 <br> Tensorflow中内置的图像处理的函数肯定没有OpenCV那么多那么强大啦，但是仅仅是作为简单的预处理的话，完全是够用了。</p>
<p>主要使用的模块就是tf.image，所以首先要是先把官方文档列出来：<a href="https://www.tensorflow.org/api_docs/python/tf/image" rel="nofollow" data-token="d92800352c79556307cb8cbbf2361955">Module: tf.image</a>，然后接下来就是按照图片处理的顺序来分别讲解各个函数的使用。 <br> 本节的完整测试代码，可以在我的GitHub：<a href="https://github.com/XierHacker/LearningTensorFlow/tree/master/12.ImageProcess" rel="nofollow" data-token="fcf86075962995c59460a184a5ac9400"><strong>LearningTensorFlow/12.ImageProcess/</strong></a>上找到。</p>
<h2 id="一图像的编解码">一.图像的编解码</h2>
<h3 id="ⅰ概览">Ⅰ.概览</h3>
<p>下面是tensorflow自带编解码部分的函数，这里一起列出来，但是并不会全部都详细讲，因为使用方式大同小异，在例子中只是详细讲其中一个，其他的都可以类比或者看文档写出来，实在是很简单，就不需要多花笔墨。</p>
<blockquote>
<p>decode_gif(…): Decode the first frame of a GIF-encoded image to a uint8 tensor. <br> decode_jpeg(…): Decode a JPEG-encoded image to a uint8 tensor. <br> decode_png(…): Decode a PNG-encoded image to a uint8 or uint16 tensor. <br> decode_image(…): Convenience function for decode_gif, decode_jpeg, and decode_png. <br> encode_jpeg(…): JPEG-encode an image. <br> encode_png(…): PNG-encode an image.</p>
</blockquote>
<p>在这一步，要是只是想把某个或者某些个文件读到ndarray中去，推荐更加高效的做法，就是使用matplot.image中的imread（）方法，或者opencv中的方法，都是很简单无脑的。 <br> 比如在这里，我文件夹下面有个叫做“1.jpg”的文件，那么就可以用比较简单的方法得到： <br> <amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170525172350900?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGllcmhhY2tlcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title="" width="762" height="531" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170525172350900?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGllcmhhY2tlcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title="" width="762" height="531" class=""></noscript></amp-img></p>
<h2 id="二数据转化和形状变换">二.数据转化和形状变换</h2>
<p>这一步的目的是什么呢？首先，很多图像像素默认是int类型的，在tensorflow里面，float类型的数据更加适合处理，然后形状来说，我们知道，对于图片来说，一个网络的输入尺寸是固定的，而训练的时候图片的尺寸确不一定是固定的，所以有必要用各种方式把图片尺寸转换为固定的适合网络输入的格式。</p>
<h3 id="ⅰ数据类型转化">Ⅰ.数据类型转化</h3>
<p><strong><em>convert_image_dtype(image,dtype,saturate=False,name=None)</em></strong></p>
<blockquote>
<p>作用：把图片元素类型，转成想要的类型，<strong>返回转换后的图片,注意，要是转成了float类型之后，像素值会在 [0,1)这个范围内</strong>。 <br> 参数: <br> <strong>image:</strong> 图像 <br> <strong>dtype:</strong> 待转换类型 <br> <strong>saturate:</strong> If True, clip the input before casting (if necessary). <br> <strong>name:</strong> 可选操作名</p>
</blockquote>
<pre class="prettyprint"><code class=" hljs avrasm">with graph<span class="hljs-preprocessor">.as</span>_default():
    <span class="hljs-preprocessor">#convert type</span>
    pic=tf<span class="hljs-preprocessor">.image</span><span class="hljs-preprocessor">.convert</span>_image_dtype(image=pic,dtype=tf<span class="hljs-preprocessor">.float</span>32)
with session<span class="hljs-preprocessor">.as</span>_default():
    pic_run=session<span class="hljs-preprocessor">.run</span>(pic)
    print(<span class="hljs-string">"type of pic:"</span>,pic_run<span class="hljs-preprocessor">.dtype</span>)
    print(pic_run)
    plt<span class="hljs-preprocessor">.imshow</span>(pic_run)</code></pre>
<p>结果： <br> <amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170525174221410?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGllcmhhY2tlcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title="" width="622" height="1103" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170525174221410?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGllcmhhY2tlcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title="" width="622" height="1103" class=""></noscript></amp-img></p>
<h3 id="ⅱ形状变换">Ⅱ.形状变换</h3>
<p><strong><em>resize_images(images,size,method=ResizeMethod.BILINEAR,align_corners=False)</em></strong></p>
<blockquote>
<p>作用:使用指定的方法来改变形状 <br> 参数: <br> <strong>images:</strong> 4维tensor,形状为 [batch, height, width, channels] 或者3维tensor,形状为 [height, width, channels]. <br> <strong>size:</strong> 1维 int32类型的 Tensor,包含两个元素:new_height, new_width. <br> <strong>method:</strong> 改变形状的方法,默认是<code>ResizeMethod.BILINEAR</code>.</p>
<blockquote>
<p><strong>ResizeMethod.BILINEAR:</strong> 双线性插值(Bilinear interpolation.) <br> <strong>ResizeMethod.NEAREST_NEIGHBOR:</strong> 最近邻插值(Nearest neighbor interpolation.) <br> <strong>ResizeMethod.BICUBIC:</strong> 双三次插值(Bicubic interpolation.) <br> <strong>ResizeMethod.AREA:</strong> 面积插值(Area interpolation.)</p>
</blockquote>
<p><strong>align_corners:</strong> bool. If true, exactly align all 4 corners of the input and output. Defaults to false.</p>
</blockquote>
<p>还有其他类似的函数带有剪裁和形状改变的功能,,如</p>
<blockquote>
<p><strong>resize_image_with_crop_or_pad(…)</strong>: Crops and/or pads an image to a target width and height. <br> <strong>central_crop(…):</strong> Crop the central region of the image. <br> <strong>crop_and_resize(…):</strong> Extracts crops from the input image tensor and bilinearly resizes them (possibly <br> <strong>crop_to_bounding_box(…):</strong> Crops an image to a specified bounding box.</p>
</blockquote>
<p>因为使用上面差不多,所以就不一个个详细介绍了,可以看文档,选择合适的方法来使用.</p>
<h3 id="ⅲ图像翻转"><strong>Ⅲ.图像翻转</strong></h3>
<p>上面介绍了尺寸的问题,然后就是翻转的问题了.为什么要翻转呢?以这幅图为例: <br> <amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170526141030728?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGllcmhhY2tlcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title="" width="1239" height="1242" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170526141030728?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGllcmhhY2tlcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title="" width="1239" height="1242" class=""></noscript></amp-img> <br> 神经网络其实是很”笨”的,要是你提供的图片都是像上面那样朝向左边,那么当出现一幅朝向右边的图片的时候,它很可能无法识别. <br> 所以,可以人为的多加一些翻转上去,使得各个角度的图片都有一点,无形中,扩充了数据量,还缓解了识别错误的问题. <br> 翻转有一些常见的函数,</p>
<blockquote>
<p><strong>flip_left_right(…):</strong> 左右翻转 <br> <strong>flip_up_down(…):</strong> 上下翻转 <br> <strong>transpose_image(…):</strong> 对角线翻转 <br> <strong>random_flip_left_right(…):</strong> 随机左右翻转 <br> <strong>random_flip_up_down(…):</strong> 随机上下翻转</p>
</blockquote>
<p>同样,使用方法都是差不多的,这里值以第一个为例子,其他的类比使用就行了. <br> <strong><em>flip_left_right(image)</em></strong></p>
<blockquote>
<p>作用:左右翻转一幅图片,返回一个形状和原图片相同的图片(翻转后) <br> 参数: <br> <strong>image:</strong> 3维tensor,形状为[height, width, channels].</p>
</blockquote>
<p><amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170526142536008?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGllcmhhY2tlcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title="" width="743" height="465" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170526142536008?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGllcmhhY2tlcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title="" width="743" height="465" class=""></noscript></amp-img></p>
<h2 id="三颜色变换">三.颜色变换</h2>
<p>和前面使用翻转可以来”增加数据集”以外,调节颜色属性也是同样很有用的方法,这里主要有调整亮度,对比度,饱和度,色调等方法.如下: <br> 亮度:</p>
<blockquote>
<p>adjust_brightness(…): 调整亮度 <br> random_brightness(…): 随机调整亮度</p>
</blockquote>
<p>对比度:</p>
<blockquote>
<p>adjust_contrast(…): 调整对比度 <br> random_contrast(…): 随机调整亮度</p>
</blockquote>
<p>饱和度:</p>
<blockquote>
<p>adjust_saturation(…): 调整饱和度 <br> random_saturation(…): 随机调整饱和度</p>
</blockquote>
<p>色调:</p>
<blockquote>
<p>adjust_hue(…): 调整色调 <br> random_hue(…): 随机调整色调</p>
</blockquote>
<p>这里只举一个调节亮度的例子,其他大同小异,可以试一下看结果 <br> <strong><em>adjust_brightness(image,delta)</em></strong></p>
<blockquote>
<p>作用:调节亮度 <br> 参数: <br> <strong>image:</strong> tensor,原图片 <br> <strong>delta:</strong> 标量,待加到像素值上面的值. </p>
</blockquote>
<p><amp-img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170526144402056?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGllcmhhY2tlcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title="" width="747" height="451" class="amp-wp-enforced-sizes" layout="intrinsic"><noscript><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20170526144402056?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQveGllcmhhY2tlcg==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="这里写图片描述" title="" width="747" height="451" class=""></noscript></amp-img></p>
<h2 id="四数据增强相关">四.数据增强相关</h2>
<p>数据增强的作用就不多说了，tensorflow的数据预处理部分也给出了一些数据增强的方法，表面上看上去也许只是普通的图片变换，但是这些方法在一方面来说能够非常有效的扩充“数据集”。 <br> 这几个方法就是tf.image里面带有random的一些方法。也就是随机怎样怎样，上面其实已经列国了，这里再列出来一遍,大家可以根据需要来选择可能用到的.</p>
<blockquote>
<p><strong>random_brightness(…)</strong>: Adjust the brightness of images by a random factor.</p>
<p><strong>random_contrast(…)</strong>: Adjust the contrast of an image by a random factor.</p>
<p><strong>random_flip_left_right(…)</strong>: Randomly flip an image horizontally (left to right).</p>
<p><strong>random_flip_up_down(…):</strong> Randomly flips an image vertically (upside down).</p>
<p><strong>random_hue(…):</strong> Adjust the hue of an RGB image by a random factor.</p>
<p><strong>random_saturation(…):</strong> Adjust the saturation of an RGB image by a random factor.</p>
</blockquote>
<p>本节只详细介绍三个非常有用的的函数，两个是翻转图像的，分别是<code>random_flip_left_right(...)</code> 和 <code>random_flip_up_down(...)</code> 看名字就知道是左右翻转和上下翻转，还有一个是<code>tf.image.sample_distorted_bounding_box</code> 是随机截取图像。</p>
<p><strong>tf.image.sample_distorted_bounding_box(image_size,bounding_boxes,seed=Noneseed2=None,min_object_covered=0.1,aspect_ratio_range=None,area_range=None,max_attempts=None,use_image_if_no_bounding_boxes=None,name=None)</strong></p>
<p>Generate a single randomly distorted bounding box for an image.</p>
<p>Bounding box annotations are often supplied in addition to ground-truth labels in image recognition or object localization tasks. A common technique for training such a system is to randomly distort an image while preserving its content, i.e. data augmentation. This Op outputs a randomly distorted localization of an object, i.e. bounding box, given an image_size, bounding_boxes and a series of constraints.</p>
<p>The output of this Op is a single bounding box that may be used to crop the original image. The output is returned as 3 tensors: begin, size and bboxes. The first 2 tensors can be fed directly into tf.slice to crop the image. The latter may be supplied to tf.image.draw_bounding_boxes to visualize what the bounding box looks like.</p>
<p>Bounding boxes are supplied and returned as [y_min, x_min, y_max, x_max]. The bounding box coordinates are floats in [0.0, 1.0] relative to the width and height of the underlying image.</p>
<p>For example,</p>
<pre><code># Generate a single distorted bounding box.
begin, size, bbox_for_draw = tf.image.sample_distorted_bounding_box(
    tf.shape(image),
    bounding_boxes=bounding_boxes,
    min_object_covered=0.1)

# Draw the bounding box in an image summary.
image_with_box = tf.image.draw_bounding_boxes(tf.expand_dims(image, 0),
                                              bbox_for_draw)
tf.summary.image('images_with_box', image_with_box)

# Employ the bounding box to distort the image.
distorted_image = tf.slice(image, begin, size)
</code></pre>
<p>Note that if no bounding box information is available, setting use_image_if_no_bounding_boxes = true will assume there is a single implicit bounding box covering the whole image. If use_image_if_no_bounding_boxes is false and no bounding boxes are supplied, an error is raised.</p>
<p>Args: <br> image_size: A Tensor. Must be one of the following types: uint8, int8, int16, int32, int64. 1-D, containing [height, width, channels]. <br> bounding_boxes: A Tensor of type float32. 3-D with shape [batch, N, 4] describing the N bounding boxes associated with the image. <br> seed: An optional int. Defaults to 0. If either seed or seed2 are set to non-zero, the random number generator is seeded by the given seed. Otherwise, it is seeded by a random seed. <br> seed2: An optional int. Defaults to 0. A second seed to avoid seed collision. <br> min_object_covered: A Tensor of type float32. Defaults to 0.1. The cropped area of the image must contain at least this fraction of any bounding box supplied. The value of this parameter should be non-negative. In the case of 0, the cropped area does not need to overlap any of the bounding boxes supplied. <br> aspect_ratio_range: An optional list of floats. Defaults to [0.75, 1.33]. The cropped area of the image must have an aspect ratio = width / height within this range. <br> area_range: An optional list of floats. Defaults to [0.05, 1]. The cropped area of the image must contain a fraction of the supplied image within in this range. <br> max_attempts: An optional int. Defaults to 100. Number of attempts at generating a cropped region of the image of the specified constraints. After max_attempts failures, return the entire image. <br> use_image_if_no_bounding_boxes: An optional bool. Defaults to False. Controls behavior if no bounding boxes supplied. If true, assume an implicit bounding box covering the whole input. If false, raise an error. <br> name: A name for the operation (optional). <br> Returns: <br> A tuple of Tensor objects (begin, size, bboxes).</p>
<p>begin: A Tensor. Has the same type as image_size. 1-D, containing [offset_height, offset_width, 0]. Provide as input to tf.slice. <br> size: A Tensor. Has the same type as image_size. 1-D, containing [target_height, target_width, -1]. Provide as input to tf.slice. <br> bboxes: A Tensor of type float32. 3-D with shape [1, 1, 4] containing the distorted bounding box. Provide as input to tf.image.draw_bounding_boxes.</p>
</div>

</div>
	</div>

	<footer class="amp-wp-article-footer">
			<div class="amp-wp-meta amp-wp-tax-category">
		Categories: <a href="https://uzzz.org/category/deeplearning/" rel="category tag">DeepLearning</a>	</div>

	<div class="amp-wp-meta amp-wp-tax-tag">
		Tags: <a href="https://uzzz.org/tag/tensorflow/" rel="tag">tensorflow</a>, <a href="https://uzzz.org/tag/tuxiang/" rel="tag">图像</a>	</div>
	</footer>
</article>

<footer class="amp-wp-footer">
	<div>
		<h2>有组织在!</h2>
		<a href="#top" class="back-to-top">Back to top</a>
	</div>
</footer>



</body>
</html>
