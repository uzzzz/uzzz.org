<!DOCTYPE html>
<html amp lang="en-US">
<head>
	<meta charset="utf-8">
	<meta name="viewport" content="width=device-width,initial-scale=1,minimum-scale=1">
	<script type="application/ld+json" class="yoast-schema-graph yoast-schema-graph--main">{"@context":"https://schema.org","@graph":[{"@type":"WebSite","@id":"https://uzzz.org/#website","url":"https://uzzz.org/","name":"\u6709\u7ec4\u7ec7\u5728!","potentialAction":{"@type":"SearchAction","target":"https://uzzz.org/?s={search_term_string}","query-input":"required name=search_term_string"}},{"@type":"WebPage","@id":"https://uzzz.org/article/1698/#webpage","url":"https://uzzz.org/article/1698/","inLanguage":"en-US","name":"\u81ea\u5236AI\u56fe\u50cf\u641c\u7d22\u5f15\u64ce[\u7b14\u8bb0] - \u6709\u7ec4\u7ec7\u5728!","isPartOf":{"@id":"https://uzzz.org/#website"},"datePublished":"2019-03-06T05:00:22+00:00","dateModified":"2019-03-06T05:00:22+00:00","author":{"@id":"https://uzzz.org/#/schema/person/29673f1347b0abda5882803c72ee5a3f"}},{"@type":["Person"],"@id":"https://uzzz.org/#/schema/person/29673f1347b0abda5882803c72ee5a3f","name":"fandyvon","sameAs":[]}]}</script>
	<title>自制AI图像搜索引擎[笔记] - 有组织在!</title>
		<link rel="canonical" href="https://uzzz.org/article/1698/">
	<script type="text/javascript" src="https://cdn.ampproject.org/v0.js" async></script>
<style amp-boilerplate>body{-webkit-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-moz-animation:-amp-start 8s steps(1,end) 0s 1 normal both;-ms-animation:-amp-start 8s steps(1,end) 0s 1 normal both;animation:-amp-start 8s steps(1,end) 0s 1 normal both}@-webkit-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-moz-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-ms-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@-o-keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}@keyframes -amp-start{from{visibility:hidden}to{visibility:visible}}</style><noscript><style amp-boilerplate>body{-webkit-animation:none;-moz-animation:none;-ms-animation:none;animation:none}</style></noscript>
	<style amp-custom>
		/* Generic WP styling */

.alignright {
	float: right;
}

.alignleft {
	float: left;
}

.aligncenter {
	display: block;
	text-align: center;
	margin-left: auto;
	margin-right: auto;
}

.amp-wp-enforced-sizes {
	/** Our sizes fallback is 100vw, and we have a padding on the container; the max-width here prevents the element from overflowing. **/
	max-width: 100%;
	margin: 0 auto;
}


/*
 * Prevent cases of amp-img converted from img to appear with stretching by using object-fit to scale.
 * See <https://github.com/ampproject/amphtml/issues/21371#issuecomment-475443219>.
 * Also use object-fit:contain in worst case scenario when we can't figure out dimensions for an image.
 * Additionally, in side of \AMP_Img_Sanitizer::determine_dimensions() it could $amp_img->setAttribute( 'object-fit', 'contain' )
 * so that the following rules wouldn't be needed.
 */
amp-img.amp-wp-enforced-sizes[layout="intrinsic"] > img,
amp-anim.amp-wp-enforced-sizes[layout="intrinsic"] > img {
	object-fit: contain;
}

amp-fit-text blockquote,
amp-fit-text h1,
amp-fit-text h2,
amp-fit-text h3,
amp-fit-text h4,
amp-fit-text h5,
amp-fit-text h6 {
	font-size: inherit;
}

/**
 * Override a style rule in Twenty Sixteen and Twenty Seventeen.
 * It set display:none for audio elements.
 * This selector is the same, though it adds body and uses amp-audio instead of audio.
 */
body amp-audio:not([controls]) {
	display: inline-block;
	height: auto;
}

/*
 * Style the default template messages for submit-success, submit-error, and submitting. These elements are inserted
 * by the form sanitizer when a POST form lacks the action-xhr attribute.
 */
.amp-wp-default-form-message > p {
	margin: 1em 0;
	padding: 0.5em;
}

.amp-wp-default-form-message[submitting] > p,
.amp-wp-default-form-message[submit-success] > p.amp-wp-form-redirecting {
	font-style: italic;
}

.amp-wp-default-form-message[submit-success] > p:not(.amp-wp-form-redirecting) {
	border: solid 1px #008000;
	background-color: #90ee90;
	color: #000;
}

.amp-wp-default-form-message[submit-error] > p {
	border: solid 1px #f00;
	background-color: #ffb6c1;
	color: #000;
}

/* Prevent showing empty success message in the case of an AMP-Redirect-To response header. */
.amp-wp-default-form-message[submit-success] > p:empty {
	display: none;
}

amp-carousel .amp-wp-gallery-caption {
	position: absolute;
	bottom: 0;
	left: 0;
	right: 0;
	text-align: center;
	background-color: rgba(0, 0, 0, 0.5);
	color: #fff;
	padding: 1rem;
}

.wp-block-gallery[data-amp-carousel="true"] {
	display: block;
	flex-wrap: unset;
}

/* Template Styles */

.amp-wp-content,
.amp-wp-title-bar div {
		margin: 0 auto;
	max-width: 840px;
	}

html {
	background: #0a89c0;
}

body {
	background: #fff;
	color: #353535;
	font-family: Georgia, 'Times New Roman', Times, Serif;
	font-weight: 300;
	line-height: 1.75em;
}

p,
ol,
ul,
figure {
	margin: 0 0 1em;
	padding: 0;
}

a,
a:visited {
	color: #0a89c0;
}

a:hover,
a:active,
a:focus {
	color: #353535;
}

/* Quotes */

blockquote {
	color: #353535;
	background: rgba(127,127,127,.125);
	border-left: 2px solid #0a89c0;
	margin: 8px 0 24px 0;
	padding: 16px;
}

blockquote p:last-child {
	margin-bottom: 0;
}

/* UI Fonts */

.amp-wp-meta,
.amp-wp-header div,
.amp-wp-title,
.wp-caption-text,
.amp-wp-tax-category,
.amp-wp-tax-tag,
.amp-wp-comments-link,
.amp-wp-footer p,
.back-to-top {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", "Roboto", "Oxygen-Sans", "Ubuntu", "Cantarell", "Helvetica Neue", sans-serif;
}

/* Header */

.amp-wp-header {
	background-color: #0a89c0;
}

.amp-wp-header div {
	color: #fff;
	font-size: 1em;
	font-weight: 400;
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: .875em 16px;
	position: relative;
}

.amp-wp-header a {
	color: #fff;
	text-decoration: none;
}


.amp-wp-header .amp-wp-site-icon {
	/** site icon is 32px **/
	background-color: #fff;
	border: 1px solid #fff;
	border-radius: 50%;
	position: absolute;
	right: 18px;
	top: 10px;
}

/* Article */

.amp-wp-article {
	color: #353535;
	font-weight: 400;
	margin: 1.5em auto;
	max-width: 840px;
	overflow-wrap: break-word;
	word-wrap: break-word;
}

/* Article Header */

.amp-wp-article-header {
	align-items: center;
	align-content: stretch;
	display: flex;
	flex-wrap: wrap;
	justify-content: space-between;
	margin: 1.5em 16px 0;
}

.amp-wp-title {
	color: #353535;
	display: block;
	flex: 1 0 100%;
	font-weight: 900;
	margin: 0 0 .625em;
	width: 100%;
}

/* Article Meta */

.amp-wp-meta {
	color: #696969;
	display: inline-block;
	flex: 2 1 50%;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0 0 1.5em;
	padding: 0;
}

.amp-wp-article-header .amp-wp-meta:last-of-type {
	text-align: right;
}

.amp-wp-article-header .amp-wp-meta:first-of-type {
	text-align: left;
}

.amp-wp-byline amp-img,
.amp-wp-byline .amp-wp-author {
	display: inline-block;
	vertical-align: middle;
}

.amp-wp-byline amp-img {
	border: 1px solid #0a89c0;
	border-radius: 50%;
	position: relative;
	margin-right: 6px;
}

.amp-wp-posted-on {
	text-align: right;
}

/* Featured image */

.amp-wp-article-featured-image {
	margin: 0 0 1em;
}
.amp-wp-article-featured-image amp-img {
	margin: 0 auto;
}
.amp-wp-article-featured-image.wp-caption .wp-caption-text {
	margin: 0 18px;
}

/* Article Content */

.amp-wp-article-content {
	margin: 0 16px;
}

.amp-wp-article-content ul,
.amp-wp-article-content ol {
	margin-left: 1em;
}

.amp-wp-article-content .wp-caption {
	max-width: 100%;
}

.amp-wp-article-content amp-img {
	margin: 0 auto;
}

.amp-wp-article-content amp-img.alignright {
	margin: 0 0 1em 16px;
}

.amp-wp-article-content amp-img.alignleft {
	margin: 0 16px 1em 0;
}

/* Captions */

.wp-caption {
	padding: 0;
}

.wp-caption.alignleft {
	margin-right: 16px;
}

.wp-caption.alignright {
	margin-left: 16px;
}

.wp-caption .wp-caption-text {
	border-bottom: 1px solid #c2c2c2;
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 0;
	padding: .66em 10px .75em;
}

/* AMP Media */

.alignwide,
.alignfull {
	clear: both;
}

amp-carousel {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}
amp-iframe,
amp-youtube,
amp-instagram,
amp-vine {
	background: #c2c2c2;
	margin: 0 -16px 1.5em;
}

.amp-wp-article-content amp-carousel amp-img {
	border: none;
}

amp-carousel > amp-img > img {
	object-fit: contain;
}

.amp-wp-iframe-placeholder {
	background: #c2c2c2 url( https://uzzz.org/wp-content/plugins/amp/assets/images/placeholder-icon.png ) no-repeat center 40%;
	background-size: 48px 48px;
	min-height: 48px;
}

/* Article Footer Meta */

.amp-wp-article-footer .amp-wp-meta {
	display: block;
}

.amp-wp-tax-category,
.amp-wp-tax-tag {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	margin: 1.5em 16px;
}

.amp-wp-comments-link {
	color: #696969;
	font-size: .875em;
	line-height: 1.5em;
	text-align: center;
	margin: 2.25em 0 1.5em;
}

.amp-wp-comments-link a {
	border-style: solid;
	border-color: #c2c2c2;
	border-width: 1px 1px 2px;
	border-radius: 4px;
	background-color: transparent;
	color: #0a89c0;
	cursor: pointer;
	display: block;
	font-size: 14px;
	font-weight: 600;
	line-height: 18px;
	margin: 0 auto;
	max-width: 200px;
	padding: 11px 16px;
	text-decoration: none;
	width: 50%;
	-webkit-transition: background-color 0.2s ease;
			transition: background-color 0.2s ease;
}

/* AMP Footer */

.amp-wp-footer {
	border-top: 1px solid #c2c2c2;
	margin: calc(1.5em - 1px) 0 0;
}

.amp-wp-footer div {
	margin: 0 auto;
	max-width: calc(840px - 32px);
	padding: 1.25em 16px 1.25em;
	position: relative;
}

.amp-wp-footer h2 {
	font-size: 1em;
	line-height: 1.375em;
	margin: 0 0 .5em;
}

.amp-wp-footer p {
	color: #696969;
	font-size: .8em;
	line-height: 1.5em;
	margin: 0 85px 0 0;
}

.amp-wp-footer a {
	text-decoration: none;
}

.back-to-top {
	bottom: 1.275em;
	font-size: .8em;
	font-weight: 600;
	line-height: 2em;
	position: absolute;
	right: 16px;
}
		/* Inline stylesheets */
.htmledit_views{font-family:-apple-system,SF UI Text,Arial,PingFang SC,Hiragino Sans GB,Microsoft YaHei,WenQuanYi Micro Hei,sans-serif,SimHei,SimSun}.htmledit_views p{font-size:16px;color:#4d4d4d;font-weight:400;line-height:26px;margin:0 0 16px;overflow-x:auto}.htmledit_views *{box-sizing:border-box}.htmledit_views h1,.htmledit_views h2{color:#4f4f4f;margin:8px 0 16px;font-weight:700}.htmledit_views h1{font-size:28px;line-height:36px}.htmledit_views h2{font-size:24px;line-height:32px}.htmledit_views blockquote{display:block;padding:16px 16px 0;margin:0 0 24px;border-left:8px solid #dddfe4;background:#eef0f4;overflow:auto;overflow-scrolling:touch;word-wrap:normal;word-break:normal}.htmledit_views blockquote p{font-size:16px;line-height:26px;font-weight:400;margin-bottom:16px;color:#4f4f4f}.htmledit_views table tr{border:0;border-top:1px solid #ddd;background-color:#fff}.htmledit_views table{border-collapse:collapse;display:table;width:100%;text-align:left;margin-bottom:24px;margin-left:auto;margin-right:auto}.htmledit_views tbody{border:0}.htmledit_views table tr:nth-child(2n){background-color:#f7f7f7}.htmledit_views table tr td,.htmledit_views table tr th{border:1px solid #ddd;font-size:14px;color:#4f4f4f;line-height:22px;padding:8px;text-align:left}.htmledit_views table tr td p,.htmledit_views table tr th p{font-size:14px;color:#4f4f4f;margin:0;padding:0;text-align:left;line-height:22px}.htmledit_views table tr th p{font-weight:700}.htmledit_views table tr td code,.htmledit_views table tr th code{white-space:normal;word-break:break-word}.htmledit_views table tr th{font-weight:700;background-color:#eff3f5}.htmledit_views pre{white-space:pre-wrap;word-wrap:break-word;margin:0 0 24px;overflow-x:auto;padding:8px}.htmledit_views pre{font-family:Consolas,Inconsolata,Courier,monospace;font-size:14px;line-height:22px;color:#000}.htmledit_views pre code,.htmledit_views pre code div{font-family:"Source Code Pro","DejaVu Sans Mono","Ubuntu Mono","Anonymous Pro","Droid Sans Mono",Menlo,Monaco,Consolas,Inconsolata,Courier,monospace,"PingFang SC","Microsoft YaHei",sans-serif}.htmledit_views code{border-radius:4px}.htmledit_views a{color:#4ea1db;text-decoration:none}.htmledit_views a:focus,.htmledit_views a:hover{color:#ca0c16}.htmledit_views a:visited{color:#6795b5}.htmledit_views pre code{display:block;line-height:22px;overflow-x:auto;white-space:pre;word-wrap:normal;border-radius:4px;padding:8px}.htmledit_views pre code:not(.hljs){background-color:#f3f4f5}.htmledit_views pre code,.htmledit_views pre code div{font-size:14px}	</style>
</head>

<body class="">

<header id="top" class="amp-wp-header">
	<div>
		<a href="https://uzzz.org/">
										<amp-img src="https://uzzz.org/wp-content/uploads/2019/10/cropped-icon-32x32.png" width="32" height="32" class="amp-wp-site-icon"></amp-img>
						<span class="amp-site-title">
				有组织在!			</span>
		</a>

					</div>
</header>

<article class="amp-wp-article">
	<header class="amp-wp-article-header">
		<h1 class="amp-wp-title">自制AI图像搜索引擎[笔记]</h1>
			<div class="amp-wp-meta amp-wp-byline">
					<amp-img src="https://secure.gravatar.com/avatar/e786821a74ef0467825a7d60183307bc?s=24&d=mm&r=g" alt="fandyvon" width="24" height="24" layout="fixed"></amp-img>
				<span class="amp-wp-author author vcard">fandyvon</span>
	</div>
<div class="amp-wp-meta amp-wp-posted-on">
	<time datetime="2019-03-06T13:00:22+00:00">
		1 year ago	</time>
</div>
	</header>

	
	<div class="amp-wp-article-content">
		<div id="article_content" class="article_content clearfix">
 
 
<div class="htmledit_views" id="content_views">
<p>一些资料：</p>
<p>谷歌搜索关键字：Deep learning web image search engine  github</p>
<blockquote>
<p><a href="https://github.com/pratheeksh" rel="nofollow" data-token="7ac77ab3a388e081cbe7167a07707f80">pratheeksh</a>/<a href="https://github.com/pratheeksh/Deep-Image-Search-Engine" rel="nofollow" data-token="be42ee3a4057c98e1daeaee4583e67d2">Deep-Image-Search-Engine</a></p>
<p><a href="https://github.com/pratheeksh/Deep-Image-Search-Engine" rel="nofollow" data-token="be42ee3a4057c98e1daeaee4583e67d2">https://github.com/pratheeksh/Deep-Image-Search-Engine</a></p>
<p>来自于课程：NYU Courant课程</p>
<p><a href="https://cs.nyu.edu/courses/spring17/CSCI-GA.3033-006/" rel="nofollow" data-token="585d502ca2e85a32fc223e4dad142583">https://cs.nyu.edu/courses/spring17/CSCI-GA.3033-006/</a></p>
</blockquote>
<blockquote>
<p><a href="https://github.com/sethuiyer/Image-to-Image-search" rel="nofollow" data-token="306f7a0966e399ff75d1f9e29d0b816f">https://github.com/sethuiyer/Image-to-Image-search</a> </p>
</blockquote>
<blockquote>
<p><a href="https://github.com/matsui528/sis" rel="nofollow" data-token="9367295c64cb9499e445c5b4a2e4be1b">https://github.com/matsui528/sis</a> </p>
</blockquote>
<blockquote>
<p><a href="https://github.com/sVujke/img_classification_deep_learning" rel="nofollow" data-token="e2281b82f5ea7898a43840b6a850fabd">https://github.com/sVujke/img_classification_deep_learning</a> </p>
</blockquote>
<blockquote>
<p><a href="https://github.com/paucarre/tiefvision" rel="nofollow" data-token="aa24ad3060ffa6f3792028a94869e133">https://github.com/paucarre/tiefvision</a> </p>
</blockquote>
<p>今天看到一个书本推送，挺有意思，图搜</p>
<p>就是以图搜图</p>
<p>《自制AI图像搜索引擎》<a href="https://www.dushu.com/author/%E6%98%8E%E6%81%92%E6%AF%85/" rel="nofollow" data-token="a4a3c004b01819e3c3ec77fd42d24ec9">明恒毅</a> 著</p>
<blockquote>
<p>图像搜索引擎有两种实现方式—基于图像上下文文本特征的方式和基于图像视觉内容特征的方式。本书所指的图像搜索引擎是基于内容特征的图像检索，也就是通常所说的“以图搜图”来检索相似图片。本书主要讲解了搜索引擎技术的发展脉络、文本搜索引擎的基本原理和搜索引擎的一般结构，详细讲述了图像搜索引擎各主要组成部分的原理和实现，并构建了一个基于深度学习的Web图像搜索引擎。</p>
</blockquote>
<pre class="has">
<code>第 1章 从文本搜索到图像搜索 1 
1．1　文本搜索引擎的发展　1 
1．2　文本搜索引擎的结构与实现　2 
1．2．1　文本预处理　3 
1．2．2　建立索引　5 
1．2．3　对索引进行搜索　7 
1．3　搜索引擎的一般结构　10 
1．4　从文本到图像　10 
1．5　现有图像搜索引擎介绍　12 
1．5．1　Google图像搜索引擎　12 
1．5．2　百度图像搜索引擎　13 
1．5．3　TinEye图像搜索引擎　14 
1．5．4　淘宝图像搜索引擎　15 
1．6　本章小结　16 
第　2章 传统图像特征提取　17 
2．1　人类怎样获取和理解一幅图像　17 
2．2　计算机怎样获取和表示一幅图像　18 
2．2．1　采样　18 
2．2．2　量化　19 
2．2．3　数字图像的存储　19 
2．2．4　常用的位图格式　20 
2．2．5　色彩空间　20 
2．2．6　图像基本操作　21 
2．3　图像特征的分类　29 
2．4　全局特征　30 
2．4．1　颜色特征　30 
2．4．2　纹理特征　41 
2．4．3　形状特征　67 
2．5　局部特征　82 
2．5．1　SIFT描述符　82 
2．5．2　SURF描述符　86 
2．6　本章小结　88 
第3章　深度学习图像特征提取　89 
3．1　深度学习　89 
3．1．1　神经网络的发展　89 
3．1．2　深度神经网络的突破　92 
3．1．3　主要的深度神经网络模型　95 
3．2　深度学习应用框架　97 
3．2．1　TensorFlow　97 
3．2．2　Torch　98 
3．2．3　Caffe　98 
3．2．4　Theano　98 
3．2．5　Keras　99 
3．2．6　DeepLearning4J　99 
3．3　卷积神经网络　99 
3．3．1　卷积　99 
3．3．2　卷积神经网络概述　103 
3．3．3　经典卷积神经网络结构　110 
3．3．4　使用卷积神经网络提取图像特征　130 
3．3．5　使用迁移学习和微调技术进一步提升提取特征的精度　134 
3．4　本章小结　141 
第4章　图像特征索引与检索　142 
4．1　图像特征降维　142 
4．1．1　主成分分析算法降维　142 
4．1．2　深度自动编码器降维　150 
4．2　图像特征标准化　153 
4．2．1　离差标准化　153 
4．2．2　标准差标准化　153 
4．3　图像特征相似度的度量　154 
4．3．1　欧氏距离　154 
4．3．2　曼哈顿距离　155 
4．3．3　海明距离　155 
4．3．4　余弦相似度　155 
4．3．5　杰卡德相似度　156 
4．4　图像特征索引与检索　157 
4．4．1　从最近邻（NN）到K最近邻（KNN）　157 
4．4．2　索引构建与检索　158 
4．5　本章小结　173 
第5章　构建一个基于深度学习的Web图像搜索引擎　174 
5．1　架构分析与技术路线　174 
5．1．1　架构分析　174 
5．1．2　技术路线　175 
5．2　程序实现　175 
5．2．1　开发环境搭建　175 
5．2．2　项目实现　176 
5．3　优化策略　204 
5．4　本章小结　205</code></pre>
<p>这个书的最后，会提供一个例子，基于web+java+深度学习的图搜Demo</p>
<p>这里我也找了一些图搜的工程：</p>
<h1>图像搜索引擎</h1>
<p><a href="https://blog.csdn.net/real_myth/article/details/45576319" rel="nofollow" data-token="20da4bab60998386429ebf424e6bab20">https://blog.csdn.net/real_myth/article/details/45576319</a></p>
<p>他是转载自维基百科：</p>
<p><a href="https://en.wikipedia.org/w/index.php?title=List_of_CBIR_engines&oldid=661221480" rel="nofollow" data-token="3007f4a1316a52d129627e6a72c06bb6">https://en.wikipedia.org/w/index.php?title=List_of_CBIR_engines&oldid=661221480</a></p>
<h2>CBIR research projects/demos/open source projects</h2>
<table>
<thead>
<tr>
<th>Name</th>
<th>Description</th>
<th>External Image Query</th>
<th>Metadata Query</th>
<th>Index Size (Estimate, Millions of Images)</th>
<th>Organization Type</th>
<th>License (Open/Closed)</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="http://www.akiwi.eu/" rel="nofollow" data-token="425fdc7a2ee754a22eda512947b4263f">akiwi</a></td>
<td>akiwi is a semi-automatic image keywording tool using CBIR techniques. It was developed by HTW Berlin / pixolution GmbH</td>
<td>Yes</td>
<td>Yes</td>
<td>15M</td>
<td>University</td>
<td>Closed</td>
</tr>
<tr>
<td><a href="http://www.alipr.com/" rel="nofollow" data-token="04722f93b4386fea1f33bc519129919c">ALIPR</a></td>
<td>Developed by Penn State University researchers</td>
<td>Yes</td>
<td>Yes</td>
<td> </td>
<td>University</td>
<td>Closed</td>
</tr>
<tr>
<td><a href="http://www.anaktisi.net/" rel="nofollow" data-token="8ea879c48a5eda660d7b456e6363ae05">Anaktisi</a></td>
<td>This Web-Solution implements a new family of CBIR descriptors. These descriptors combine in one histogram color and texture information and are suitable for accurately retrieving images.</td>
<td>Yes</td>
<td>No</td>
<td>0.225M</td>
<td>University</td>
<td>Open</td>
</tr>
<tr>
<td><a href="http://brisc.sourceforge.net/" rel="nofollow" data-token="70a85d78bf4e47c266d2223a80ecdeca">BRISC</a></td>
<td>BRISC is a recursive acronym for BRISC Really IS Cool, and is (conveniently enough) also an anagram of Content-Based Image Retrieval System.</td>
<td>Yes</td>
<td>No</td>
<td> </td>
<td>University</td>
<td>GPL</td>
</tr>
<tr>
<td><a href="https://en.wikipedia.org/wiki/DigiKam" rel="nofollow" data-token="849b04fb54e365bd5cac0b139ec75ca7">digiKam</a></td>
<td>Extensive photo management application build on top of <a href="https://en.wikipedia.org/wiki/KDE" rel="nofollow" data-token="3af8d8191a2ecc58644d4e2b0ffc9dfc">KDE</a> libraries. It provides, besides many other features, reverse searches for images in the local collection, detection of duplicates and a fuzzy search by drawings.</td>
<td>Yes</td>
<td>Yes</td>
<td>Desktop-based</td>
<td>KDE</td>
<td><a href="https://en.wikipedia.org/wiki/GPL" rel="nofollow" data-token="74ea22d398366aa8bd8a1fbd7df3e922">GPL</a></td>
</tr>
<tr>
<td><a href="http://www.semanticmetadata.net/features/" rel="nofollow" data-token="e97e5c9d805c4c545563d8fd5c365260">Caliph & Emir</a></td>
<td>Creation and Retrieval of images based on MPEG-7.</td>
<td>Yes</td>
<td>No</td>
<td>Desktop-based</td>
<td>University</td>
<td><a href="https://en.wikipedia.org/wiki/GPL" rel="nofollow" data-token="74ea22d398366aa8bd8a1fbd7df3e922">GPL</a></td>
</tr>
<tr>
<td><a href="http://thomas.deselaers.de/fire/" rel="nofollow" data-token="73d97a4540ade4d46eaf06c4cbc8403f">FIRE</a></td>
<td>Open source query by visual example CBIR system. Developed at RWTH Aachen University. <a href="http://thomas.deselaers.de/FIRE" rel="nofollow" data-token="4d713bbed343a99fb3dd63b56ac41227">FIRE</a> is a research system developed with extensibility in mind and can easily be combined with textual information retrieval systems.</td>
<td>No</td>
<td>No</td>
<td> </td>
<td>University</td>
<td>Open</td>
</tr>
<tr>
<td><a href="http://www.gnu.org/software/gift/" rel="nofollow" data-token="abcc5d5b0b27131e60257c1793d9046a">GNU Image Finding Tool</a></td>
<td>Query by example image search system.</td>
<td>Yes</td>
<td>No</td>
<td>Desktop-based</td>
<td>GNU</td>
<td><a href="https://en.wikipedia.org/wiki/GPL" rel="nofollow" data-token="74ea22d398366aa8bd8a1fbd7df3e922">GPL</a></td>
</tr>
<tr>
<td><a href="http://imense.com/similarsearch/desktop" rel="nofollow" data-token="25793563d109bb5155171b01127a43c9">ISSBP</a></td>
<td>Similar Image Search by Imense plugin for Adobe Bridge, free beta.</td>
<td>Yes</td>
<td>Yes</td>
<td>free-beta limited to 4k images</td>
<td>Private Company</td>
<td>Closed</td>
</tr>
<tr>
<td><a href="http://www.img-rummager.com/" rel="nofollow" data-token="7166ddee61cebaddfcf634d09cf235e4">img(Rummager)</a></td>
<td>Image retrieval Engine (Freeware Application).</td>
<td>Yes</td>
<td>No</td>
<td>Desktop-based</td>
<td>Individual</td>
<td>Closed</td>
</tr>
<tr>
<td><a href="http://server.imgseek.net/" rel="nofollow" data-token="dd0605da1fa97412cdf864d3eb3ce2bd">imgSeek</a></td>
<td>photo collection manager and viewer with content-based search and many other features.</td>
<td>Yes</td>
<td>No</td>
<td> </td>
<td>Individual</td>
<td><a href="https://en.wikipedia.org/wiki/GPL" rel="nofollow" data-token="74ea22d398366aa8bd8a1fbd7df3e922">GPL</a></td>
</tr>
<tr>
<td><a href="https://www.rocq.inria.fr/cgi-bin/imedia/circario.cgi/demos" rel="nofollow" data-token="aef02ca65702c6fa9f5ec9835929bb96">IKONA</a></td>
<td>Generic CBIR system – INRIA – IMEDIA</td>
<td>Yes</td>
<td>Yes</td>
<td> </td>
<td>University</td>
<td>Closed</td>
</tr>
<tr>
<td><a href="http://www.iosb.fraunhofer.de/servlet/is/28046/" rel="nofollow" data-token="8139111a03ec84729fb63fec7d089e92">IOSB</a></td>
<td>Image retrieval demonstration software of Fraunhofer IOSB (Germany)</td>
<td>Yes</td>
<td>No</td>
<td>Desktop-based</td>
<td>Research Institute</td>
<td>Closed</td>
</tr>
<tr>
<td><a href="http://www.lire-project.net/" rel="nofollow" data-token="175ea9f368ced018119074a3ea4180e3">LIRE</a></td>
<td>Java GPL library for content based image retrieval based on Lucene including multiple low level global and local features and different indexing strategies including bag of visual words and hashing.</td>
<td>Yes</td>
<td>Yes</td>
<td> </td>
<td>University</td>
<td>GPL</td>
</tr>
<tr>
<td><a href="http://lucignolo.isti.cnr.it/" rel="nofollow" data-token="02c5fb9b1f9cc66753fc3717fb8a53f4">Lucignolo</a></td>
<td>Image similarity search engine using only the native full-text search engine Lucene.</td>
<td>Yes</td>
<td>Yes</td>
<td>106M</td>
<td>Research Institute</td>
<td>Closed</td>
</tr>
<tr>
<td><a href="http://mi-file.isti.cnr.it/CophirSearch/" rel="nofollow" data-token="b37ef931e39b4fa2d9ca4d83ce53ed02">MIFile</a></td>
<td>Image similarity search engine based on MI File (Metric Inverted File) developed at ISTI-CNR. <a href="http://code.google.com/p/mi-file/" rel="nofollow" data-token="d981a99dc98d35464d8b2cf0f02f1dbe">Source code</a> of the MI File.</td>
<td>No</td>
<td>No</td>
<td>106M</td>
<td>Research Institute</td>
<td>Open</td>
</tr>
<tr>
<td><a href="http://muvis.cs.tut.fi/" rel="nofollow" data-token="8f9ee60a71a00860cddb4578bd1bc9dd">MUVIS</a></td>
<td>CBIR System at TUT- Tampere University of Technology.</td>
<td>Yes</td>
<td>No</td>
<td>Desktop-based</td>
<td>University</td>
<td>Closed</td>
</tr>
<tr>
<td><a href="http://www.pastec.io/" rel="nofollow" data-token="1a4b1332b996da295aa4b637c6995fd1">Pastec</a></td>
<td>C++ LGPL index and search engine for near-duplicate image retrieval that uses bag of visual words with ORB features.</td>
<td>Yes</td>
<td>Yes</td>
<td> </td>
<td>Private company</td>
<td>LGPL</td>
</tr>
<tr>
<td><a href="http://www.kalisteo.org/en/index.htm" rel="nofollow" data-token="727b97f3f3d33b4b0d068d7ec6d8801a">PIRIA</a></td>
<td>CBIR tool developed at CEA-LIST, LVIC (Vision and Content Engineering Laboratory).</td>
<td>Yes</td>
<td>Yes</td>
<td>130M</td>
<td>University</td>
<td>Closed</td>
</tr>
<tr>
<td><a href="http://www.picslikethat.com/" rel="nofollow" data-token="cfc461979fcca942c06527da554e5480">PicsLikeThat</a></td>
<td>Image search using visual similarity search and sorting combined with a recommender system. (Cooperation of pixolution GmbH, fotolia and HTW Berlin)</td>
<td>No</td>
<td>No</td>
<td>12M</td>
<td>University</td>
<td>Closed</td>
</tr>
<tr>
<td><a href="http://inperc.com/wiki/index.php?title=Pixcavator_image_search" rel="nofollow" data-token="41acbfa499ccb70ac55811d3098ff773">Pixcavator</a></td>
<td>Similar image search based on topological image analysis</td>
<td>Yes</td>
<td>No</td>
<td>Desktop-based</td>
<td>Private company</td>
<td>Closed</td>
</tr>
<tr>
<td><a href="http://projects.ivl.disco.unimib.it/quicklook/" rel="nofollow" data-token="933129ad22806719ed1548ababf524cd">QuickLook</a></td>
<td>Visual information retrieval system with relevance feedback</td>
<td>No</td>
<td>Yes</td>
<td> </td>
<td>University</td>
<td>Closed</td>
</tr>
<tr>
<td><a href="http://retin.ensea.fr/" rel="nofollow" data-token="eec561e19704e5e11ae44b1909042934">RETIN</a></td>
<td>Interactive images retrieval system – CNRS – ETIS Lab., MIDI Team</td>
<td>No</td>
<td>No</td>
<td> </td>
<td>University</td>
<td>Closed</td>
</tr>
<tr>
<td><a href="http://labs.systemone.at/retrievr/" rel="nofollow" data-token="ebdefbcc1e15c473c3e40b3bf14e9059">Retrievr</a></td>
<td>Search and explore in a selection of Flickr images by drawing a rough sketch or uploading an image.</td>
<td>No</td>
<td>No</td>
<td> </td>
<td>University</td>
<td>Closed</td>
</tr>
<tr>
<td><a href="http://simba.informatik.uni-freiburg.de/" rel="nofollow" data-token="9310fd7a5f2a1914351ef7be900d6ed3">SIMBA</a></td>
<td>demo of system by the Albert-Ludwigs-Universitet Freiburg (Germany) Inst. for Pattern Recognition and Image Processing</td>
<td>Yes</td>
<td>No</td>
<td>0.002M</td>
<td>University</td>
<td>Closed</td>
</tr>
<tr>
<td><a href="http://pascal.inrialpes.fr/local/tagprop/" rel="nofollow" data-token="6d4a91504918cbf4df5db37279987ae8">TagProp</a></td>
<td>The demonstration of image annotation tool TagProp in ICCV2009 for image set: Corel 5k ESP Game IAPR TC-12 and MIR Flickr.</td>
<td>No</td>
<td>Yes</td>
<td> </td>
<td>Institute</td>
<td>Closed</td>
</tr>
<tr>
<td><a href="http://viral.image.ntua.gr/" rel="nofollow" data-token="2422601de19eb2e37a130d9d556fbaee">VIRaL</a></td>
<td>Visual Image Retrieval and Localization: A visual search engine that, given a query image, retrieves photos depicting the same object or scene under varying viewpoint or lighting conditions. Using Flickr photos of urban scenes, it automatically estimates where a picture is taken, suggests tags, identifies known landmarks or points of interest, and links to relevant Wikipedia articles. It currently supports 39 cities around the world.</td>
<td>Yes</td>
<td>Yes</td>
<td>2.221M</td>
<td>University</td>
<td>Closed</td>
</tr>
<tr>
<td><a href="http://www-db.deis.unibo.it/Windsurf/" rel="nofollow" data-token="8e74eb14f3561d5e18c719b762b8ca30">Windsurf</a></td>
<td>A general framework for efficiently processing content-based image queries with particular emphasis to the region-based paradigm; it provides an environment where different alternatives of the paradigm can be implemented, allowing such implementations to be compared on a fair basis, from the points of view of both effectiveness and efficiency.</td>
<td>Yes</td>
<td>No</td>
<td> </td>
<td>University</td>
<td>Open but not free</td>
</tr>
<tr>
<td><a href="http://www-db.deis.unibo.it/PIBE/" rel="nofollow" data-token="e799eccb6a8c24b70597b80f1d0059e3">PIBE</a></td>
<td>An adaptive image browsing system that provides users with an intuitive, easy-to-use, structured view of an image collection and complements it with ideas from the field of adaptable content-based similarity search. A hierarchical view of images (the Browsing Tree) that can be customized according to user preferences is provided.</td>
<td>Yes</td>
<td>No</td>
<td> </td>
<td>University</td>
<td>Closed</td>
</tr>
<tr>
<td><a href="http://www-db.deis.unibo.it/Shiatsu/" rel="nofollow" data-token="a5782ab757508d3359f740992b1ed2a8">SHIATSU</a></td>
<td>A novel system for automatic video tagging which is based on shot boundaries detection and hierarchical annotation processes. The tagging phase assigns semantic concepts to both shot sequences and whole videos, by exploiting visual features extracted from key frames.</td>
<td>Yes</td>
<td>Yes</td>
<td> </td>
<td>University</td>
<td>Closed</td>
</tr>
</tbody>
</table></div>
</div>
	</div>

	<footer class="amp-wp-article-footer">
			<div class="amp-wp-meta amp-wp-tax-category">
		Categories: Uncategorized	</div>

	</footer>
</article>

<footer class="amp-wp-footer">
	<div>
		<h2>有组织在!</h2>
		<a href="#top" class="back-to-top">Back to top</a>
	</div>
</footer>



</body>
</html>
