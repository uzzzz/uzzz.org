<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>opencv &#8211; 有组织在!</title>
	<atom:link href="https://uzzz.org/tag/opencv/feed" rel="self" type="application/rss+xml" />
	<link>https://uzzz.org/</link>
	<description></description>
	<lastBuildDate>Mon, 24 Sep 2018 02:17:34 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.2.4</generator>

<image>
	<url>https://uzzz.org/wp-content/uploads/2019/10/cropped-icon-32x32.png</url>
	<title>opencv &#8211; 有组织在!</title>
	<link>https://uzzz.org/</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>关于opencv更改摄像头参数（帧率，分辨率，曝光度……）的几个问题</title>
		<link>https://uzzz.org/article/3253.html</link>
				<pubDate>Mon, 24 Sep 2018 02:17:34 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[图形视频]]></category>
		<category><![CDATA[opencv]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/3253.html</guid>
				<description><![CDATA[1，适用于VideoCapture打开的摄像头 VideoCapture capture(0); 设置摄像头参数&#160;不要随意修改 capture.set(CV_CAP_PROP_FRAME_WIDTH, 1080);//宽度 capture.set(CV_CAP_PROP_FRAME_HEIGHT, 960);//高度 capture.set(CV_CAP_PROP_FPS, 30);//帧率 帧/秒 capture.set(CV_CAP_PROP_BRIGHTNESS, 1);//亮度&#160; capture.set(CV_CAP_PROP_CONTRAST,40);//对比度 40 capture.set(CV_CAP_PROP_SATURATION, 50);//饱和度 50 capture.set(CV_CAP_PROP_HUE, 50);//色调 50 capture.set(CV_CAP_PROP_EXPOSURE, 50);//曝光 50 获取摄像头参数 得到摄像头的参数 capture.get(CV_CAP_PROP_FRAME_WIDTH); capture.get(CV_CAP_PROP_FRAME_HEIGHT); capture.get(CV_CAP_PROP_FPS); capture.get(CV_CAP_PROP_BRIGHTNESS); capture.get(CV_CAP_PROP_CONTRAST); capture.get(CV_CAP_PROP_SATURATION); capture.get(CV_CAP_PROP_HUE); capture.get(CV_CAP_PROP_EXPOSURE); 获取视频参数： capture.get(CV_CAP_PROP_FRAME_COUNT);//视频帧数&#160; 然后你会发现除了个别参数你能更改之外（如曝光度），大分布你是不能更改的，甚至都没办法得到，这种并不适用 2，不做开发，只是单纯的更改 那么推荐一个软件，amcap，百度网盘链接，https://pan.baidu.com/s/1pL8nq0V#list/path=%2F，很简单很容易上手。 补，现在突然想起来我的一个学长告诉我的，利用这个软件调节摄像头的曝光度，可以改变帧率，且摄像头会记住曝光度的设置（其他特性就没有这个特点）。-2019.3.12 3，修改opencv的文件，不过效果可能和第一个差不多 大概是在opencv的这个位置，找一下，modules/highgui/src/cap_v4l.cpp，里面有关于参数的设置，位置比较靠前，可以搜索，也可以直接找到 大致在200多行 4，v4l2 下面是我找到的一篇参考，可以突破帧率的限制，当然前提是摄像头支持 https://blog.csdn.net/c406495762/article/details/72732135 目前只适用于Linux系统，本人试验过，120帧的摄像头在只打开摄像头时可以达到100帧左右，设置的图片分辨率越小，能达到的帧率越高 #include &#60;unistd.h&#62; #include &#60;error.h&#62; #include &#60;errno.h&#62; #include &#60;fcntl.h&#62; #include &#60;sys/ioctl.h&#62; #include &#60;sys/types.h&#62; #include &#60;pthread.h&#62; #include &#60;linux/videodev2.h&#62; #include &#60;sys/mman.h&#62; #include &#60;opencv2/core/core.hpp&#62; #include &#60;opencv2/highgui/highgui.hpp&#62; #include &#60;stdio.h&#62; #include &#60;stdlib.h&#62; #include &#60;string.h&#62; #include &#60;time.h&#62; #include "opencv2/highgui/highgui.hpp" #include "opencv2/imgproc/imgproc.hpp" #include &#60;math.h&#62; #include &#60;iostream&#62; #include &#60;iomanip&#62; #include &#60;string&#62; using namespace std; using namespace cv; #define CLEAR(x) memset(&#38;(x), 0, sizeof(x)) #define IMAGEWIDTH 3264 #define IMAGEHEIGHT 2448 #define WINDOW_NAME1 "【原始图】" //为窗口标题定义的宏 #define WINDOW_NAME2 "【图像轮廓】" //为窗口标题定义的宏 Mat g_srcImage; Mat g_grayImage; int g_nThresh = 90; int g_nMaxThresh = 255; RNG g_rng(12345); Mat g_cannyMat_output; vector&#60;vector&#60;Point&#62; &#62; g_vContours; vector&#60;Vec4i&#62; g_vHierarchy; Point point1[100000]; Point point2[100000]; Point point3[100000]; int ii,iii; int flag2 = 0;//避障用 float number = 0; int fps=0; class V4L2Capture { public: V4L2Capture(char *devName, int width, int height); virtual ~V4L2Capture(); int openDevice(); int closeDevice(); int initDevice(); int startCapture(); int stopCapture(); int freeBuffers(); int getFrame(void **,size_t]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div class="htmledit_views" id="content_views">
<h2 id="1%EF%BC%8C%E9%80%82%E7%94%A8%E4%BA%8EVideoCapture%E6%89%93%E5%BC%80%E7%9A%84%E6%91%84%E5%83%8F%E5%A4%B4">1，适用于VideoCapture打开的摄像头</h2>
<p>VideoCapture capture(0); 设置摄像头参数&nbsp;不要随意修改</p>
<p>capture.set(CV_CAP_PROP_FRAME_WIDTH, 1080);//宽度</p>
<p>capture.set(CV_CAP_PROP_FRAME_HEIGHT, 960);//高度</p>
<p>capture.set(CV_CAP_PROP_FPS, 30);//帧率 帧/秒</p>
<p>capture.set(CV_CAP_PROP_BRIGHTNESS, 1);//亮度&nbsp;</p>
<p>capture.set(CV_CAP_PROP_CONTRAST,40);//对比度 40</p>
<p>capture.set(CV_CAP_PROP_SATURATION, 50);//饱和度 50</p>
<p>capture.set(CV_CAP_PROP_HUE, 50);//色调 50</p>
<p>capture.set(CV_CAP_PROP_EXPOSURE, 50);//曝光 50 获取摄像头参数</p>
<p>得到摄像头的参数</p>
<p>capture.get(CV_CAP_PROP_FRAME_WIDTH);</p>
<p>capture.get(CV_CAP_PROP_FRAME_HEIGHT);</p>
<p>capture.get(CV_CAP_PROP_FPS);</p>
<p>capture.get(CV_CAP_PROP_BRIGHTNESS);</p>
<p>capture.get(CV_CAP_PROP_CONTRAST);</p>
<p>capture.get(CV_CAP_PROP_SATURATION);</p>
<p>capture.get(CV_CAP_PROP_HUE);</p>
<p>capture.get(CV_CAP_PROP_EXPOSURE); 获取视频参数：</p>
<p>capture.get(CV_CAP_PROP_FRAME_COUNT);//视频帧数&nbsp;</p>
<p>然后你会发现除了个别参数你能更改之外（如曝光度），大分布你是不能更改的，甚至都没办法得到，这种并不适用</p>
<h2 id="2%EF%BC%8C%E4%B8%8D%E5%81%9A%E5%BC%80%E5%8F%91%EF%BC%8C%E5%8F%AA%E6%98%AF%E5%8D%95%E7%BA%AF%E7%9A%84%E6%9B%B4%E6%94%B9">2，不做开发，只是单纯的更改</h2>
<p>那么推荐一个软件，amcap，百度网盘链接，<a href="https://pan.baidu.com/s/1pL8nq0V#list/path=%2F" rel="nofollow" data-token="97b1bbe118ed4b783bd17ce84fcafa7a">https://pan.baidu.com/s/1pL8nq0V#list/path=%2F</a>，很简单很容易上手。</p>
<p>补，现在突然想起来我的一个学长告诉我的，利用这个软件调节摄像头的曝光度，可以改变帧率，且摄像头会记住曝光度的设置（其他特性就没有这个特点）。-2019.3.12</p>
<h2>3，修改opencv的文件，不过效果可能和第一个差不多</h2>
<p>大概是在opencv的这个位置，找一下，modules/highgui/src/cap_v4l.cpp，里面有关于参数的设置，位置比较靠前，可以搜索，也可以直接找到</p>
<p>大致在200多行<img alt="" class="has" height="149" src="https://uzshare.com/_p?https://img-blog.csdn.net/2018092414270643?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl8zOTkxNjA4Ng==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" width="419"></p>
<h2>4，v4l2</h2>
<p>下面是我找到的一篇参考，可以突破帧率的限制，当然前提是摄像头支持</p>
<p><a href="https://blog.csdn.net/c406495762/article/details/72732135" rel="nofollow" data-token="1cbfb6830f56eecd337b0d11183c5bd7">https://blog.csdn.net/c406495762/article/details/72732135</a></p>
<p>目前只适用于Linux系统，本人试验过，120帧的摄像头在只打开摄像头时可以达到100帧左右，设置的图片分辨率越小，能达到的帧率越高</p>
<pre class="has">
<code class="language-cpp">#include &lt;unistd.h&gt;
#include &lt;error.h&gt;
#include &lt;errno.h&gt;
#include &lt;fcntl.h&gt;
#include &lt;sys/ioctl.h&gt;
#include &lt;sys/types.h&gt;
#include &lt;pthread.h&gt;
#include &lt;linux/videodev2.h&gt;
#include &lt;sys/mman.h&gt;
#include &lt;opencv2/core/core.hpp&gt;
#include &lt;opencv2/highgui/highgui.hpp&gt;
#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
#include &lt;string.h&gt;
#include &lt;time.h&gt;
#include "opencv2/highgui/highgui.hpp"
#include "opencv2/imgproc/imgproc.hpp"
#include &lt;math.h&gt;
#include &lt;iostream&gt;
#include &lt;iomanip&gt;
#include &lt;string&gt;

using namespace std;
using namespace cv;
#define CLEAR(x) memset(&amp;(x), 0, sizeof(x))

#define IMAGEWIDTH 3264
#define IMAGEHEIGHT 2448

#define WINDOW_NAME1 "【原始图】"					//为窗口标题定义的宏
#define WINDOW_NAME2 "【图像轮廓】"        //为窗口标题定义的宏

Mat g_srcImage; Mat g_grayImage;
int g_nThresh = 90;
int g_nMaxThresh = 255;
RNG g_rng(12345);
Mat g_cannyMat_output;
vector&lt;vector&lt;Point&gt; &gt; g_vContours;
vector&lt;Vec4i&gt; g_vHierarchy;
Point point1[100000];
Point point2[100000];
Point point3[100000];
int ii,iii;
int flag2 = 0;//避障用
float number = 0;
int fps=0;


class V4L2Capture {
public:
    V4L2Capture(char *devName, int width, int height);
    virtual ~V4L2Capture();

    int openDevice();
    int closeDevice();
    int initDevice();
    int startCapture();
    int stopCapture();
    int freeBuffers();
    int getFrame(void **,size_t *);
    int backFrame();
    static void test();

private:
    int initBuffers();

    struct cam_buffer
    {
        void* start;
        unsigned int length;
    };
    char *devName;
    int capW;
    int capH;
    int fd_cam;
    cam_buffer *buffers;
    unsigned int n_buffers;
    int frameIndex;
};

V4L2Capture::V4L2Capture(char *devName, int width, int height) {
    // TODO Auto-generated constructor stub
    this-&gt;devName = devName;
    this-&gt;fd_cam = -1;
    this-&gt;buffers = NULL;
    this-&gt;n_buffers = 0;
    this-&gt;frameIndex = -1;
    this-&gt;capW=width;
    this-&gt;capH=height;
}

V4L2Capture::~V4L2Capture() {
    // TODO Auto-generated destructor stub
}

int V4L2Capture::openDevice() {
    /*设备的打开*/
    printf("video dev : %s\n", devName);
    fd_cam = open(devName, O_RDWR);
    if (fd_cam &lt; 0) {
        perror("Can't open video device");
    }
    return 0;
}

int V4L2Capture::closeDevice() {
    if (fd_cam &gt; 0) {
        int ret = 0;
        if ((ret = close(fd_cam)) &lt; 0) {
            perror("Can't close video device");
        }
        return 0;
    } else {
        return -1;
    }
}

int V4L2Capture::initDevice() {
    int ret;
    struct v4l2_capability cam_cap;		//显示设备信息
    struct v4l2_cropcap cam_cropcap;	//设置摄像头的捕捉能力
    struct v4l2_fmtdesc cam_fmtdesc;	//查询所有支持的格式：VIDIOC_ENUM_FMT
    struct v4l2_crop cam_crop;			//图像的缩放
    struct v4l2_format cam_format;		//设置摄像头的视频制式、帧格式等

    /* 使用IOCTL命令VIDIOC_QUERYCAP，获取摄像头的基本信息*/
    ret = ioctl(fd_cam, VIDIOC_QUERYCAP, &amp;cam_cap);
    if (ret &lt; 0) {
        perror("Can't get device information: VIDIOCGCAP");
    }
    printf(
            "Driver Name:%s\nCard Name:%s\nBus info:%s\nDriver Version:%u.%u.%u\n",
            cam_cap.driver, cam_cap.card, cam_cap.bus_info,
            (cam_cap.version &gt;&gt; 16) &amp; 0XFF, (cam_cap.version &gt;&gt; 8) &amp; 0XFF,
            cam_cap.version &amp; 0XFF);

    /* 使用IOCTL命令VIDIOC_ENUM_FMT，获取摄像头所有支持的格式*/
    cam_fmtdesc.index = 0;
    cam_fmtdesc.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    printf("Support format:\n");
    while (ioctl(fd_cam, VIDIOC_ENUM_FMT, &amp;cam_fmtdesc) != -1) {
        printf("\t%d.%s\n", cam_fmtdesc.index + 1, cam_fmtdesc.description);
        cam_fmtdesc.index++;
    }

    /* 使用IOCTL命令VIDIOC_CROPCAP，获取摄像头的捕捉能力*/
    cam_cropcap.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    if (0 == ioctl(fd_cam, VIDIOC_CROPCAP, &amp;cam_cropcap)) {
        printf("Default rec:\n\tleft:%d\n\ttop:%d\n\twidth:%d\n\theight:%d\n",
                cam_cropcap.defrect.left, cam_cropcap.defrect.top,
                cam_cropcap.defrect.width, cam_cropcap.defrect.height);
        /* 使用IOCTL命令VIDIOC_S_CROP，获取摄像头的窗口取景参数*/
        cam_crop.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
        cam_crop.c = cam_cropcap.defrect;		//默认取景窗口大小
        if (-1 == ioctl(fd_cam, VIDIOC_S_CROP, &amp;cam_crop)) {
            //printf("Can't set crop para\n");
        }
    } else {
        printf("Can't set cropcap para\n");
    }

    /* 使用IOCTL命令VIDIOC_S_FMT，设置摄像头帧信息*/
    cam_format.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    cam_format.fmt.pix.width = capW;
    cam_format.fmt.pix.height = capH;
    cam_format.fmt.pix.pixelformat = V4L2_PIX_FMT_MJPEG;		//要和摄像头支持的类型对应
    cam_format.fmt.pix.field = V4L2_FIELD_INTERLACED;
    ret = ioctl(fd_cam, VIDIOC_S_FMT, &amp;cam_format);
    if (ret &lt; 0) {
        perror("Can't set frame information");
    }
    /* 使用IOCTL命令VIDIOC_G_FMT，获取摄像头帧信息*/
    cam_format.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    ret = ioctl(fd_cam, VIDIOC_G_FMT, &amp;cam_format);
    if (ret &lt; 0) {
        perror("Can't get frame information");
    }
    printf("Current data format information:\n\twidth:%d\n\theight:%d\n",
            cam_format.fmt.pix.width, cam_format.fmt.pix.height);
    ret = initBuffers();
    if (ret &lt; 0) {
        perror("Buffers init error");
        //exit(-1);
    }
    return 0;
}

int V4L2Capture::initBuffers() {
    int ret;
    /* 使用IOCTL命令VIDIOC_REQBUFS，申请帧缓冲*/
    struct v4l2_requestbuffers req;
    CLEAR(req);
    req.count = 4;
    req.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    req.memory = V4L2_MEMORY_MMAP;
    ret = ioctl(fd_cam, VIDIOC_REQBUFS, &amp;req);
    if (ret &lt; 0) {
        perror("Request frame buffers failed");
    }
    if (req.count &lt; 2) {
        perror("Request frame buffers while insufficient buffer memory");
    }
    buffers = (struct cam_buffer*) calloc(req.count, sizeof(*buffers));
    if (!buffers) {
        perror("Out of memory");
    }
    for (n_buffers = 0; n_buffers &lt; req.count; n_buffers++) {
        struct v4l2_buffer buf;
        CLEAR(buf);
        // 查询序号为n_buffers 的缓冲区，得到其起始物理地址和大小
        buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
        buf.memory = V4L2_MEMORY_MMAP;
        buf.index = n_buffers;
        ret = ioctl(fd_cam, VIDIOC_QUERYBUF, &amp;buf);
        if (ret &lt; 0) {
            printf("VIDIOC_QUERYBUF %d failed\n", n_buffers);
            return -1;
        }
        buffers[n_buffers].length = buf.length;
        //printf("buf.length= %d\n",buf.length);
        // 映射内存
        buffers[n_buffers].start = mmap(
                NULL, // start anywhere
                buf.length, PROT_READ | PROT_WRITE, MAP_SHARED, fd_cam,
                buf.m.offset);
        if (MAP_FAILED == buffers[n_buffers].start) {
            printf("mmap buffer%d failed\n", n_buffers);
            return -1;
        }
    }
    return 0;
}

int V4L2Capture::startCapture() {
    unsigned int i;
    for (i = 0; i &lt; n_buffers; i++) {
        struct v4l2_buffer buf;
        CLEAR(buf);
        buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
        buf.memory = V4L2_MEMORY_MMAP;
        buf.index = i;
        if (-1 == ioctl(fd_cam, VIDIOC_QBUF, &amp;buf)) {
            printf("VIDIOC_QBUF buffer%d failed\n", i);
            return -1;
        }
    }
    enum v4l2_buf_type type;
    type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    if (-1 == ioctl(fd_cam, VIDIOC_STREAMON, &amp;type)) {
        printf("VIDIOC_STREAMON error");
        return -1;
    }
    return 0;
}

int V4L2Capture::stopCapture() {
    enum v4l2_buf_type type;
    type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    if (-1 == ioctl(fd_cam, VIDIOC_STREAMOFF, &amp;type)) {
        printf("VIDIOC_STREAMOFF error\n");
        return -1;
    }
    return 0;
}/*ok*/

int V4L2Capture::freeBuffers() {
    unsigned int i;
    for (i = 0; i &lt; n_buffers; ++i) {
        if (-1 == munmap(buffers[i].start, buffers[i].length)) {
            printf("munmap buffer%d failed\n", i);
            return -1;
        }
    }
    free(buffers);
    return 0;
}

int V4L2Capture::getFrame(void **frame_buf, size_t* len) {
    struct v4l2_buffer queue_buf;
    CLEAR(queue_buf);
    queue_buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
    queue_buf.memory = V4L2_MEMORY_MMAP;
    if (-1 == ioctl(fd_cam, VIDIOC_DQBUF, &amp;queue_buf)) {
        printf("VIDIOC_DQBUF error\n");
        return -1;
    }
    *frame_buf = buffers[queue_buf.index].start;
    *len = buffers[queue_buf.index].length;
    frameIndex = queue_buf.index;
    return 0;
}

int V4L2Capture::backFrame() {
    if (frameIndex != -1) {
        struct v4l2_buffer queue_buf;
        CLEAR(queue_buf);
        queue_buf.type = V4L2_BUF_TYPE_VIDEO_CAPTURE;
        queue_buf.memory = V4L2_MEMORY_MMAP;
        queue_buf.index = frameIndex;
        if (-1 == ioctl(fd_cam, VIDIOC_QBUF, &amp;queue_buf)) {
            printf("VIDIOC_QBUF error\n");
            return -1;
        }
        return 0;
    }
    return -1;
}
void V4L2Capture::test() {
    unsigned char *yuv422frame = NULL;
    unsigned long yuvframeSize = 0;

    string videoDev="/dev/video0";
    V4L2Capture *vcap = new V4L2Capture(const_cast&lt;char*&gt;(videoDev.c_str()),
            1920, 1080);
    vcap-&gt;openDevice();
    vcap-&gt;initDevice();
    vcap-&gt;startCapture();
    vcap-&gt;getFrame((void **) &amp;yuv422frame, (size_t *)&amp;yuvframeSize);

    vcap-&gt;backFrame();
    vcap-&gt;freeBuffers();
    vcap-&gt;closeDevice();
}
void line2(Point point3[100000], int n)
{
    float aa, bb, cc, dd, ee, ff, gg;
    int jj = 0;
    for (;jj &lt;n;jj++)
    {
        aa += point3[jj].x*point3[jj].x;
        bb += point3[jj].x;
        cc += point3[jj].x*point3[jj].y;
        dd += point3[jj].y;
    }
    ee = aa*n - bb*bb;
    if ((int)(ee* 100) != 0)
    {
        ff = (n*cc - bb*dd) / ee;
        gg = (dd - bb*ff) / n;
    }
    else {
        ff = 0;
        gg = 1;
    }
    Point point0, pointn;
    point0.y = 0;
    point0.x = gg;
    pointn.y = (n-1);
    pointn.x = ((n-1) * ff + gg);

    Mat draw_ing2 = Mat::zeros(g_cannyMat_output.size(), CV_8UC3);
    line(draw_ing2, point0, pointn, (255, 255, 255));
    imshow("10", draw_ing2);
    //cout &lt;&lt; "\n"&lt;&lt;ff &lt;&lt;"      "&lt;&lt; gg &lt;&lt; endl;
    float the =180*atan(ff)/3.14159;
    float dis = ff * 160+gg - 160;
    cout &lt;&lt; the &lt;&lt; "    " &lt;&lt; dis &lt;&lt; endl;
    //正中心ff=0，gg=160，逆时ff为正，顺时ff为负
}
void findcolor(cv::Mat &amp;image)
{
    cv::Mat_&lt;cv::Vec3b&gt;::iterator it = image.begin&lt;cv::Vec3b&gt;();
    cv::Mat_&lt;cv::Vec3b&gt;::iterator itend = image.end&lt;cv::Vec3b&gt;();
    ii = 0;
    iii = 0;
    int flagg = 0;
        cv::Mat srcX(image.rows, image.cols , CV_32F);
        cv::Mat srcY(image.rows, image.cols, CV_32F);
        for (int i = 0;i &lt; image.rows;i++)
        {
            for (int j = 0;j &lt; image.cols;j++)
            {
                if (flagg == 0)/*这样遍历水平方向无法得到有效数据*/
                {

                    if ((*it)[0] == 255 &amp;&amp; (*it)[1] == 0 &amp;&amp; (*it)[2] == 255)
                    {
                        flagg = 1;
                        point1[ii].x = i;
                        point1[ii].y = j;
                        ii++;
                    }

                }
                else
                {
                    if ((*it)[0] == 255 &amp;&amp; (*it)[1] == 0 &amp;&amp; (*it)[2] == 255)
                    {
                        flagg = 0;
                        point2[iii].x = i;
                        point2[iii].y = j;
                        iii++;
                    }
                }
                if (it == itend)
                    break;
                else it++;
            }
        }
        IplImage pImg = IplImage(image);
        CvArr* arr = (CvArr*)&amp;pImg;
        int nn = ii;
        for (;ii &gt; 0;ii--)
        {
            point3[ii].x = (point1[ii].x + point2[ii].x) / 2;
            point3[ii].y = (point1[ii].y + point2[ii].y) / 2;
            //circle(image, point3[ii], 1, (255, 255, 255));
            cvSet2D(arr, point3[ii].x, point3[ii].y, Scalar(255, 255, 255));
        }
        line2(point3, nn);
}

void on_ThreshChange(int, void* )
{
    // 使用Canndy检测边缘
    Canny( g_grayImage, g_cannyMat_output, g_nThresh, g_nThresh*2, 3 );

    // 找到轮廓
    findContours( g_cannyMat_output, g_vContours, g_vHierarchy, RETR_TREE, CHAIN_APPROX_SIMPLE, Point(0, 0) );

    // 计算矩
    vector&lt;Moments&gt; mu(g_vContours.size() );
    for(unsigned int i = 0; i &lt; g_vContours.size(); i++ )
    { mu[i] = moments( g_vContours[i], false ); }

    //  计算中心矩
    vector&lt;Point2f&gt; mc( g_vContours.size() );
    for( unsigned int i = 0; i &lt; g_vContours.size(); i++ )
    { mc[i] = Point2f( static_cast&lt;float&gt;(mu[i].m10/mu[i].m00), static_cast&lt;float&gt;(mu[i].m01/mu[i].m00 )); }

    // 绘制轮廓
    Mat drawing = Mat::zeros(g_cannyMat_output.size(), CV_8UC3);
    for( unsigned int i = 0; i&lt; g_vContours.size(); i++ )
    {
        //Scalar color = Scalar( g_rng.uniform(0, 255), g_rng.uniform(0,255), g_rng.uniform(0,255) );//随机生成颜色值
        Scalar color = Scalar(255, 0, 255);
        drawContours( drawing, g_vContours, i, color, 2, 8, g_vHierarchy, 0, Point() );//绘制外层和内层轮廓
        circle( drawing, mc[i], 4, color, -1, 8, 0 );;//绘制圆
    }

    findcolor(drawing);
    //line1(point1,point2,ii,iii);

    // 显示到窗口中
//    namedWindow( WINDOW_NAME2, WINDOW_AUTOSIZE );
    imshow( WINDOW_NAME2, drawing );

}

void findline(Mat image)
{
    cv::Mat_&lt;cv::Vec3b&gt;::iterator it = image.begin&lt;cv::Vec3b&gt;();
    cv::Mat_&lt;cv::Vec3b&gt;::iterator itend = image.end&lt;cv::Vec3b&gt;();
    for (;it != itend;it++)
    {
        if ((*it)[1] == 0 &amp;&amp; (*it)[2] &gt;= 100)//条件可能需要改变
        {
            if(flag2==0)
            {
                flag2 = 1;
                cout &lt;&lt; "注意line1，避障"&lt;&lt;endl;
                //向主控发送消息
            }
            else
            {
                cout &lt;&lt; "注意line2，避障" &lt;&lt; endl;
                //向主控发送消息
                //避障一与避障二中间要隔一段时间
            }

        }
    }
}
void wave(const cv::Mat &amp;image, cv::Mat &amp;result)
{
    cv::Mat srcX(image.rows / 2, image.cols / 2, CV_32F);
    cv::Mat srcY(image.rows / 2, image.cols / 2, CV_32F);
    for (int i = 0;i&lt;image.rows /2;i++)
        for (int j = 0;j &lt; image.cols /2;j++)
        {
            srcX.at&lt;float&gt;(i, j) = 2 * j;
            srcY.at&lt;float&gt;(i, j) = 2 * i;
        }
    cv::remap(image, result, srcX, srcY, cv::INTER_LINEAR);
}

void VideoPlayer() {
    unsigned char *yuv422frame = NULL;
    unsigned long yuvframeSize = 0;

    string videoDev = "/dev/video0";
    V4L2Capture *vcap = new V4L2Capture(const_cast&lt;char*&gt;(videoDev.c_str()), 640, 480);
    vcap-&gt;openDevice();
    vcap-&gt;initDevice();
    vcap-&gt;startCapture();

    cvNamedWindow("Capture",CV_WINDOW_AUTOSIZE);
    IplImage* img;
    CvMat cvmat;
    double t;
    clock_t start, end;
    double number=0;
    int fps=0;
    while(1){
        start=clock();
        t = (double)cvGetTickCount();
        vcap-&gt;getFrame((void **) &amp;yuv422frame, (size_t *)&amp;yuvframeSize);
        cvmat = cvMat(IMAGEHEIGHT,IMAGEWIDTH,CV_8UC3,(void*)yuv422frame);		//CV_8UC3
        //解码
        img = cvDecodeImage(&amp;cvmat,1);
        if(!img){
            printf("DecodeImage error!\n");
        }
        
        cv::Mat g_srcImage = cv::cvarrToMat(img,true);
        
        cvShowImage("Capture",img);
        cvReleaseImage(&amp;img);
        vcap-&gt;backFrame();
        if((cvWaitKey(1)&amp;255) == 27){
            exit(0);
        }



        wave(g_srcImage, g_srcImage);
        findline(g_srcImage);

        // 把原图像转化成灰度图像并进行平滑
        cvtColor(g_srcImage, g_grayImage, COLOR_BGR2GRAY);
        blur(g_grayImage, g_grayImage, Size(3, 3));


        //创建滚动条并进行初始化
        createTrackbar(" 阈值", WINDOW_NAME1, &amp;g_nThresh, g_nMaxThresh, on_ThreshChange);
        on_ThreshChange(0, 0);
		t = (double)cvGetTickCount() - t;
		printf("Used time is %g ms\n", (t / (cvGetTickFrequency() * 1000)));

        end =clock();
        number=number+end-start;
        fps++;
        if (number/ CLOCKS_PER_SEC&gt;= 0.25)//windows10   for   CLK_TCK
        {
            cout&lt;&lt;fps&lt;&lt;endl;
            fps = 0;
            number = 0;
        }
    }
    vcap-&gt;stopCapture();
    vcap-&gt;freeBuffers();
    vcap-&gt;closeDevice();

}

int main() {
    VideoPlayer();

    return 0;
}
</code></pre>
<p>&nbsp;</p>
</p></div>
</div>
]]></content:encoded>
										</item>
		<item>
		<title>捕获海康威视IPCamera图像，转成OpenCV可以处理的图像（一）</title>
		<link>https://uzzz.org/article/3276.html</link>
				<pubDate>Mon, 16 Jun 2014 10:32:41 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[开发]]></category>
		<category><![CDATA[opencv]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/3276.html</guid>
				<description><![CDATA[海康威视IPCamera图像捕获 捕获海康威视IPCamera图像，转成OpenCV可以处理的IplImage图像（一） 捕获海康威视IPCamera图像，转成OpenCV可以处理的IplImage图像（二） 所使用海康威视摄像头型号：DS-2CD4026FWD-(A)(P) 海康威视IPCamera图像捕获方法有两种： （1）利用SDK里面的NET_DVR_CaptureJPEGPicture_NEW进行视频抓图 （2）捕获实时流，将实时流解码成YV12，然后转换成RGB 在这篇博文里，我先介绍第一种方法。 第一种方法，关键是调用NET_DVR_CaptureJPEGPicture_NEW这个函数。关于这个函数的参数，可以在SDK中找到，我这里截个图以作说明。 这个函数Ret是用于返回该图像大小的一个参数，但是该函数的这个参数大概是没有用引用或者指针的方式来传递参数，导致返回值一直是我初始化的0，因此为后面的操作带来了些许的不便——不得不使用一个较大的内存来保存图像一定能存储的下。 NET_DVR_CaptureJPEGPicture_NEW这个函数是将单帧数据捕获并保存成JPEG，存放在指定的内存空间中。也就是内存里的JPEG。为了获得OpenCV能处理的IplImage图像，必须在内存中进行解码。 OpenCV在内存中解码的函数只有一个：imdecode，下图是imdecode的说明 该函数要求buf必须是数组或者是byte类型的vector. 因此需要对char * 类型的JPEG压缩图像进行存储格式转换。 #include &#60;cstdio&#62; #include &#60;iostream&#62; #include &#60;ctime&#62; #include &#60;Windows.h&#62; #include "HCNetSDK.h" #include "highgui.h" #include "cv.h" using namespace cv; using namespace std; //typedef HWND (WINAPI *PROCGETCONSOLEWINDOW)(); //PROCGETCONSOLEWINDOW GetConsoleWindow; int main(int argc, char * argv[]) { //--------------------------------------- // 初始化 NET_DVR_Init(); //设置连接时间与重连时间 NET_DVR_SetConnectTime(2000, 1); NET_DVR_SetReconnect(10000, true); //--------------------------------------- //获取控制台窗口句柄 //HMODULE hKernel32 = GetModuleHandle((LPCWSTR)"kernel32"); //GetConsoleWindow = (PROCGETCONSOLEWINDOW)GetProcAddress(hKernel32,"GetConsoleWindow"); //--------------------------------------- // 注册设备 LONG lUserID; NET_DVR_DEVICEINFO_V30 struDeviceInfo; lUserID = NET_DVR_Login_V30("10.102.7.88", 8000, "admin", "12345", &#38;struDeviceInfo); if (lUserID &#60; 0) { printf("Login error, %d\n", NET_DVR_GetLastError()); NET_DVR_Cleanup(); return -1; } //--------------------------------------- //cvNamedWindow("camera",CV_WINDOW_AUTOSIZE); IplImage* frame; //定义JPEG图像质量 LPNET_DVR_JPEGPARA JpegPara = new NET_DVR_JPEGPARA; JpegPara-&#62;wPicQuality = 0; JpegPara-&#62;wPicSize = 9; char * Jpeg = new char[200*1024]; DWORD len = 200*1024; LPDWORD Ret = 0; if(!NET_DVR_SetCapturePictureMode(BMP_MODE)) { cout&#60;&#60;"Set Capture Picture Mode error!"&#60;&#60;endl; cout&#60;&#60;"The error code is "&#60;&#60;NET_DVR_GetLastError()&#60;&#60;endl; } //bool capture = NET_DVR_CaptureJPEGPicture(lUserID,1,JpegPara,"1111"); vector&#60;char&#62;data(200*1024); while(1) { bool capture = NET_DVR_CaptureJPEGPicture_NEW(lUserID,1,JpegPara,Jpeg,len,Ret); if(!capture) { printf("Error: NET_DVR_CaptureJPEGPicture_NEW = %d", NET_DVR_GetLastError()); return -1; } for(int i=0;i&#60;200*1024;i++) data[i] = Jpeg[i]; Mat img = imdecode(Mat(data),1); imshow("camera",img); waitKey(1); } //FILE * fp = fopen("3.jpg","wb"); //fwrite(Jpeg,1,123*1024,fp); //fclose(fp); return 0; }]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div class="htmledit_views" id="content_views">
<h2>海康威视IPCamera图像捕获</h2>
<p></p>
</p>
<p> <a href="http://blog.csdn.net/wanghuiqi2008/article/details/31404571" rel="nofollow" data-token="da28483303d28b3d7bb05caf49144801"><span style="font-size:14px;">捕获海康威视IPCamera图像，转成OpenCV可以处理的IplImage图像（一）</span></a></p>
<p> <a href="http://blog.csdn.net/wanghuiqi2008/article/details/31410509" rel="nofollow" data-token="eb6e83bfc871d65e1b3ec4c789a8197b"><span style="font-size:14px;">捕获海康威视IPCamera图像，转成OpenCV可以处理的IplImage图像（二）</span></a></p>
</p>
<p></p>
<p>所使用海康威视摄像头型号：<span style="color:rgb(64,64,64);font-family:'微软雅黑', arial;line-height:16px;text-align:center;"><a href="http://www.hikvision.com/cn/prgs_171_i3042.html" rel="nofollow" data-token="905073dfb30404c97f2e441e3c102019">DS-2CD4026FWD-(A)(P)</a></span></p>
<p></p>
<p>海康威视IPCamera图像捕获方法有两种：</p>
<p>（1）利用SDK里面的<span style="font-family:SimSun;"><span style="font-size:10px;">NET_DVR_CaptureJPEGPicture_NEW</span></span>进行视频抓图</p>
<p>（2）捕获实时流，将实时流解码成YV12，然后转换成RGB</p>
<p></p>
<p>在这篇博文里，我先介绍第一种方法。</p>
<p>第一种方法，关键是调用<span style="font-family:SimSun;font-size:10px;">NET_DVR_CaptureJPEGPicture_NEW这个函数。关于这个函数的参数，可以在SDK中找到，我这里截个图以作说明。</span></p>
<p><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20140616181319921?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2FuZ2h1aXFpMjAwOA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p>
<p><span style="font-family:SimSun;font-size:10px;">这个函数Ret是用于返回该图像大小的一个参数，但是该函数的这个参数大概是没有用引用或者指针的方式来传递参数，导致返回值一直是我初始化的0，因此为后面的操作带来了些许的不便——不得不使用一个较大的内存来保存图像一定能存储的下。</span></p>
<p><span style="font-family:SimSun;font-size:10px;">NET_DVR_CaptureJPEGPicture_NEW</span>这个函数是将单帧数据捕获并保存成JPEG，存放在指定的内存空间中。也就是内存里的JPEG。为了获得OpenCV能处理的IplImage图像，必须在内存中进行解码。</p>
<p>OpenCV在内存中解码的函数只有一个：imdecode，下图是imdecode的说明</p>
<p><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20140616181228437?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvd2FuZ2h1aXFpMjAwOA==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt=""></p>
<p>该函数要求buf必须是数组或者是byte类型的vector. 因此需要对char * 类型的JPEG压缩图像进行存储格式转换。</p>
<p></p>
</p>
<pre><code class="language-cpp">#include &lt;cstdio&gt;
#include &lt;iostream&gt;
#include &lt;ctime&gt;
#include &lt;Windows.h&gt;
#include "HCNetSDK.h"
#include "highgui.h"
#include "cv.h"


using namespace cv;
using namespace std;


//typedef HWND (WINAPI *PROCGETCONSOLEWINDOW)();
//PROCGETCONSOLEWINDOW GetConsoleWindow;

int main(int argc, char * argv[]) 
{	
	//---------------------------------------
	// 初始化
	NET_DVR_Init();
	//设置连接时间与重连时间
	NET_DVR_SetConnectTime(2000, 1);
	NET_DVR_SetReconnect(10000, true);
	
	//---------------------------------------
	//获取控制台窗口句柄
	//HMODULE hKernel32 = GetModuleHandle((LPCWSTR)"kernel32");
	//GetConsoleWindow = (PROCGETCONSOLEWINDOW)GetProcAddress(hKernel32,"GetConsoleWindow");

	
	//---------------------------------------
	// 注册设备
	LONG lUserID;
	NET_DVR_DEVICEINFO_V30 struDeviceInfo;
	lUserID = NET_DVR_Login_V30("10.102.7.88", 8000, "admin", "12345", &amp;struDeviceInfo);
	if (lUserID &lt; 0)
	{
		printf("Login error, %d\n", NET_DVR_GetLastError());
		NET_DVR_Cleanup();
		return -1;
	}	

	
	//---------------------------------------
	//cvNamedWindow("camera",CV_WINDOW_AUTOSIZE);
	IplImage* frame;
	//定义JPEG图像质量
	LPNET_DVR_JPEGPARA JpegPara = new NET_DVR_JPEGPARA;
	JpegPara-&gt;wPicQuality = 0;
	JpegPara-&gt;wPicSize = 9;
	
	char * Jpeg = new char[200*1024];
	DWORD len = 200*1024;
	LPDWORD Ret = 0;
			
	if(!NET_DVR_SetCapturePictureMode(BMP_MODE))
	{
		cout&lt;&lt;"Set Capture Picture Mode error!"&lt;&lt;endl;
		cout&lt;&lt;"The error code is "&lt;&lt;NET_DVR_GetLastError()&lt;&lt;endl;
	}

	//bool capture = NET_DVR_CaptureJPEGPicture(lUserID,1,JpegPara,"1111");
	vector&lt;char&gt;data(200*1024);
	while(1)
	{
	bool capture = NET_DVR_CaptureJPEGPicture_NEW(lUserID,1,JpegPara,Jpeg,len,Ret);
	if(!capture)
	{
		printf("Error: NET_DVR_CaptureJPEGPicture_NEW = %d", NET_DVR_GetLastError());
		return -1;	
	}	

	for(int i=0;i&lt;200*1024;i++)
		data[i] = Jpeg[i];

	Mat img = imdecode(Mat(data),1);
	imshow("camera",img);
	waitKey(1);
	
	}

	//FILE * fp = fopen("3.jpg","wb");
	//fwrite(Jpeg,1,123*1024,fp);
	//fclose(fp);
	
	return 0;
}
</code></pre>
<p> 运行这个代码当然OpenCV的配置不能少，HCNetSDK.h也必须包含进工程。 </p>
<p>运行这个程序，可以捕获到图像，但是我计算了下时间，在调用&nbsp;NET_DVR_CaptureJPEGPicture_NEW(lUserID,1,JpegPara,Jpeg,len,Ret);这一句话的时候，用时300ms，这个耗时太长，无法实时！但是如果对实时无要求，用这个也可以了，好理解！</p>
<pre><span style="font-family:'Microsoft YaHei';">*********************************************************************************************
</span></pre>
<pre><span style="font-family:'Microsoft YaHei';">转载请注明出处：<a href="http://blog.csdn.net/wanghuiqi2008/article/details/31404571" rel="nofollow" data-token="da28483303d28b3d7bb05caf49144801">http://blog.csdn.net/wanghuiqi2008/article/details/31404571 </a></span></pre>
<pre><span style="font-family:'Microsoft YaHei';">*********************************************************************************************</span></pre>
<p></p>
<p></p>
</p></div>
</div>
]]></content:encoded>
										</item>
	</channel>
</rss>
