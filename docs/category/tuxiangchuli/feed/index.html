<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>图像处理 &#8211; 有组织在!</title>
	<atom:link href="https://uzzz.org/category/tuxiangchuli/feed" rel="self" type="application/rss+xml" />
	<link>https://uzzz.org/</link>
	<description></description>
	<lastBuildDate>Sun, 29 Sep 2019 02:38:06 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.2.4</generator>

<image>
	<url>https://uzzz.org/wp-content/uploads/2019/10/cropped-icon-32x32.png</url>
	<title>图像处理 &#8211; 有组织在!</title>
	<link>https://uzzz.org/</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>穿墙透视算法&#124;MIT华人Team通过墙壁和遮挡物的超强动作检测模型</title>
		<link>https://uzzz.org/article/2555.html</link>
				<pubDate>Sun, 29 Sep 2019 02:38:06 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[图像处理]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/2555.html</guid>
				<description><![CDATA[&#160; 介绍 了解人们的行为和互动通常取决于看到他们。从视觉数据中自动进行动作识别的过程已成为计算机视觉界众多研究的主题。但是如果太暗，或者人被遮挡或在墙壁后面怎么办？在本文中，我们介绍了一个神经网络该模型可以在光线不足的情况下通过墙壁和遮挡物检测人类的行为。我们的模型将射频（RF）信号作为输入，生成3D人体骨骼作为中间表示，并随着时间的推移识别多个人的动作和互动。通过将输入转换为基于中间骨架的表示形式，我们的模型可以从基于视觉的数据集和基于RF的数据集中学习，并允许这两个任务互相帮助。我们表明，在可见场景中，我们的模型可以达到与基于视觉的动作识别系统相当的准确性，但是在看不见人的情况下，该模型仍可以继续正常工作，因此可以解决超出当今基于视觉的动作识别的局限性的场景。 &#160; 先来看一组动图 &#160; &#160; 墙后动作可识别 &#160; 黑暗环境可识别 &#160; 他们的模型将射频（RF）信号作为输入，生成3D人体骨架作为中间表示，并随着时间的推移识别多个人的动作和互动。 &#160; 多人模式可识别 &#160; 在本文中，我们旨在弥合两个世界。我们引入了RF-Action，这是一个端到端的深度神经网络，可以识别无线信号中的人类动作。它的性能可与基于视觉的系统相媲美，但可以穿过墙壁和遮挡物，并且对光照条件不敏感。图1显示了RF-Action在两种情况下的性能。在左侧，两个人握手，但其中一个被遮挡。基于视觉的系统将无法识别动作，而RF-Action轻松将其归类为握手。在右侧，一个人正在打电话，而另一个人将要向他扔东西。由于光线不佳，基于视觉的系统几乎看不到后者。相反，RF-Action可以正确识别两个动作。 &#160; RF-Action基于多模式设计，可与无线信号和基于视觉的数据集一起使用。我们利用最近的工作显示即推断人类骨骼（即，姿势）从无线信号的可行性&#160; ，并采用骨架作为适合于RF和基于视觉的系统的中间表示。使用骨架作为中间表示是有利的， 因为： （1）它使模型与RF和视觉数据来训练，并利用现有的基于视觉的三维骨骼数据集如PKU-MMD和NTU-RGB + d &#160;[ 26，31 ];&#160; （2）它允许对中间骨骼进行额外的监督，从而有助于指导学习过程，而不仅仅是过去基于RF的动作识别系统中使用的单纯动作标签； （3）由于骨架表示受环境或主体身份的影响最小，因此提高了模型推广到新环境和新人的能力。 &#160; 我们通过两项改进其性能的创新进一步扩展了我们的模型：首先，骨骼，尤其是从RF信号生成的骨骼，可能会出现错误和错误预测。为了解决这个问题，我们的中间表示除了骨架之外还包括每个关节上随时间变化的置信度得分。我们使用自我关注来允许模型随着时间的推移以不同的方式关注不同的关节，具体取决于它们的置信度得分。 &#160; 其次，过去的动作识别模型可以随时生成单个动作。但是，场景中的不同人可能会采取不同的动作，如图1右图所示，一个人在电话上交谈，而另一个人在扔物体。我们的模型可以使用专门设计用于解决此问题的多提案模块来解决此类情况。 &#160; 为了评估RF-Action，我们使用无线设备和多摄像头系统收集了来自不同环境的动作检测数据集。该数据集跨越25个小时，包含30个执行各种单人和多人动作的个人。我们的实验表明，RF-Action在可见场景中的性能可与基于视觉的系统相媲美，并且在存在完全遮挡的情况下仍能继续保持良好的性能。具体来说，RF-Action在无遮挡的情况下可达到87.8的平均平均精度（mAP），在穿墙场景中的mAP为83.0。我们的结果还表明，多模式训练可以改善视觉和无线模式的动作检测。使用RF数据集和PKU-MMD数据集训练模型，我们观察到测试集的mAP性能从83.3提高到87。 &#160; 贡献：本文有以下贡献： &#160; 它提出了第一个使用无线电信号进行基于骨骼的动作识别的模型；它进一步证明了这种模型可以仅使用RF信号（如图1所示）就可以准确识别穿过墙壁的动作和相互作用，并且在极端恶劣的照明条件下。 &#160; 本文提出了“骨架”作为跨各种形式来传递与动作识别相关的知识的中间表示，并通过经验证明这种知识传递可以提高绩效。 &#160; 本文介绍了一个新的时空注意模块，该模块改进了基于骨骼的动作识别，而不管骨骼是从RF还是基于视觉的数据生成的。 &#160; 它还提出了一种新颖的多提案模块，该模块扩展了基于骨骼的动作识别以检测多个人同时进行的动作和互动。 该图显示了我们系统的两个测试用例。在左侧，两个人握手，而其中一个在墙后。在右边，一个人躲在黑暗中，向另一个正在打电话的人扔东西。底行显示了由我们的模型生成的骨骼表示和动作预测。 &#160; 相关知识 &#160; （a）基于视频的动作识别：&#160; 在过去的几年中，从视频中识别动作一直是一个热门话题。早期方法使用手工制作的功能。为实例，像HOG和SIFT图像描述符已经被扩展到3D 来提取视频时间线索。此外，诸如改进的密集轨迹（iDT）之类的描述符是专门设计用来跟踪视频中的运动信息的。 最新的解决方案基于深度学习，分为两大类。 第一类通过利用三维卷积网络提取运动和外观特征共同。 第二类分别通过使用两个流神经网络考虑空间特征和时间特征。 &#160; （二）基于骨架行为识别：基于骷髅动作识别最近获得广泛关注。这种方法具有多个优点。 首先，骨骼为人类动态提供了一种强大的表现力来抵抗背景噪声[ 23 ]。 其次，与RGB视频相比，骨骼更为简洁，这减少了计算开销，并允许使用更小的模型来适合移动平台。 &#160; 基于骨骼的动作识别的先前工作可以分为三类。早期工作使用递归神经网络（RNN）对骨架数据中的时间依赖性进行建模。 &#160; 然而，最近，文献转向了卷积神经网络（CNN），以学习时空特征并取得了令人印象深刻的性能。 &#160; 此外，某些文件表示的骨架作为动作识别图形和利用图形神经网络（GNN）。 在我们的工作中，我们采用基于CNN的方法，并通过引入时空注意模块来处理从无线信号生成的骨骼，并在多提案中扩展了分层共现网络（HCN）模型。 模块以同时启用多个动作预测。 （C）无线电的基于动作的识别：&#160; 研究在无线系统中已经使用无线电信号探索动作识别，特别是用于家庭应用，其中隐私问题可以排除使用摄像机 。 这些作品可以分为两类： 第一类类似于RF-Action，因为它可以分析从人体反弹的无线电信号。他们用行动标签监督，简单分类。 他们只能识别简单的动作（例如步行，坐着和跑步），最多只能识别10个不同的动作。 而且，它们仅处理单人场景。 第二类依赖于传感器网络。 他们或者部署不同传感器，用于不同的动作，（例如，在冰箱门上的传感器可检测的饮食），或贴在每个主体部的可穿戴式传感器和基于其上的身体部位移动识别被摄体的动作。 这样的系统需要对环境或人的大量检测，这限制了它们的实用性和鲁棒性。 &#160; 射频信号入门 &#160; 同时记录RF热图和RGB图像。 我们使用在过去的工作常用于基于RF的动作识别一种类型的无线电的。 无线电会产生一个称为FMCW的波形，并在5.4至7.2 GHz之间工作。 &#160; 该设备具有垂直和水平排列的两个天线阵列。 &#160; 因此，我们的输入数据采用二维热图的形式，一个来自水平阵列，一个来自垂直阵列。如图2所示，水平热图是无线电信号在平行于地面的平面上的投影，而垂直热图是信号在垂直于地面的平面上的投影（红色表示大值，蓝色表示小值）。直观地，较高的值对应于来自某个位置的信号反射的强度更高。 &#160; 无线电以30 FPS的帧速率工作，即每秒产生30对热图。 &#160; 如图所示，RF信号与视觉数据具有不同的属性，这使基于RF的动作识别成为一个难题。尤其是： &#160; 穿过壁的频率中的RF信号的空间分辨率低于视觉数据。在我们的系统中，深度分辨率为10 cm，角度分辨率为10度。如此低的分辨率使得难以区分诸如挥手和梳头等活动。 &#160; 人体在穿过墙壁的频率范围内镜面反射。RF镜面反射是当波长大于表面粗糙度时发生的物理现象。 在这种情况下，与散射体相反，物体的作用就像反射镜（即镜子）。我们收音机的波长约为5厘米，因此人类可以充当反射器。 根据每个肢体表面的方向，信号可能会反射到我们的传感器或远离我们的传感器。 反射信号远离无线电的肢体对于设备来说是不可见的。即使信号被反射回收音机，但表面较小的肢体（例如手）也会反射较少的信号，因此更难追踪。 &#160; 尽管RF信号可以穿过墙壁，但它们穿过墙壁时的衰减明显大于通过空气的衰减。结果，当人在墙壁后面时，从人体反射的信号较弱，因此，在存在墙壁和闭塞的情况下，检测动作的准确性降低。 &#160; RF-Action架构。RF-Action从无线信号中检测人为行为。它首先从原始无线信号输入（黄色框）中提取每个人的3D骨架。然后，它对提取的骨架序列（绿色框）执行动作检测和识别。动作检测框架还可以将从视觉数据生成的3D骨架作为输入（蓝色框），从而可以使用RF生成的骨架和现有的基于骨架的动作识别数据集进行训练。 方法 RF-Action是一种端到端的神经网络模型，可以通过遮挡和不良照明来检测人类行为。 模型架构如图所示，该模型将无线信号作为输入，生成3D人体骨骼作为中间表示，并随着时间的推移识别多个人的动作和交互。 &#160; 该图进一步显示，RF-Action还可以获取从视觉数据生成的3D骨架。 这允许RF-Action与现有的基于骨骼的动作识别数据集一起训练。 &#160; 在本节的其余部分中，我们将描述如何将无线信号转换为3D骨架序列，以及如何从此类骨架序列（即图3中的黄色和绿色框）推断动作。从多相机系统到3D骨架转化可视数据可以通过使用像AlphaPose的算法提取图像的二维骨架，然后进行三角测量的2D关键点，以生成三维骨架来完成。 &#160; a.无线信号的骨架生成 为了从无线信号生成人体骨骼，我们采用其中的架构。具体来说，骨架生成网络（图中橙色框）的水平和垂直热图的形式接收无线信号。 &#160; ，并生成多人3D骨架。网络的输入是水平和垂直热图的3秒窗口（90帧）。该网络由三个通常用于姿势/骨架估计的模块组成。 &#160; 首先，包括时空卷积的特征网络从输入的RF信号中提取特征。然后，将提取的特征通过区域提议网络（RPN）以获得针对可能的骨架边界框的多个提议。最终，将提取的提案输入3D 姿势估计子网，以从每个提案中提取3D骨架。 &#160; b.与模式无关的动作识别 如图所示，与模式无关的动作识别框架使用从RF信号生成的3D骨架来执行动作检测。 &#160; 输入：我们首先跨时间关联骨骼以获取多个骨骼序列，每个序列都来自一个人。每个骨骼都由关键点（肩膀，手腕，头部等）的3D坐标表示。由于无线电信号的特性，不同的关键点在不同的时间实例反射不同数量的无线电信号，从而导致对关键点位置的置信度发生变化（跨时间和跨关键点）。 因此，我们将骨架生成网络的预测置信度用作每个关键点的另一个输入参数。因此，每个骨架序列都是大小为4 × T × N j的矩阵，其中4表示空间尺寸加上置信度T是序列中的帧数，并且N j对应于骨架中关键点的数量。 &#160; 模型：我们的动作检测模型（图3中的绿色大框））具有以下三个模块： 1）基于注意力的特征学习网络，该网络从每个骨架序列中提取高级时空特征。 2）然后，我们将这些功能传递给多提案模块以提取提案-即每个与操作的开始和结束相对应的时间窗口。我们的多提案模块包含两个提案子网：一个用于为单人操作生成提案，另一个用于两人互动。 3）最后，我们使用生成的提案对相应的潜在特征进行裁剪和调整大小，并将每个裁剪后的动作段输入到分类网络中。分类网络首先通过执行2-way分类来确定此持续时间是否包含动作，从而改进时间建议。 &#160; 接下来，我们详细描述注意力模块和多提案模块。 &#160; 时空注意模块 我们学习使用基于时空注意力的网络进行动作识别的功能。我们的模型基于分层共现网络（HCN）。 HCN使用两种卷积流：对骨架关键点进行操作的空间流，以及随时间变化对骨架关键点的位置进行更改的时间流。HCN连接这两个流的输出，以从输入骨架序列中提取时空特征。然后使用这些功能来预测人类的行为。 &#160; 但是，从无线信号预测的骨骼可能不如人类标记的骨骼那么准确。同样，不同的关键点可能具有不同的预测误差。为了使我们的动作检测模型专注于具有更高预测置信度的身体关节，我们引入了时空注意力模块。 具体来说，我们定义可学习的掩码权重W m，并在每个步骤将其与潜在的空间特征f s和时间特征f t进行卷积： &#160; M a s k = C o n v （c o n c a t （f s，f t），W m）。 然后，我们将M a s k应用于潜在特征，如图所示。通过这种方式，面罩可以学习为不同的关节提供不同的重量，以获得更好的动作识别性能。我们还添加了一个多头注意力模块。 &#160; 在特征提取后的时间维度上学习不同时间戳的注意。 &#160; 时空注意模块。我们建议的注意力模块（黄色框）学习面具，使模型更专注于身体关节，并具有更高的预测置信度。它还使用多头注意力模块来帮助模型更多地参与有用的时间实例。 &#160;]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div class="htmledit_views" id="content_views">
<p>&nbsp;</p>
<p><strong>介绍</strong></p>
<p>了解人们的行为和互动通常取决于看到他们。从视觉数据中自动进行动作识别的过程已成为计算机视觉界众多研究的主题。但是如果太暗，或者人被遮挡或在墙壁后面怎么办？在本文中，我们介绍了一个神经网络该模型可以在光线不足的情况下通过墙壁和遮挡物检测人类的行为。我们的模型将射频（RF）信号作为输入，生成3D人体骨骼作为中间表示，并随着时间的推移识别多个人的动作和互动。通过将输入转换为基于中间骨架的表示形式，我们的模型可以从基于视觉的数据集和基于RF的数据集中学习，并允许这两个任务互相帮助。我们表明，在可见场景中，我们的模型可以达到与基于视觉的动作识别系统相当的准确性，但是在看不见人的情况下，该模型仍可以继续正常工作，因此可以解决超出当今基于视觉的动作识别的局限性的场景。</p>
<p>&nbsp;</p>
<p><strong>先来看一组动图</strong></p>
<p>&nbsp;</p>
<p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019092910380054.gif"></p>
<p>&nbsp;</p>
<p>墙后动作可识别</p>
<p>&nbsp;</p>
<p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190929103840418.gif"></p>
<p>黑暗环境可识别</p>
<p>&nbsp;</p>
<p>他们的模型将射频（RF）信号作为输入，生成3D人体骨架作为中间表示，并随着时间的推移识别多个人的动作和互动。</p>
<p>&nbsp;</p>
<p><img alt="" class="has" height="323" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190929103855677.gif" width="480"></p>
<p>多人模式可识别</p>
<p>&nbsp;</p>
<p>在本文中，我们旨在弥合两个世界。我们引入了RF-Action，这是一个端到端的深度神经网络，可以识别无线信号中的人类动作。它的性能可与基于视觉的系统相媲美，但可以穿过墙壁和遮挡物，并且对光照条件不敏感。图1显示了RF-Action在两种情况下的性能。在左侧，两个人握手，但其中一个被遮挡。基于视觉的系统将无法识别动作，而RF-Action轻松将其归类为握手。在右侧，一个人正在打电话，而另一个人将要向他扔东西。由于光线不佳，基于视觉的系统几乎看不到后者。相反，RF-Action可以正确识别两个动作。</p>
<p>&nbsp;</p>
<p>RF-Action基于多模式设计，可与无线信号和基于视觉的数据集一起使用。我们利用最近的工作显示即推断人类骨骼（即，姿势）从无线信号的可行性&nbsp; ，并采用骨架作为适合于RF和基于视觉的系统的中间表示。使用骨架作为中间表示是有利的，</p>
<p>因为：</p>
<p>（1）它使模型与RF和视觉数据来训练，并利用现有的基于视觉的三维骨骼数据集如PKU-MMD和NTU-RGB + d &nbsp;[ 26，31 ];&nbsp;</p>
<p>（2）它允许对中间骨骼进行额外的监督，从而有助于指导学习过程，而不仅仅是过去基于RF的动作识别系统中使用的单纯动作标签；</p>
<p>（3）由于骨架表示受环境或主体身份的影响最小，因此提高了模型推广到新环境和新人的能力。</p>
<p>&nbsp;</p>
<p>我们通过两项改进其性能的创新进一步扩展了我们的模型：首先，骨骼，尤其是从RF信号生成的骨骼，可能会出现错误和错误预测。为了解决这个问题，我们的中间表示除了骨架之外还包括每个关节上随时间变化的置信度得分。我们使用自我关注来允许模型随着时间的推移以不同的方式关注不同的关节，具体取决于它们的置信度得分。</p>
<p>&nbsp;</p>
<p>其次，过去的动作识别模型可以随时生成单个动作。但是，场景中的不同人可能会采取不同的动作，如图1右图所示，一个人在电话上交谈，而另一个人在扔物体。我们的模型可以使用专门设计用于解决此问题的多提案模块来解决此类情况。</p>
<p>&nbsp;</p>
<p>为了评估RF-Action，我们使用无线设备和多摄像头系统收集了来自不同环境的动作检测数据集。该数据集跨越25个小时，包含30个执行各种单人和多人动作的个人。我们的实验表明，RF-Action在可见场景中的性能可与基于视觉的系统相媲美，并且在存在完全遮挡的情况下仍能继续保持良好的性能。具体来说，RF-Action在无遮挡的情况下可达到87.8的平均平均精度（mAP），在穿墙场景中的mAP为83.0。我们的结果还表明，多模式训练可以改善视觉和无线模式的动作检测。使用RF数据集和PKU-MMD数据集训练模型，我们观察到测试集的mAP性能从83.3提高到87。</p>
<p>&nbsp;</p>
<p>贡献：本文有以下贡献：</p>
<p>&nbsp;</p>
<ul>
<li>
<p>它提出了第一个使用无线电信号进行基于骨骼的动作识别的模型；它进一步证明了这种模型可以仅使用RF信号（如图1所示）就可以准确识别穿过墙壁的动作和相互作用，并且在极端恶劣的照明条件下。</p>
<p>&nbsp;</p>
</li>
<li>
<p>本文提出了“骨架”作为跨各种形式来传递与动作识别相关的知识的中间表示，并通过经验证明这种知识传递可以提高绩效。</p>
<p>&nbsp;</p>
</li>
<li>
<p>本文介绍了一个新的时空注意模块，该模块改进了基于骨骼的动作识别，而不管骨骼是从RF还是基于视觉的数据生成的。</p>
<p>&nbsp;</p>
</li>
<li>
<p>它还提出了一种新颖的多提案模块，该模块扩展了基于骨骼的动作识别以检测多个人同时进行的动作和互动。</p>
</li>
</ul>
<p><img alt="" class="has" height="482" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190929103929824.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hhaGFiZWliZWkxMjM0NTY3ODk=,size_16,color_FFFFFF,t_70" width="637"></p>
<p>该图显示了我们系统的两个测试用例。在左侧，两个人握手，而其中一个在墙后。在右边，一个人躲在黑暗中，向另一个正在打电话的人扔东西。底行显示了由我们的模型生成的骨骼表示和动作预测。</p>
<p>&nbsp;</p>
<p><strong>相关知识</strong></p>
<p>&nbsp;</p>
<p>（a）基于视频的动作识别：&nbsp;</p>
<p>在过去的几年中，从视频中识别动作一直是一个热门话题。早期方法使用手工制作的功能。为实例，像HOG和SIFT图像描述符已经被扩展到3D 来提取视频时间线索。此外，诸如改进的密集轨迹（iDT）之类的描述符是专门设计用来跟踪视频中的运动信息的。</p>
<p>最新的解决方案基于深度学习，分为两大类。</p>
<p>第一类通过利用三维卷积网络提取运动和外观特征共同。</p>
<p>第二类分别通过使用两个流神经网络考虑空间特征和时间特征。</p>
<p>&nbsp;</p>
<p>（二）基于骨架行为识别：基于骷髅动作识别最近获得广泛关注。这种方法具有多个优点。</p>
<p>首先，骨骼为人类动态提供了一种强大的表现力来抵抗背景噪声[ 23 ]。</p>
<p>其次，与RGB视频相比，骨骼更为简洁，这减少了计算开销，并允许使用更小的模型来适合移动平台。</p>
<p>&nbsp;</p>
<p>基于骨骼的动作识别的先前工作可以分为三类。早期工作使用递归神经网络（RNN）对骨架数据中的时间依赖性进行建模。</p>
<p>&nbsp;</p>
<p>然而，最近，文献转向了卷积神经网络（CNN），以学习时空特征并取得了令人印象深刻的性能。</p>
<p>&nbsp;</p>
<p>此外，某些文件表示的骨架作为动作识别图形和利用图形神经网络（GNN）。</p>
<p>在我们的工作中，我们采用基于CNN的方法，并通过引入时空注意模块来处理从无线信号生成的骨骼，并在多提案中扩展了分层共现网络（HCN）模型。</p>
<p>模块以同时启用多个动作预测。</p>
<p>（C）无线电的基于动作的识别：&nbsp;</p>
<p>研究在无线系统中已经使用无线电信号探索动作识别，特别是用于家庭应用，其中隐私问题可以排除使用摄像机 。</p>
<p>这些作品可以分为两类：</p>
<p>第一类类似于RF-Action，因为它可以分析从人体反弹的无线电信号。他们用行动标签监督，简单分类。</p>
<p>他们只能识别简单的动作（例如步行，坐着和跑步），最多只能识别10个不同的动作。</p>
<p>而且，它们仅处理单人场景。</p>
<p>第二类依赖于传感器网络。</p>
<p>他们或者部署不同传感器，用于不同的动作，（例如，在冰箱门上的传感器可检测的饮食），或贴在每个主体部的可穿戴式传感器和基于其上的身体部位移动识别被摄体的动作。</p>
<p>这样的系统需要对环境或人的大量检测，这限制了它们的实用性和鲁棒性。</p>
<p>&nbsp;</p>
<p><strong>射频信号入门</strong></p>
<p>&nbsp;</p>
<p><img alt="" class="has" height="385" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190929103946698.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hhaGFiZWliZWkxMjM0NTY3ODk=,size_16,color_FFFFFF,t_70" width="610"></p>
<p>同时记录RF热图和RGB图像。</p>
<p>我们使用在过去的工作常用于基于RF的动作识别一种类型的无线电的。</p>
<p>无线电会产生一个称为FMCW的波形，并在5.4至7.2 GHz之间工作。</p>
<p>&nbsp;</p>
<p>该设备具有垂直和水平排列的两个天线阵列。</p>
<p>&nbsp;</p>
<p>因此，我们的输入数据采用二维热图的形式，一个来自水平阵列，一个来自垂直阵列。如图2所示，水平热图是无线电信号在平行于地面的平面上的投影，而垂直热图是信号在垂直于地面的平面上的投影（红色表示大值，蓝色表示小值）。直观地，较高的值对应于来自某个位置的信号反射的强度更高。</p>
<p>&nbsp;</p>
<p>无线电以30 FPS的帧速率工作，即每秒产生30对热图。</p>
<p>&nbsp;</p>
<p>如图所示，RF信号与视觉数据具有不同的属性，这使基于RF的动作识别成为一个难题。尤其是：</p>
<p>&nbsp;</p>
<p>穿过壁的频率中的RF信号的空间分辨率低于视觉数据。在我们的系统中，深度分辨率为10 cm，角度分辨率为10度。如此低的分辨率使得难以区分诸如挥手和梳头等活动。</p>
<p>&nbsp;</p>
<p>人体在穿过墙壁的频率范围内镜面反射。RF镜面反射是当波长大于表面粗糙度时发生的物理现象。</p>
<p>在这种情况下，与散射体相反，物体的作用就像反射镜（即镜子）。我们收音机的波长约为5厘米，因此人类可以充当反射器。</p>
<p>根据每个肢体表面的方向，信号可能会反射到我们的传感器或远离我们的传感器。</p>
<p>反射信号远离无线电的肢体对于设备来说是不可见的。即使信号被反射回收音机，但表面较小的肢体（例如手）也会反射较少的信号，因此更难追踪。</p>
<p>&nbsp;</p>
<p>尽管RF信号可以穿过墙壁，但它们穿过墙壁时的衰减明显大于通过空气的衰减。结果，当人在墙壁后面时，从人体反射的信号较弱，因此，在存在墙壁和闭塞的情况下，检测动作的准确性降低。</p>
<p>&nbsp;</p>
<p><img alt="" class="has" height="203" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190929104006468.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hhaGFiZWliZWkxMjM0NTY3ODk=,size_16,color_FFFFFF,t_70" width="679"></p>
<p>RF-Action架构。RF-Action从无线信号中检测人为行为。它首先从原始无线信号输入（黄色框）中提取每个人的3D骨架。然后，它对提取的骨架序列（绿色框）执行动作检测和识别。动作检测框架还可以将从视觉数据生成的3D骨架作为输入（蓝色框），从而可以使用RF生成的骨架和现有的基于骨架的动作识别数据集进行训练。</p>
<p><strong>方法</strong></p>
<p>RF-Action是一种端到端的神经网络模型，可以通过遮挡和不良照明来检测人类行为。</p>
<p>模型架构如图所示，该模型将无线信号作为输入，生成3D人体骨骼作为中间表示，并随着时间的推移识别多个人的动作和交互。</p>
<p>&nbsp;</p>
<p>该图进一步显示，RF-Action还可以获取从视觉数据生成的3D骨架。</p>
<p>这允许RF-Action与现有的基于骨骼的动作识别数据集一起训练。</p>
<p>&nbsp;</p>
<p>在本节的其余部分中，我们将描述如何将无线信号转换为3D骨架序列，以及如何从此类骨架序列（即图3中的黄色和绿色框）推断动作。从多相机系统到3D骨架转化可视数据可以通过使用像AlphaPose的算法提取图像的二维骨架，然后进行三角测量的2D关键点，以生成三维骨架来完成。</p>
<p>&nbsp;</p>
<p><strong>a.无线信号的骨架生成</strong></p>
<p>为了从无线信号生成人体骨骼，我们采用其中的架构。具体来说，骨架生成网络（图中橙色框）的水平和垂直热图的形式接收无线信号。</p>
<p>&nbsp;</p>
<p>，并生成多人3D骨架。网络的输入是水平和垂直热图的3秒窗口（90帧）。该网络由三个通常用于姿势/骨架估计的模块组成。</p>
<p>&nbsp;</p>
<p>首先，包括时空卷积的特征网络从输入的RF信号中提取特征。然后，将提取的特征通过区域提议网络（RPN）以获得针对可能的骨架边界框的多个提议。最终，将提取的提案输入3D 姿势估计子网，以从每个提案中提取3D骨架。</p>
<p>&nbsp;</p>
<p><strong>b.与模式无关的动作识别</strong></p>
<p>如图所示，与模式无关的动作识别框架使用从RF信号生成的3D骨架来执行动作检测。</p>
<p>&nbsp;</p>
<p>输入：我们首先跨时间关联骨骼以获取多个骨骼序列，每个序列都来自一个人。每个骨骼都由关键点（肩膀，手腕，头部等）的3D坐标表示。由于无线电信号的特性，不同的关键点在不同的时间实例反射不同数量的无线电信号，从而导致对关键点位置的置信度发生变化（跨时间和跨关键点）。</p>
<p>因此，我们将骨架生成网络的预测置信度用作每个关键点的另一个输入参数。因此，每个骨架序列都是大小为4 × T × N j的矩阵，其中4表示空间尺寸加上置信度T是序列中的帧数，并且N j对应于骨架中关键点的数量。</p>
<p>&nbsp;</p>
<p>模型：我们的动作检测模型（图3中的绿色大框））具有以下三个模块：</p>
<p>1）基于注意力的特征学习网络，该网络从每个骨架序列中提取高级时空特征。</p>
<p>2）然后，我们将这些功能传递给多提案模块以提取提案-即每个与操作的开始和结束相对应的时间窗口。我们的多提案模块包含两个提案子网：一个用于为单人操作生成提案，另一个用于两人互动。</p>
<p>3）最后，我们使用生成的提案对相应的潜在特征进行裁剪和调整大小，并将每个裁剪后的动作段输入到分类网络中。分类网络首先通过执行2-way分类来确定此持续时间是否包含动作，从而改进时间建议。</p>
<p>&nbsp;</p>
<p>接下来，我们详细描述注意力模块和多提案模块。</p>
<p>&nbsp;</p>
<p><strong>时空注意模块</strong></p>
<p>我们学习使用基于时空注意力的网络进行动作识别的功能。我们的模型基于分层共现网络（HCN）。</p>
<p>HCN使用两种卷积流：对骨架关键点进行操作的空间流，以及随时间变化对骨架关键点的位置进行更改的时间流。HCN连接这两个流的输出，以从输入骨架序列中提取时空特征。然后使用这些功能来预测人类的行为。</p>
<p>&nbsp;</p>
<p>但是，从无线信号预测的骨骼可能不如人类标记的骨骼那么准确。同样，不同的关键点可能具有不同的预测误差。为了使我们的动作检测模型专注于具有更高预测置信度的身体关节，我们引入了时空注意力模块。</p>
<p>具体来说，我们定义可学习的掩码权重W m，并在每个步骤将其与潜在的空间特征f s和时间特征f t进行卷积：</p>
<p>&nbsp;</p>
<p>M a s k = C o n v （c o n c a t （f s，f t），W m）。</p>
<p>然后，我们将M a s k应用于潜在特征，如图所示。通过这种方式，面罩可以学习为不同的关节提供不同的重量，以获得更好的动作识别性能。我们还添加了一个多头注意力模块。</p>
<p>&nbsp;</p>
<p>在特征提取后的时间维度上学习不同时间戳的注意。</p>
<p>&nbsp;</p>
<p><img alt="" class="has" height="634" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190929104029170.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hhaGFiZWliZWkxMjM0NTY3ODk=,size_16,color_FFFFFF,t_70" width="622"></p>
<p>时空注意模块。我们建议的注意力模块（黄色框）学习面具，使模型更专注于身体关节，并具有更高的预测置信度。它还使用多头注意力模块来帮助模型更多地参与有用的时间实例。</p>
<p>&nbsp;</p>
<p><strong>多方案模块</strong></p>
<p>&nbsp;</p>
<p>以前的大多数动作识别数据集在任何时间都只有一个动作（或交互作用），而不管存在的人数如何。</p>
<p>&nbsp;</p>
<p>结果，先前的骨架动作识别方法无法处理多个人同时执行不同动作的情况。</p>
<p>&nbsp;</p>
<p>当场景中有多个人时，他们只是简单地对从每个人提取的特征进行最大化，然后转发结果组合的特征以输出一个动作。</p>
<p>因此，他们一次只能预测一个动作。</p>
<p>&nbsp;</p>
<p>但是，在我们的数据集中，当场景中有多个人时，他们可以随时执行任何操作或彼此互动。</p>
<p>&nbsp;</p>
<p>因此，在许多情况下，多个人同时在做动作和互动。</p>
<p>&nbsp;</p>
<p>我们通过多提案模块解决了这个问题。具体来说，表示N是同时出现的人数。而不是执行的MAX-汇集了N个功能，我们的多提案模块输出 N + （ N 2）来自这N个功能的提案，对应于N个可能的单人操作和（ N2）每两个人之间可能的互动。</p>
<p>&nbsp;</p>
<p>我们的多提案模块使我们能够同时输出多个动作和交互。</p>
<p>&nbsp;</p>
<p>最后，我们采用优先级策略，以优先于单人操作进行交互。</p>
<p>&nbsp;</p>
<p>例如，如果同时存在“指向某物”（单人）和“指向某人”（互动）的预测，那么我们的最终预测将是“指向某人”。</p>
<p>&nbsp;</p>
<p><strong>多模式端到端培训</strong></p>
<p>&nbsp;</p>
<p>由于我们想以端到端的方式训练模型，因此我们不再可以使用argmax可以提取3D关键点位置，就像过去基于RF的姿势估计 [45]一样。因此，我们使用回归器来执行 arg的功能max提取每个关键点的3D位置。这使模型具有可区分性，因此动作标签也可以充当对骨架预测模型的监督。</p>
<p>&nbsp;</p>
<p>我们的端到端架构使用3D骨架作为中间表示，这使我们能够利用以前基于骨架的动作识别数据集。</p>
<p>我们通过以下方式组合不同的模式来训练我们的模型：对于无线信号数据集，梯度在整个模型中向后传播，并用于调整骨架预测模型和动作识别模型的参数；</p>
<p>对于以前的基于骨骼的动作识别数据集，梯度会向后传播直到骨骼，然后将它们用于调整动作识别模块的参数。</p>
<p>&nbsp;</p>
<p>如实验部分所示，这种多模式训练显着增加了数据多样性并改善了模型的性能。</p>
<p><img alt="" class="has" height="406" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190929104044961.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hhaGFiZWliZWkxMjM0NTY3ODk=,size_16,color_FFFFFF,t_70" width="652"></p>
<p>定性结果。该图显示了RF-Action在各种情况下的输出。前两行显示了模型在可见场景中的性能。最下面的两行显示了我们模型在部分/完全遮挡和不良光照条件下的性能。所示的骨架是由我们的模型生成的中间3D骨架的2D投影。</p>
<p>&nbsp;</p>
<p><strong>实验</strong></p>
<p><strong>数据集</strong></p>
<p>由于没有可用的动作检测数据集提供RF信号和相应的骨骼，因此我们收集了我们自己的数据集，我们将其称为RF多模态数据集（RF-MMD）。</p>
<p>&nbsp;</p>
<p>我们使用无线电设备收集RF信号，并使用具有10个不同视点的摄像头系统收集视频帧。</p>
<p>无线电设备和摄像头系统在10毫秒内同步。</p>
<p>&nbsp;</p>
<p>附录A包含对我们的数据收集系统的更详细描述。</p>
<p>&nbsp;</p>
<p>我们在10个不同环境中（包括办公室，休息室，走廊，走廊，演讲室等）与30名志愿者收集了25小时的数据。我们从PKU-MMD的行动集中选择了35个行动（29个单一行动和6个互动）。</p>
<p>&nbsp;</p>
<p>对于每10分钟的数据，我们要求最多3名志愿者从上述集合中随机执行不同的操作。</p>
<p>平均而言，每个样本包含1.54名志愿者，每个志愿者在10分钟内执行43项操作，每项操作耗时5.4秒。</p>
<p>&nbsp;</p>
<p>我们使用20个小时的数据集进行训练，并使用5个小时进行测试。</p>
<p>&nbsp;</p>
<p>该数据集还包含2种通透方案，其中一种用于训练，一种用于测试。对于这些穿墙环境，我们将摄像头放在墙壁的每一侧，以便可以使用无线电设备对摄像头系统进行校准，并使用可以看到人员的摄像头来标记动作。</p>
<p>&nbsp;</p>
<p>RF-MMD上的所有测试结果仅使用无线电信号，而无需基于视觉的输入。</p>
<p>&nbsp;</p>
<p>我们使用多视角相机系统提取3D骨架序列。</p>
<p>我们首先将AlphaPose 应用于我们的相机系统收集的视频，以提取多视图2D骨架。</p>
<p>由于场景中可能有多个人，因此我们将每个视图的2D骨架关联起来，以获得每个人的多视图2D骨架。</p>
<p>之后，由于我们的相机系统已经过校准，因此我们可以对每个人的3D骨骼进行三角剖分。这些3D骨架充当我们模型生成的中间3D骨架的监督。</p>
<p>&nbsp;</p>
<p>最后，我们利用PKU-MMD数据集提供其他训练示例。</p>
<p>该数据集允许进行动作检测和识别。它包含由66个主体执行的来自51个类别的近20,000个动作。该数据集使我们能够展示RF-Action如何从基于视觉的示例中学习。</p>
<p>&nbsp;</p>
<p><strong>设定</strong></p>
<p>&nbsp;在基于视频的动作检测文献中称为共同和骨架为基础的行动检测，我们评估我们的模型的使用在不同交叉点中值平均精度（MAP）的性能联盟之上（IoU）阈值θ。我们报告了mAP在θ = 0.1和θ = 0.5时的结果。</p>
<p>&nbsp;</p>
<p>&nbsp;要对我们提出的RF-Action模型进行端到端训练，我们需要两种类型的地面真相标签：3D人体骨骼来监督我们的中间表示，以及动作开始-结束时间和类别来监督模型的输出。使用AlphaPose和先前描述的多视图相机系统对3D骨骼进行了三角剖分。至于动作的持续时间和类别，我们使用多视角摄像头系统手动对每个人的动作进行分段和标记。</p>
<p>&nbsp;</p>
<p><strong>定性结果</strong></p>
<p>显示的定性结果说明了在各种情况下RF-Action的输出。</p>
<p>该图显示，即使不同的人同时执行不同的动作，RF-Action仍可以正确检测动作和交互，并且可以应对遮挡和恶劣的照明条件。因此，它解决了当今动作识别系统的多个挑战</p>
<p>&nbsp;</p>
<p><strong>不同型号的比较</strong></p>
<p>我们将RF-Action的性能与基于骨架的动作识别和基于RF的动作识别的最新模型进行了比较。我们将HCN用作计算机视觉中性能最高的基于骨骼的动作检测系统的代表。</p>
<p>&nbsp;</p>
<p>当前，它在此任务上达到了最佳准确性。</p>
<p>&nbsp;</p>
<p>我们使用Aryokee 作为基于RF的动作识别技术的代表。据我们所知，这是过去唯一基于RF的动作识别系统，除了分类之外还执行动作检测。</p>
<p>&nbsp;</p>
<p>原始的Aryokee代码适用于两个类别。因此，我们扩展了支持更多的课程。所有模型都在我们的RF动作识别数据集中进行了训练和测试。由于HCN将骨骼作为输入（与RF信号相反），因此我们为它提供了RF-Action生成的中间骨骼。这使我们可以在基于相同骨架的动作识别方面将RF-Action与HCN进行比较。</p>
<p><img alt="" class="has" height="276" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190929104103164.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hhaGFiZWliZWkxMjM0NTY3ODk=,size_16,color_FFFFFF,t_70" width="565"></p>
<p>RF-MMD数据集上的模型比较。该表显示了在不同IoU阈值θ下可见光和穿墙场景中的mAP 。由于HCN在骨骼上运行，并且为了公平起见，我们向其提供由RF-Action生成的基于RF的骨骼</p>
<p>&nbsp;</p>
<p>该表显示了在可见场景和穿墙场景下以无线信号作为输入进行测试的结果。如表所示，在两种测试条件下，RF-Action的性能均优于HCN。这表明了我们提出的模块的有效性。此外，我们还可以看到，在可见光和穿墙场景中，RF-Action的性能都大大优于Aryokee。这表明来自骨骼的额外监督以及RF-Action神经网络设计对于使用RF数据提供准确的性能非常重要。</p>
<p>&nbsp;</p>
<p><strong>不同模式的比较</strong></p>
<p>&nbsp;</p>
<p>接下来，我们研究在基于RF的骨骼与基于视觉的骨骼上操作时，RF-Action的性能。和以前一样，我们在训练集上训练RF-Action。但是，当进行推理时，我们要么向它提供来自测试集的输入RF信号，要么为它提供使用相机系统获得的可见地面真相骨架。表2显示了不同输入方式的结果。该表显示，对于可见的场景，对摄像机系统中的地面真实骨骼进行操作只会导致精度提高百分之几。这是可以预期的，因为RF骨架是使用基于视觉的骨架作为基本事实来训练的。此外，正如我们在实验设置中所述，基于摄像头的系统使用10个视点来估计3D骨架，而只有一个无线设备用于基于RF的动作识别。该结果表明，基于RF的动作识别可以实现接近经过精心校准的10个视点的摄像头系统的性能。该系统在穿墙场景中仍然可以正常工作，尽管由于信号在穿过墙时会受到一定程度的衰减，因此精度降低了百分之几。</p>
<p>&nbsp;</p>
<p><img alt="" class="has" height="220" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190929104118175.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hhaGFiZWliZWkxMjM0NTY3ODk=,size_16,color_FFFFFF,t_70" width="602"></p>
<p>在不同IoU阈值θ下，基于RF的骨骼（RF-MMD）和基于视觉的骨骼（GT骨骼）的RF动作性能（mAP）</p>
<p>&nbsp;</p>
<p><strong>动作检测</strong></p>
<p>在图中，我们显示了测试集上动作检测结果的代表性示例。这个实验有两个人参加。他们有时会独立执行动作，或彼此互动。第一行显示第一人称的动作持续时间，第二行显示第二人称的动作持续时间，第三行显示它们之间的交互。我们的模型可以高精度地检测每个人的动作以及他们之间的互动。这清楚地表明，在多个人独立执行某些动作或彼此交互的情况下，我们的多提案模块具有良好的性能</p>
<p><img alt="" class="has" height="260" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190929104137337.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2hhaGFiZWliZWkxMjM0NTY3ODk=,size_16,color_FFFFFF,t_70" width="654"></p>
<p> 测试集上的动作检测结果示例，其中两个人正在做动作以及彼此交互。实地行动部分以蓝色绘制，而使用我们的模型检测到的部分以红色绘制。水平轴是指帧号。</p>
<p>&nbsp;</p>
<p><strong>结论</strong></p>
<p>本文介绍了第一个使用无线电信号进行基于骨骼的动作识别的模型，并证明了该模型可以识别在墙壁和极端恶劣的光照条件下的动作和相互作用。新模型可在由于隐私问题或可见性差而难以使用相机的环境中实现动作识别。因此，它可以将动作识别带入人们的家中，并允许其集成到智能家居系统中。</p>
<p>相关论文源码下载地址：关注“<strong>图像算法</strong>”微信公众号，回复<strong>穿墙术</strong></p>
</p></div>
</div>
]]></content:encoded>
										</item>
		<item>
		<title>学习笔记之——水下图像增强/复原</title>
		<link>https://uzzz.org/article/2345.html</link>
				<pubDate>Mon, 29 Jul 2019 07:34:41 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[图像处理]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/2345.html</guid>
				<description><![CDATA[本博文为本人调研水下图像增强时做的一些笔记。可能整理得不是很清晰，仅仅供个人学习记录用~欢迎各位交流~ &#160; 目录 背景 研究现状（常用的方法） 非物理模型的图像增强方法 白平衡方法 直方图均衡化方法 基于Retinex的方法 基于暗通道先验的方法（去雾的方法） 基于卷积神经网络的方法 基于物理模型的图像复原方法 水下图像成像理论 水下成像系统 水下散射模型 水下退化图像模糊类型 高斯模糊 运动模糊 散焦模糊 图像质量评价标准 参考资料： &#160; 背景 对于水下作业，特别是水下机器人作业等场景，水下图像增强具有广阔得应用前景（水下机器人主要是靠它的视觉系统来判断周围的环境信息，水下机器人的视觉系统就好比人体的眼睛，它可以为机器人提供了水下目标位置信息，根据目标的位置信息，研究人员可以对目标进行监测与追踪，它还可以将获得的环境实时状态一起抽象为供机器人管理的环境模型。）。基于声视觉和基于光视觉的水下目标检测识别技术是目前主流的水下目标检测识别技术。基于声视觉的水下目标检测识别技术是通过声呐实现的，但其图像信息采集能力弱，生成图像清晰度低。基于光视觉的水下目标检测识别技术则是通过光视觉传感器实现的，成像分辨率高的光视觉传感器更适用于短距离的目标识别和精确定位。二者相比，基于光视觉的水下目标检测识别技术在水下捕捞机器人应用中优势更为明显 基于光学的水下小目标检测识别是水下捕捞机器人智能化作业的关键。然而，基于光视觉的水下目标检测识别技术同样面临着巨大的挑战，其主要原因是海洋复杂成像环境导致光视觉系统获取到的水下图像严重退化（水下图像的衰退主要包括：光线吸收导致的颜色偏差，光线前向散射导致的细节模糊和光线后向散射造成的低对比度），出现颜色衰退、对比度低以及细节模糊等现象。首先，由于水对光的吸收作用，光线在传输过程中就会发生能量衰减，在一般情况下，红光在水中衰减最快，衰减最慢的是蓝绿色光线；另外，由于光在水中的散射作用也会造成水下图像成像效果不好。散射效应又分为前向散射和后向散射，前向散射的意思是水中物体反射的光向摄像机传输的过程中发生的小角度偏离原来的传输方向的散射现象；后向散射的意思是光线在照射到水中物体时遇到水中的杂质就会发生散射直接被摄像机接收的散射现象，导致图像对比度低。 严重退化的水下图像由于缺少用于目标识别的有效信息，导致水下目标检测识别难度提升。随着高科技水下成像设备的发展，获取的水下图像的质量也得到了一定程度的提升，但仍然存在颜色衰退、对比度低以及细节模糊等现象，此外实际应用成本也是需要考虑的问题，因此对水下图像进行增强仍然有其必要性。 水下图像处理技术的算法可以根据是否基于水下成像模型分为图像增强算法和图像复原算法两种。图像增强方法是对得到的水下图像的像素点进行研究增强，算法过程中不需要考虑图像的形成过程和降质过程；图像复原方法是要根据水下图像的成像过程来获得出真实的情况。图像复原方法需要水体的光学参数、摄像机参数和摄像机与目标物体的距离等信息，这些信息都要通过人工测量或其他方法估测出这些值。 水下视觉探测技术的重点和难点有两个方面，一是水下光传感设备参数的标定，另一个是水下模糊图像的复原。由于水质的复杂性，导致光线在水下的传播有折射、散射等现象，同时可能存在的浑浊水质也是导致水下图像退化的主要原因，水下图像就因为这种降质因素产生了严重的模糊。目前科学技术处理这种模糊还存在一定的难度。由于无法获得原始的水下清晰图像，以及无法精确测量到导致水下图像发生退化的模糊函数，水下图像复原技术的应用一直受到限制，也间接限制了水下探测等技术的发展。因此如何根据水下图像的形成机制和水下图像发生退化的原因，建立一个合理的水下图像退化的物理模型，同时使得该物理模型能够实际应用，能够通过软硬件手段估计得到模糊函数来复原水下图像是目前的研究重点，具备实际的研究价值和意义。(由于水下环境的复杂，且难以获得ground truth，故此若采用DL来做，其中一个难点就是如何获取成pair的训练数据，除非采用无监督学习) &#160; 研究现状（常用的方法） 受水下光传播过程中的衰减和散射的影响，在纯水区域中，水下能见度一般为20m，在浑浊海水中的能见度一般只有&#160;5m。 McGlamery在&#160;1979&#160;年搭建了经典的计算机水下成像系统模型。他发现，摄像机水下成像系统获得到的光能量可以分成三个部分：直接传输的光能量、前向散射的光能量和后向散射的光能量。 在图像处理中，图像复原又叫做图像恢复，该项技术有着广泛的应用领域。同时图像复原技术又与其他图像技术之间有着一定的联系，比如：与图像增强相比，两种技术在一定程度上都是针对图像进行改善，从而提高图像质量。但是这两项技术有着不一样的图像质量评价指标和不同的设计算法。相对而言，图像增强一般是增强视觉感受，偏向于人的主观判断，丢失的细节信息不会得到修复。而图像复原计算则是根据图像退化的模型，进行图像建模，设计一定的代价函数来优化逆问题，从而估计出原始图像和模糊函数。经典的图像复原方法一般都是基于先验知识设计的，已知的先验知识越多，复原出来的效果就越好。但是，在实际应用中，先验知识往往都是未知的。因此经典的方法限制了实际的应用。 已知图像在采集、传输、储存和处理过程中，会出现畸变、模糊、失真和附加噪声的影响，造成图像发生降质，这种现象一般称为图像退化。图像复原的关键在于建立图像退化模型，此退化模型应该能反映图像退化的原因。造成图像退化的原因很多，典型原因表现为：成像系统的像差、畸变、带宽有限造成图像失真；太阳辐射、大气湍流、云层遮挡等造成的遥感图像失真；由于成像器件拍摄姿态和扫描非线性引起的图像几何失真；成像传感器与被拍摄景物之间的相对运动，引起所成图像的运动模糊；光学系统或成像传感器本身特性不均匀，造成同样亮度景物成像灰度不同；由于场景能量传输通道中的介质特性如大气湍流效应、大气成分变化引起图像失真；图像在成像、数字化、采集和处理过程中引入的噪声等。 （tips：傅里叶变换是一种频域变换，是将图像的空间域信息转换到频率域中，傅里叶变换的应用一般是将在空域中不明显的信息或隐藏的信息转换到频域中，使其在频域中很明显地显现出来。） 传统的图像增强方法有很多种，主要分为两大部分：空域图像处理和频域图像处理。空域图像处理方法直接针对图像的像素点，以灰度映射为基础来改善灰度层级，例如直方图均衡化、限制对比度直方图均衡化、灰度世界假设等，此外，还可以通过滤波的方式对图像去除噪声达到图像增强的目的，例如中值滤波、均值滤波等；频域图像增强方法则通过各种频域变换，如傅里叶变换、小波变换等，可以间接地增强图像。国内外很多学者采用空域和频域方法对水下图像进行了增强，传统的图像增强算法在一定程度上可以消除图像模糊、增强边缘等，但仍存在噪声大、清晰度较低和颜色失真等问题，因此还需要进一步加强和完善。 目前，用于增强或复原水下图像的处理方法大致可分为非物理模型的图像增强方法和基于物理模型的图像复原方法。 非物理模型的图像增强方法 图像增强技术不必过多考虑图像成像的过程和模型，可以叫非物理模型方法，这种方法力图通过单纯的图像处理手段提高水下图像质量，通过调整图像的像素值来改善视觉质量，不过实现过程往往较为复杂。 该类方法采用直接调整图像像素值的方式改善图像质量，并不考虑水下图像退化的物理过程（就是没有考虑退化模型、水下得信道），属于图像增强范畴。 在水下图像增强技术研究早期，对水下图像的处理经常直接应用一些空气中传统的的图像增强算法，传统的图像增强算法可以分为空间域法与频域法。空间域方法是对图像中的像素点直接处理，采用灰度映射的方法，比如选取合适的映射变换来增加图像的对比度，改善图像灰度级等。频域法是一种间接的图像处理方法，运用变换技术把图像映射到某种变换域内，然后利用变换域中特有性质进行某种滤波处理，再反变换到空间域内，即得到增强后的图像。常被应用到水下图像传统空间域增强算法有直方图均衡化、限制对比度直方图均衡化、灰度世界假设和白平衡算法等，频域增强算法有傅里叶变换、小波变换和滤波技术，主要包括低通滤波，高通滤波和同态滤波等。目前图像增强算法往往存在可能只是对某一类的图像增强效果好，而其他类型的效果不好的特点，而且由于水下环境的特殊性，仅仅通过研究把传统的图像增强算法应用在水下图像上无法彻底解决水下图像退化问题。 水下图像増强算法研究早期，传统的图像处理方法，例如白平衡，灰度世界假设和灰度边缘假设等颜色修正算法，直方图均衡化和限制对比度直方图均衡化等对比度增强算法，多被用来增强水下图像。相比于处理普通图像获取的较好的结果，这些方法在处理水下图像获取的结果并不理想，其主要原因是海洋环境复杂，多重不利因素如水介质对光线的散射、吸收作用以及水下悬浮粒子等对其产生严重干扰。考虑到水下图像存在的颜色衰退、低对比度以及模糊等特点，研究人员往往从图像颜色、对比度、细节等方面入手对水下图像进行增强。 白平衡方法 在不同光源照射下，观察同一个物体会发现其呈现的颜色是不同的，原因是不同光源具有的不同色温造成目标物体的反射光线光谱偏离其“真实”颜色。当同一白色目标物体在被高色温光源照射（如阴天时）将会表现为蓝色，被低色温光源照射（如床头灯等）将会表现为姜黄色。白平衡方法能够根据图像所呈现的色温纠正图像的色彩偏差，其具体实现过程建立在朗伯特反射模型上。 朗伯特反射模型表示反射图像主要与三项因素有关：光源光谱分布、物体表面的反射率以及成像设备感光函数。针对彩色图像，即包含ＲＧＢ三个颜色通道的图像，图像呈现的场景中某物体表面上的空间坐标点x的颜色可用朗伯特反射模型表示为： 白平衡方法以上述朗伯特反射模型为基础，考虑到传统的以标准白色参照物进行颜色校准的白平衡方法在实际应用中具有很大的局限性，研宄人员提出了多种白平衡算法纠正图像的色彩偏差。白平衡方法应用场景一般为普通偏色情况，对于并不严重的偏色可以起到较好的恢复作用，但是水下偏色情况一般较为严重，因此需要继续研究可以对水下颜色衰退起到良好恢复作用的白平衡算法。 直方图均衡化方法 将图像的灰度直方图从较为集中的某灰度区间均匀拉伸至全部灰度范围内，用以扩大图像灰度值的分布范围，提升图像对比度并突出部分细节效果。 &#160; 基于Retinex的方法 Retinex&#160;理论是&#160;20&#160;世纪&#160;70&#160;年代最早由&#160;Land提出的一种基于颜色恒常性的理论，该理论基于三个假设：（1）真实世界是无颜色的，人类所见到的颜色是光与物体相互作用的结果；（2）每一种颜色由红、绿、蓝三原色组成的；（3）三原色决定了每个单位区域的颜色。Retinex&#160;算法可以对不同类型的图像进行自适应增强，比传统的单一的图像增强算法具有更好的自适应性，因为传统的增强算法只能增强图像的某一类特征，而Retinex&#160;增强算法则可以在动态范围内压缩、细节增强和颜色校正等方面达到较好的平衡效果，因此，Retinex&#160;理论得到了广泛的发展和应用。 &#160; 基于暗通道先验的方法（去雾的方法） DCP是一种去雾的图像增强方法（恺明神提出的方法）。接下来会写一篇博客专门对这种方法进行分析。 对于水下图像增强而言，跟去雾有很多相似的特性。故此在去雾中的一些方法也适用于水下图像增强。 &#160; &#160; 基于卷积神经网络的方法 基于卷积网络的图像去雾、去模糊、图像盲复原等任务跟水下图像增强有异曲同工之妙。但是关键点在于训练集的获取以及卷积模型的泛化能力上。 其实对于运算量和实时性而言。个人觉得卷积网络只要训练好了，后面的使用过程是非常方便的。但是对于水下如此复杂的退化环境，要训练出一种泛化能力足够强的网络才是难点所在。与此同时，需要有相应的数据集的定制，也是难点所在。 &#160; &#160; 基于物理模型的图像复原方法 该类方法针对水下图像退化过程构建数学模型，通过该模型反演图像退化过程，获得理想状态下未经退化的图像，属于图像复原范畴。（两种方法感觉好像有点类似于图像复原中的成pair的训练和不成pair的训练） 水下图像复原技术是基于物理模型的方法，是指对水下图像退化过程搭建一个合理的数学模型估算出模型参数信息，了解整个图像的退化过程使水下图像恢复到退化前的状态。图像复原技术适用范围更广，但是往往需要场景先验信息或深度信息来实现图像复原。 受图像处理和质量衡量方法的多样性的影响，对于水下图像处理结果的选取只能从其应用目的和场合入手，水下图像增强算法的研究仍然有待深入研究和完善。海洋的环境多种多样，必须要用应用的目的和场合入手来进行合适的水下图像增强。 &#160; 水下图像成像理论 海水是一种化学成分非常复杂的混合物，它包含着以物理化学形态存在的各种元素，通常在海水中还含有悬浮体和各种活性有机体，如细菌、浮游生物和矿物颗粒等，使得海水存在不均匀性。水中悬浮颗粒的存在，使得光线在水下容易发生折射、散射，同时水对光线具有一定的吸收和衰减特性。即使是经过过滤的最纯净的水，它对光的衰减也是很严重的。实验表明，水的衰减是光波长的复函数，它是由两个不相关的物理过程（即吸收和散射）引起的，因此光在水中传输时的能量按指数规律迅速地衰减。一般对于清澈的海水，60％的衰减是由散射引起的，40％的衰减是由吸收引起的。 在水中，光是按照指数衰减的方式进行运动，这种衰减限制了相机到目标物的距离，并非常严重的影响了水下的成像系统的性能，通常情况下，吸收造成了光能量的损失，散射造成光传播方向的改变，前向散射是水下物体到摄像机的过程中发生小角度偏离的光线，这种散射造成了图像清晰度低，而后向散射是从存在的太阳光或者人工光源到摄像机的过程中遇到悬浮小颗粒散射到相机的偏离光，这种散射会造成图像对比度低。 &#160; 水下成像系统 水下成像系统获取的图像严重衰退，其主要原因是水下环境中能见度较低，清澈水中的能见度大约为二十米，浑浊水中的能见度则大约在五米之内。这种能见度降低源于光线在水中的衰减。朗伯－比尔经验定律表示，光线在媒介中以指数形式衰减，媒介的特性将直接影响光线的衰减程度。 根据光衰减模型 自然光入射到水中，水中介质对光线有散射和吸收的作用。水中光线衰减模型可以表示为： 水下成像系统如下图所示。其中，光线散射分为前向散射和后向散射，前向散射光作为目标表面反射或辐射经水中悬浮粒子散射后进入成像系统的光，将导致成像系统获取的图像呈现模糊的现象；后向散射光作为自然光入射到水体经悬浮粒子散射后进入成像系统的光，将导致成像系统获取的图像呈现低对比度的现象。采用人工光源对水下成像过程进行主动照明能够对上述现象起到一定程度的改善作用，但人工光源的光强以光量最强点为中心沿径向逐渐衰减，将导致获取的图像存在背景灰度不均、假轮廓、假细节和自阴影等情况，同时人工光源在浑浊水中能够发挥的作用非常有限。 水中介质对光线的散射作用会导致获取的图像存在模糊及低对比度的现象，而水介质对光线的吸收作用则将会造成获取的图像出现颜色衰退的现象。水对光的吸收在不同的光谱区域是不同的，具有明显的选择性。水对光谱中的红外和紫外部分表现出强烈地吸收。在可见光谱区段，吸收最大的是红色、黄色和淡绿色光谱区域。纯净水和清澈的海水在光谱的蓝一绿区域透射比量大，其中波长&#160;462~475nm&#160;的蓝光衰减最少。水的吸收足以使光的强度每米衰减约4％，而其他颜色则更多，几米之外几乎完全消失。 如下图所示。水介质对光线的吸收效应是有选择性的，即水介质对不同波长的光吸收程度不同，红色光、橙色光和黄色光基本会消失在大约五米、十米、二十米水深处，而随着水深的进一步增加，绿色光也会逐渐消失，而蓝色光在六十米水深处才会基本消失（而对于LED光源而言，主要是蓝色芯片发光的，故此可能在这个程度上，有利？）。因此，一般获取的水下图像皆呈现蓝绿色调。 &#160; 水下散射模型 相比于水对光的吸收作用，光在水中发生散射效应是造成水下图像降质的主要原因。 水体对自然光的散射作用受到水体中粒子的类别、大小和密度以及入射光的波长、角度以及偏振的共同影响（故此对于不同的海洋环境，有不同的粒子类别，散射模型也许也会不一样，从而大大增加了问题的多样性）。水下图像总照度=直接照射分量+前向散射分量+后向散射分量 直接照射分量是指经目标表面反射进入相机的并未被水体散射或吸收的光；前向散射分量是目标表面反射的经水中悬浮粒子散射后进入相机的光；后向散射分量则指的是自然光入射到水体后经悬浮粒子散射后进入相机的光。Jaffe-McGlamery模型假设光源以球状扩散并衰减，目标反射光可以由入射光和反射函数表示。直接照射分量的估计可以在假设目标物体为理想朗伯特体的基础上采用几何光学实现。前向散射分量是目标反射光在到达相机之前发生的小角度散射产生的，它的求解可以结合直接照射分量和点扩散函数的卷积算子实现。后向散射光进入相机的角度很广，其相应的后向散射分量则是通过体积散射函数对场景和相机之间的水体所分成的小水体进行加权，然后线性叠加得到的。该模型表示相机、成像范围、光源距离和水下环境都将对获取的水下图像产生影响。在短距离成像中，相机和光源简单组合即可获取质量较好的水下图像。在距离较长的成像范围内，独立相机和光源组成的系统将获取质量更好的水下图像，但是成像距离的增加将导致后向散射效应的凸显。 &#160; 水下退化图像模糊类型 由于不同水下环境的复杂性，因此造成水下图像发生退化的原因主要可以分为：噪声和模糊。其中水下模糊可以分为三种类型： 1、水体或鱼群等运动造成的运动模糊；2、水下光线的散射或相机镜头未能达到理想的对焦的情况下造成的散焦模糊；3、水下湍流造成的高斯模糊。 高斯模糊 高斯模糊函数是最常见的模糊，对成像系统和光学测量系统来说，许多因素共同决定了系统的退化函数，综合的结果就是使退化函数趋于高斯模型。光学相机和&#160;CCD&#160;摄像机、显微光学系统、CT&#160;机等等都属于这类系统。大气湍流和水下湍流也一样都会近似为高斯函数，其数学模糊可表示为： 运动模糊 运动模糊图像形成于目标的成像过程中，主要是因为在相机曝光的过程中拍摄目标与相机镜头之间发生相对位移而产生的一种图像退化现象，其数学模糊可表示为： 散焦模糊 一般，一个理想的点在成像平面上呈圆盘状光斑的现象叫做离焦模糊，这种模糊是由于成像系统未能达到理想的对焦状态而产生的。常采用的基于几何光学中提出的圆盘离焦模型，能很好的近似点扩散函数，有效解决离焦模糊的去模糊问题。用一个灰度值服从均匀分布的圆盘状光斑来表示&#160;PSF，其数学模糊可表示为： &#160; 图像质量评价标准 图像质量评价指标是评估图像处理算法好坏的重要指标。图像质量通常指图像逼真度和图像可懂度。在图像处理的许多技术中，如：压缩、增强、超分、去噪、去模糊、去摩尔纹、复原等，都会涉及到图像质量评价。图像质量的含义主要包括图像的逼真度和图像的可懂度两个方面，其质量主要受成像装备的光学性能、仪器噪声和成像条件等多种因素的影响。图像质量评价方法主要分为两类：分别为主观图像质量评价方法和客观质量评价方法 对于客观质量的评价方法又分为有参考和无参考评价 &#160; &#160; &#160; &#160; &#160; 参考资料： 《基于卷积神经网络的水下图像增强算法研究_丁雪妍》 《水下图像复原方法研究_王婷》 &#160; &#160; &#160; &#160; &#160; &#160; &#160;]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div class="htmledit_views" id="content_views">
<p>本博文为本人调研水下图像增强时做的一些笔记。可能整理得不是很清晰，仅仅供个人学习记录用~欢迎各位交流~</p>
<p>&nbsp;</p>
<p id="main-toc"><strong>目录</strong></p>
<p id="%E8%83%8C%E6%99%AF-toc" style="margin-left:0px;"><a href="#%E8%83%8C%E6%99%AF" rel="nofollow" data-token="43ffbd3b66c5e6f766785c82124d909e">背景</a></p>
<p id="%E7%A0%94%E7%A9%B6%E7%8E%B0%E7%8A%B6%EF%BC%88%E5%B8%B8%E7%94%A8%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%89-toc" style="margin-left:0px;"><a href="#%E7%A0%94%E7%A9%B6%E7%8E%B0%E7%8A%B6%EF%BC%88%E5%B8%B8%E7%94%A8%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%89" rel="nofollow" data-token="b506081c7f811bb30a5e64302d416100">研究现状（常用的方法）</a></p>
<p id="%E9%9D%9E%E7%89%A9%E7%90%86%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95-toc" style="margin-left:40px;"><a href="#%E9%9D%9E%E7%89%A9%E7%90%86%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95" rel="nofollow" data-token="a486d6cbf18bafcecd3bd622e2ce3bdf">非物理模型的图像增强方法</a></p>
<p id="%E7%99%BD%E5%B9%B3%E8%A1%A1%E6%96%B9%E6%B3%95-toc" style="margin-left:80px;"><a href="#%E7%99%BD%E5%B9%B3%E8%A1%A1%E6%96%B9%E6%B3%95" rel="nofollow" data-token="41214742c09973250be564f37065d008">白平衡方法</a></p>
<p id="%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1%E5%8C%96%E6%96%B9%E6%B3%95-toc" style="margin-left:80px;"><a href="#%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1%E5%8C%96%E6%96%B9%E6%B3%95" rel="nofollow" data-token="dec593f07ca9425a0ab7d319a1a00ae9">直方图均衡化方法</a></p>
<p id="%E5%9F%BA%E4%BA%8ERetinex%E7%9A%84%E6%96%B9%E6%B3%95-toc" style="margin-left:80px;"><a href="#%E5%9F%BA%E4%BA%8ERetinex%E7%9A%84%E6%96%B9%E6%B3%95" rel="nofollow" data-token="f86d94fa49880402ab52fcadc4150d95">基于Retinex的方法</a></p>
<p id="%E5%9F%BA%E4%BA%8E%E6%9A%97%E9%80%9A%E9%81%93%E5%85%88%E9%AA%8C%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%88%E5%8E%BB%E9%9B%BE%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%89-toc" style="margin-left:80px;"><a href="#%E5%9F%BA%E4%BA%8E%E6%9A%97%E9%80%9A%E9%81%93%E5%85%88%E9%AA%8C%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%88%E5%8E%BB%E9%9B%BE%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%89" rel="nofollow" data-token="9223e0a74d99fe69d053c26eb5ce4592">基于暗通道先验的方法（去雾的方法）</a></p>
<p id="%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%96%B9%E6%B3%95-toc" style="margin-left:80px;"><a href="#%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%96%B9%E6%B3%95" rel="nofollow" data-token="9a3e9e9fd6d032ac287019745c961621">基于卷积神经网络的方法</a></p>
<p id="%E5%9F%BA%E4%BA%8E%E7%89%A9%E7%90%86%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%8D%E5%8E%9F%E6%96%B9%E6%B3%95-toc" style="margin-left:40px;"><a href="#%E5%9F%BA%E4%BA%8E%E7%89%A9%E7%90%86%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%8D%E5%8E%9F%E6%96%B9%E6%B3%95" rel="nofollow" data-token="7319bb5906c0e905c8e2c8c2504d627d">基于物理模型的图像复原方法</a></p>
<p id="%E6%B0%B4%E4%B8%8B%E5%9B%BE%E5%83%8F%E6%88%90%E5%83%8F%E7%90%86%E8%AE%BA-toc" style="margin-left:0px;"><a href="#%E6%B0%B4%E4%B8%8B%E5%9B%BE%E5%83%8F%E6%88%90%E5%83%8F%E7%90%86%E8%AE%BA" rel="nofollow" data-token="0bb7c7b8e5b002a3737016296b0a2294">水下图像成像理论</a></p>
<p id="%E6%B0%B4%E4%B8%8B%E6%88%90%E5%83%8F%E7%B3%BB%E7%BB%9F-toc" style="margin-left:40px;"><a href="#%E6%B0%B4%E4%B8%8B%E6%88%90%E5%83%8F%E7%B3%BB%E7%BB%9F" rel="nofollow" data-token="9ca5b6455df7d8fd747f5cb66e774d21">水下成像系统</a></p>
<p id="%E6%B0%B4%E4%B8%8B%E6%95%A3%E5%B0%84%E6%A8%A1%E5%9E%8B-toc" style="margin-left:40px;"><a href="#%E6%B0%B4%E4%B8%8B%E6%95%A3%E5%B0%84%E6%A8%A1%E5%9E%8B" rel="nofollow" data-token="677083e33762071bc9b78669375411ac">水下散射模型</a></p>
<p id="%E6%B0%B4%E4%B8%8B%E9%80%80%E5%8C%96%E5%9B%BE%E5%83%8F%E6%A8%A1%E7%B3%8A%E7%B1%BB%E5%9E%8B-toc" style="margin-left:0px;"><a href="#%E6%B0%B4%E4%B8%8B%E9%80%80%E5%8C%96%E5%9B%BE%E5%83%8F%E6%A8%A1%E7%B3%8A%E7%B1%BB%E5%9E%8B" rel="nofollow" data-token="2f63afa877ac46f723b93fc52b51b3a5">水下退化图像模糊类型</a></p>
<p id="%E9%AB%98%E6%96%AF%E6%A8%A1%E7%B3%8A-toc" style="margin-left:40px;"><a href="#%E9%AB%98%E6%96%AF%E6%A8%A1%E7%B3%8A" rel="nofollow" data-token="7c8cbd7444abf3265bcf91a6031b56fc">高斯模糊</a></p>
<p id="%E8%BF%90%E5%8A%A8%E6%A8%A1%E7%B3%8A-toc" style="margin-left:40px;"><a href="#%E8%BF%90%E5%8A%A8%E6%A8%A1%E7%B3%8A" rel="nofollow" data-token="80e0a2392f689b13981d57e31d493f9f">运动模糊</a></p>
<p id="%E6%95%A3%E7%84%A6%E6%A8%A1%E7%B3%8A-toc" style="margin-left:40px;"><a href="#%E6%95%A3%E7%84%A6%E6%A8%A1%E7%B3%8A" rel="nofollow" data-token="2e4af6e4b8e3400bbf41fdc8f01e7621">散焦模糊</a></p>
<p id="%E5%9B%BE%E5%83%8F%E8%B4%A8%E9%87%8F%E8%AF%84%E4%BB%B7%E6%A0%87%E5%87%86-toc" style="margin-left:0px;"><a href="#%E5%9B%BE%E5%83%8F%E8%B4%A8%E9%87%8F%E8%AF%84%E4%BB%B7%E6%A0%87%E5%87%86" rel="nofollow" data-token="11eac6e46632864ef1b20468940e46dc">图像质量评价标准</a></p>
<p id="%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99%EF%BC%9A-toc" style="margin-left:0px;"><a href="#%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99%EF%BC%9A" rel="nofollow" data-token="8653358888c10b256501f768c062363f">参考资料：</a></p>
<hr id="hr-toc">
<hr>
<hr>
<p>&nbsp;</p>
<h1 id="%E8%83%8C%E6%99%AF">背景</h1>
<p>对于水下作业，特别是水下机器人作业等场景，水下图像增强具有广阔得应用前景（水下机器人主要是靠它的视觉系统来判断周围的环境信息，水下机器人的视觉系统就好比人体的眼睛，它可以为机器人提供了水下目标位置信息，根据目标的位置信息，研究人员可以对目标进行监测与追踪，它还可以将获得的环境实时状态一起抽象为供机器人管理的环境模型。）。基于声视觉和基于光视觉的水下目标检测识别技术是目前主流的水下目标检测识别技术。基于声视觉的水下目标检测识别技术是通过声呐实现的，但其图像信息采集能力弱，生成图像清晰度低。基于光视觉的水下目标检测识别技术则是通过光视觉传感器实现的，成像分辨率高的光视觉传感器更适用于短距离的目标识别和精确定位。二者相比，基于光视觉的水下目标检测识别技术在水下捕捞机器人应用中优势更为明显</p>
<p>基于光学的水下小目标检测识别是水下捕捞机器人智能化作业的关键。然而，基于光视觉的水下目标检测识别技术同样面临着巨大的挑战，其主要原因是海洋复杂成像环境导致光视觉系统获取到的水下图像严重退化（<strong>水下图像的衰退主要包括：光线吸收导致的颜色偏差，光线前向散射导致的细节模糊和光线后向散射造成的低对比度</strong>），出现颜色衰退、对比度低以及细节模糊等现象。首先，由于水对光的吸收作用，光线在传输过程中就会发生能量衰减，在一般情况下，红光在水中衰减最快，衰减最慢的是蓝绿色光线；另外，由于光在水中的散射作用也会造成水下图像成像效果不好。散射效应又分为前向散射和后向散射，前向散射的意思是水中物体反射的光向摄像机传输的过程中发生的小角度偏离原来的传输方向的散射现象；后向散射的意思是光线在照射到水中物体时遇到水中的杂质就会发生散射直接被摄像机接收的散射现象，导致图像对比度低。</p>
<p>严重退化的水下图像由于缺少用于目标识别的有效信息，导致水下目标检测识别难度提升。随着高科技水下成像设备的发展，获取的水下图像的质量也得到了一定程度的提升，但仍然存在颜色衰退、对比度低以及细节模糊等现象，此外实际应用成本也是需要考虑的问题，因此对水下图像进行增强仍然有其必要性。</p>
<p>水下图像处理技术的算法可以根据是否基于水下成像模型分为图像增强算法和图像复原算法两种。图像增强方法是对得到的水下图像的像素点进行研究增强，算法过程中不需要考虑图像的形成过程和降质过程；图像复原方法是要根据水下图像的成像过程来获得出真实的情况。图像复原方法需要水体的光学参数、摄像机参数和摄像机与目标物体的距离等信息，这些信息都要通过人工测量或其他方法估测出这些值。</p>
<p>水下视觉探测技术的重点和难点有两个方面，一是<u>水下光传感设备参数的标定</u>，另一个是<u>水下模糊图像的复原</u>。由于水质的复杂性，导致光线在水下的传播有折射、散射等现象，同时可能存在的浑浊水质也是导致水下图像退化的主要原因，水下图像就因为这种降质因素产生了严重的模糊。目前科学技术处理这种模糊还存在一定的难度。由于无法获得原始的水下清晰图像，以及无法精确测量到导致水下图像发生退化的模糊函数，水下图像复原技术的应用一直受到限制，也间接限制了水下探测等技术的发展。因此如何根据水下图像的形成机制和水下图像发生退化的原因，建立一个合理的水下图像退化的物理模型，同时使得该物理模型能够实际应用，能够通过软硬件手段估计得到模糊函数来复原水下图像是目前的研究重点，具备实际的研究价值和意义。(由于水下环境的复杂，且难以获得ground truth，故此若采用DL来做，其中一个难点就是如何获取成pair的训练数据，除非采用无监督学习)<br /> &nbsp;</p>
<h1 id="%E7%A0%94%E7%A9%B6%E7%8E%B0%E7%8A%B6%EF%BC%88%E5%B8%B8%E7%94%A8%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%89">研究现状（常用的方法）</h1>
<p>受水下光传播过程中的衰减和散射的影响，在纯水区域中，水下能见度一般为20m，在浑浊海水中的能见度一般只有&nbsp;5m。</p>
<p>McGlamery在&nbsp;1979&nbsp;年搭建了经典的计算机水下成像系统模型。他发现，摄像机水下成像系统获得到的光能量可以分成三个部分：直接传输的光能量、前向散射的光能量和后向散射的光能量。</p>
<p>在图像处理中，图像复原又叫做图像恢复，该项技术有着广泛的应用领域。同时图像复原技术又与其他图像技术之间有着一定的联系，比如：与图像增强相比，两种技术在一定程度上都是针对图像进行改善，从而提高图像质量。但是这两项技术有着不一样的图像质量评价指标和不同的设计算法。相对而言，图像增强一般是增强视觉感受，偏向于人的主观判断，丢失的细节信息不会得到修复。而图像复原计算则是根据图像退化的模型，进行图像建模，设计一定的代价函数来优化逆问题，从而估计出原始图像和模糊函数。经典的图像复原方法一般都是基于先验知识设计的，已知的先验知识越多，复原出来的效果就越好。但是，在实际应用中，先验知识往往都是未知的。因此经典的方法限制了实际的应用。</p>
<p>已知图像在采集、传输、储存和处理过程中，会出现畸变、模糊、失真和附加噪声的影响，造成图像发生降质，这种现象一般称为图像退化。图像复原的关键在于建立图像退化模型，此退化模型应该能反映图像退化的原因。造成图像退化的原因很多，典型原因表现为：成像系统的像差、畸变、带宽有限造成图像失真；太阳辐射、大气湍流、云层遮挡等造成的遥感图像失真；由于成像器件拍摄姿态和扫描非线性引起的图像几何失真；成像传感器与被拍摄景物之间的相对运动，引起所成图像的运动模糊；光学系统或成像传感器本身特性不均匀，造成同样亮度景物成像灰度不同；由于场景能量传输通道中的介质特性如大气湍流效应、大气成分变化引起图像失真；图像在成像、数字化、采集和处理过程中引入的噪声等。</p>
<p>（tips：傅里叶变换是一种频域变换，是将图像的空间域信息转换到频率域中，傅里叶变换的应用一般是将在空域中不明显的信息或隐藏的信息转换到频域中，使其在频域中很明显地显现出来。）</p>
<p>传统的图像增强方法有很多种，主要分为两大部分：空域图像处理和频域图像处理。空域图像处理方法直接针对图像的像素点，以灰度映射为基础来改善灰度层级，例如直方图均衡化、限制对比度直方图均衡化、灰度世界假设等，此外，还可以通过滤波的方式对图像去除噪声达到图像增强的目的，例如中值滤波、均值滤波等；频域图像增强方法则通过各种频域变换，如傅里叶变换、小波变换等，可以间接地增强图像。国内外很多学者采用空域和频域方法对水下图像进行了增强，传统的图像增强算法在一定程度上可以消除图像模糊、增强边缘等，但仍存在噪声大、清晰度较低和颜色失真等问题，因此还需要进一步加强和完善。</p>
<p>目前，用于增强或复原水下图像的处理方法大致可分为非物理模型的图像增强方法和基于物理模型的图像复原方法。</p>
<h2 id="%E9%9D%9E%E7%89%A9%E7%90%86%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%BC%BA%E6%96%B9%E6%B3%95">非物理模型的图像增强方法</h2>
<p>图像增强技术不必过多考虑图像成像的过程和模型，可以叫非物理模型方法，这种方法力图通过单纯的图像处理手段提高水下图像质量，通过调整图像的像素值来改善视觉质量，不过实现过程往往较为复杂。</p>
<p>该类方法采用直接调整图像像素值的方式改善图像质量，<strong>并不考虑水下图像退化的物理过程</strong>（就是没有考虑退化模型、水下得信道），属于图像增强范畴。</p>
<p>在水下图像增强技术研究早期，对水下图像的处理经常直接应用一些空气中传统的的图像增强算法，传统的图像增强算法可以分为空间域法与频域法。空间域方法是对图像中的像素点直接处理，采用灰度映射的方法，比如选取合适的映射变换来增加图像的对比度，改善图像灰度级等。频域法是一种间接的图像处理方法，运用变换技术把图像映射到某种变换域内，然后利用变换域中特有性质进行某种滤波处理，再反变换到空间域内，即得到增强后的图像。常被应用到水下图像传统空间域增强算法有直方图均衡化、限制对比度直方图均衡化、灰度世界假设和白平衡算法等，频域增强算法有傅里叶变换、小波变换和滤波技术，主要包括低通滤波，高通滤波和同态滤波等。目前图像增强算法往往存在可能只是对某一类的图像增强效果好，而其他类型的效果不好的特点，而且由于水下环境的特殊性，仅仅通过研究把传统的图像增强算法应用在水下图像上无法彻底解决水下图像退化问题。<br /> 水下图像増强算法研究早期，传统的图像处理方法，例如白平衡，灰度世界假设和灰度边缘假设等颜色修正算法，直方图均衡化和限制对比度直方图均衡化等对比度增强算法，多被用来增强水下图像。相比于处理普通图像获取的较好的结果，这些方法在处理水下图像获取的结果并不理想，其主要原因是海洋环境复杂，多重不利因素如水介质对光线的散射、吸收作用以及水下悬浮粒子等对其产生严重干扰。考虑到水下图像存在的颜色衰退、低对比度以及模糊等特点，研究人员往往从图像颜色、对比度、细节等方面入手对水下图像进行增强。</p>
<h3 id="%E7%99%BD%E5%B9%B3%E8%A1%A1%E6%96%B9%E6%B3%95">白平衡方法</h3>
<p>在不同光源照射下，观察同一个物体会发现其呈现的颜色是不同的，原因是不同光源具有的不同色温造成目标物体的反射光线光谱偏离其“真实”颜色。当同一白色目标物体在被高色温光源照射（如阴天时）将会表现为蓝色，被低色温光源照射（如床头灯等）将会表现为姜黄色。白平衡方法能够根据图像所呈现的色温纠正图像的色彩偏差，其具体实现过程建立在朗伯特反射模型上。<br /> 朗伯特反射模型表示反射图像主要与三项因素有关：光源光谱分布、物体表面的反射率以及成像设备感光函数。针对彩色图像，即包含ＲＧＢ三个颜色通道的图像，图像呈现的场景中某物体表面上的空间坐标点x的颜色可用朗伯特反射模型表示为：</p>
<p style="text-align:center;"><img alt="" class="has" height="85" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190729162404885.png" width="359"></p>
<p style="text-align:center;"><img alt="" class="has" height="144" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190729162432423.png" width="744"></p>
<p style="text-align:center;"><img alt="" class="has" height="91" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190729162458142.png" width="254"></p>
<p>白平衡方法以上述朗伯特反射模型为基础，考虑到传统的以标准白色参照物进行颜色校准的白平衡方法在实际应用中具有很大的局限性，研宄人员提出了多种白平衡算法纠正图像的色彩偏差。白平衡方法应用场景一般为普通偏色情况，对于并不严重的偏色可以起到较好的恢复作用，但是水下偏色情况一般较为严重，因此需要继续研究可以对水下颜色衰退起到良好恢复作用的白平衡算法。</p>
<h3 id="%E7%9B%B4%E6%96%B9%E5%9B%BE%E5%9D%87%E8%A1%A1%E5%8C%96%E6%96%B9%E6%B3%95">直方图均衡化方法</h3>
<p>将图像的灰度直方图从较为集中的某灰度区间均匀拉伸至全部灰度范围内，用以扩大图像灰度值的分布范围，提升图像对比度并突出部分细节效果。<br /> &nbsp;</p>
<h3 id="%E5%9F%BA%E4%BA%8ERetinex%E7%9A%84%E6%96%B9%E6%B3%95">基于Retinex的方法</h3>
<p>Retinex&nbsp;理论是&nbsp;20&nbsp;世纪&nbsp;70&nbsp;年代最早由&nbsp;Land提出的一种基于颜色恒常性的理论，该理论基于三个假设：（1）真实世界是无颜色的，人类所见到的颜色是光与物体相互作用的结果；（2）每一种颜色由红、绿、蓝三原色组成的；（3）三原色决定了每个单位区域的颜色。Retinex&nbsp;算法可以对不同类型的图像进行自适应增强，比传统的单一的图像增强算法具有更好的自适应性，因为传统的增强算法只能增强图像的某一类特征，而Retinex&nbsp;增强算法则可以在动态范围内压缩、细节增强和颜色校正等方面达到较好的平衡效果，因此，Retinex&nbsp;理论得到了广泛的发展和应用。</p>
<p>&nbsp;</p>
<h3 id="%E5%9F%BA%E4%BA%8E%E6%9A%97%E9%80%9A%E9%81%93%E5%85%88%E9%AA%8C%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%88%E5%8E%BB%E9%9B%BE%E7%9A%84%E6%96%B9%E6%B3%95%EF%BC%89">基于暗通道先验的方法（去雾的方法）</h3>
<p>DCP是一种去雾的图像增强方法（恺明神提出的方法）。接下来会写一篇博客专门对这种方法进行分析。</p>
<p>对于水下图像增强而言，跟去雾有很多相似的特性。故此在去雾中的一些方法也适用于水下图像增强。</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h3 id="%E5%9F%BA%E4%BA%8E%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E6%96%B9%E6%B3%95">基于卷积神经网络的方法</h3>
<p>基于卷积网络的图像去雾、去模糊、图像盲复原等任务跟水下图像增强有异曲同工之妙。但是关键点在于训练集的获取以及卷积模型的泛化能力上。</p>
<p>其实对于运算量和实时性而言。个人觉得卷积网络只要训练好了，后面的使用过程是非常方便的。但是对于水下如此复杂的退化环境，要训练出一种泛化能力足够强的网络才是难点所在。与此同时，需要有相应的数据集的定制，也是难点所在。</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h2 id="%E5%9F%BA%E4%BA%8E%E7%89%A9%E7%90%86%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%9B%BE%E5%83%8F%E5%A4%8D%E5%8E%9F%E6%96%B9%E6%B3%95">基于物理模型的图像复原方法</h2>
<p>该类方法针对水下图像退化过程构建数学模型，通过该模型反演图像退化过程，获得理想状态下未经退化的图像，属于图像复原范畴。（两种方法感觉好像有点类似于图像复原中的成pair的训练和不成pair的训练）</p>
<p>水下图像复原技术是基于物理模型的方法，是指对水下图像退化过程搭建一个合理的数学模型估算出模型参数信息，了解整个图像的退化过程使水下图像恢复到退化前的状态。图像复原技术适用范围更广，但是往往需要场景先验信息或深度信息来实现图像复原。</p>
<p>受图像处理和质量衡量方法的多样性的影响，对于水下图像处理结果的选取只能从其应用目的和场合入手，水下图像增强算法的研究仍然有待深入研究和完善。海洋的环境多种多样，必须要用应用的目的和场合入手来进行合适的水下图像增强。<br /> &nbsp;</p>
<h1 id="%E6%B0%B4%E4%B8%8B%E5%9B%BE%E5%83%8F%E6%88%90%E5%83%8F%E7%90%86%E8%AE%BA">水下图像成像理论</h1>
<p>海水是一种化学成分非常复杂的混合物，它包含着以物理化学形态存在的各种元素，通常在海水中还含有悬浮体和各种活性有机体，如细菌、浮游生物和矿物颗粒等，使得海水存在不均匀性。水中悬浮颗粒的存在，使得光线在水下容易发生折射、散射，同时水对光线具有一定的吸收和衰减特性。即使是经过过滤的最纯净的水，它对光的衰减也是很严重的。实验表明，水的衰减是光波长的复函数，它是由两个不相关的物理过程（即吸收和散射）引起的，因此光在水中传输时的能量按指数规律迅速地衰减。一般对于清澈的海水，60％的衰减是由散射引起的，40％的衰减是由吸收引起的。</p>
<p>在水中，光是按照指数衰减的方式进行运动，这种衰减限制了相机到目标物的距离，并非常严重的影响了水下的成像系统的性能，通常情况下，吸收造成了光能量的损失，散射造成光传播方向的改变，前向散射是水下物体到摄像机的过程中发生小角度偏离的光线，这种散射造成了图像清晰度低，而后向散射是从存在的太阳光或者人工光源到摄像机的过程中遇到悬浮小颗粒散射到相机的偏离光，这种散射会造成图像对比度低。<br /> &nbsp;</p>
<h2 id="%E6%B0%B4%E4%B8%8B%E6%88%90%E5%83%8F%E7%B3%BB%E7%BB%9F">水下成像系统</h2>
<p>水下成像系统获取的图像严重衰退，其主要原因是水下环境中能见度较低，清澈水中的能见度大约为二十米，浑浊水中的能见度则大约在五米之内。这种能见度降低源于光线在水中的衰减。朗伯－比尔经验定律表示，光线在媒介中以指数形式衰减，媒介的特性将直接影响光线的衰减程度。<br /> 根据光衰减模型</p>
<p style="text-align:center;"><img alt="" class="has" height="77" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190729155500762.png" width="201"></p>
<p><img alt="" class="has" height="54" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190729155526354.png" width="740"></p>
<p>自然光入射到水中，水中介质对光线有散射和吸收的作用。水中光线衰减模型可以表示为：</p>
<p style="text-align:center;"><img alt="" class="has" height="113" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190729155602241.png" width="651"></p>
<p>水下成像系统如下图所示。其中，光线散射分为前向散射和后向散射，<strong>前向散射光</strong>作为目标表面反射或辐射经水中悬浮粒子散射后进入成像系统的光，将导致成像系统获取的图像呈现模糊的现象；<strong>后向散射光</strong>作为自然光入射到水体经悬浮粒子散射后进入成像系统的光，将导致成像系统获取的图像呈现低对比度的现象。采用人工光源对水下成像过程进行主动照明能够对上述现象起到一定程度的改善作用，但人工光源的光强以光量最强点为中心沿径向逐渐衰减，将导致获取的图像存在背景灰度不均、假轮廓、假细节和自阴影等情况，同时人工光源在浑浊水中能够发挥的作用非常有限。</p>
<p style="text-align:center;"><img alt="" class="has" height="502" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190729155709617.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d3cGxvdmVraW1p,size_16,color_FFFFFF,t_70" width="701"></p>
<p>水中介质对光线的散射作用会导致获取的图像存在模糊及低对比度的现象，而水介质对光线的吸收作用则将会造成获取的图像出现颜色衰退的现象。水对光的吸收在不同的光谱区域是不同的，具有明显的选择性。水对光谱中的红外和紫外部分表现出强烈地吸收。在可见光谱区段，吸收最大的是红色、黄色和淡绿色光谱区域。纯净水和清澈的海水在光谱的蓝一绿区域透射比量大，其中波长&nbsp;462~475nm&nbsp;的蓝光衰减最少。水的吸收足以使光的强度每米衰减约4％，而其他颜色则更多，几米之外几乎完全消失。<br /> 如下图所示。水介质对光线的吸收效应是有选择性的，即水介质对不同波长的光吸收程度不同，红色光、橙色光和黄色光基本会消失在大约五米、十米、二十米水深处，而随着水深的进一步增加，绿色光也会逐渐消失，而<strong>蓝色光在六十米水深处才会基本消失</strong>（而对于LED光源而言，主要是蓝色芯片发光的，故此可能在这个程度上，有利？）<strong>。</strong>因此，一般获取的水下图像皆呈现蓝绿色调。</p>
<p style="text-align:center;"><img alt="" class="has" height="728" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190729160415128.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d3cGxvdmVraW1p,size_16,color_FFFFFF,t_70" width="831"></p>
<p>&nbsp;</p>
<h2 id="%E6%B0%B4%E4%B8%8B%E6%95%A3%E5%B0%84%E6%A8%A1%E5%9E%8B">水下散射模型</h2>
<p>相比于水对光的吸收作用，光在水中发生散射效应是造成水下图像降质的主要原因。</p>
<p>水体对自然光的散射作用受到水体中粒子的类别、大小和密度以及入射光的波长、角度以及偏振的共同影响（故此对于不同的海洋环境，有不同的粒子类别，散射模型也许也会不一样，从而大大增加了问题的多样性）。水下图像总照度=直接照射分量+前向散射分量+后向散射分量</p>
<p style="text-align:center;"><img alt="" class="has" height="597" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190729161030918.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d3cGxvdmVraW1p,size_16,color_FFFFFF,t_70" width="684"></p>
<p>直接照射分量是指经目标表面反射进入相机的并未被水体散射或吸收的光；前向散射分量是目标表面反射的经水中悬浮粒子散射后进入相机的光；后向散射分量则指的是自然光入射到水体后经悬浮粒子散射后进入相机的光。Jaffe-McGlamery模型假设光源以球状扩散并衰减，目标反射光可以由入射光和反射函数表示。直接照射分量的估计可以在假设目标物体为理想朗伯特体的基础上采用几何光学实现。前向散射分量是目标反射光在到达相机之前发生的小角度散射产生的，它的求解可以结合直接照射分量和点扩散函数的卷积算子实现。后向散射光进入相机的角度很广，其相应的后向散射分量则是通过体积散射函数对场景和相机之间的水体所分成的小水体进行加权，然后线性叠加得到的。该模型表示相机、成像范围、光源距离和水下环境都将对获取的水下图像产生影响。<strong><u>在短距离成像中，相机和光源简单组合即可获取质量较好的水下图像。在距离较长的成像范围内，独立相机和光源组成的系统将获取质量更好的水下图像，但是成像距离的增加将导致后向散射效应的凸显。</u></strong><br /> &nbsp;</p>
<h1 id="%E6%B0%B4%E4%B8%8B%E9%80%80%E5%8C%96%E5%9B%BE%E5%83%8F%E6%A8%A1%E7%B3%8A%E7%B1%BB%E5%9E%8B">水下退化图像模糊类型</h1>
<p>由于不同水下环境的复杂性，因此造成水下图像发生退化的原因主要可以分为：噪声和模糊。其中水下模糊可以分为三种类型：<br /> 1、水体或鱼群等运动造成的运动模糊；2、水下光线的散射或相机镜头未能达到理想的对焦的情况下造成的散焦模糊；3、水下湍流造成的高斯模糊。</p>
<h2 id="%E9%AB%98%E6%96%AF%E6%A8%A1%E7%B3%8A">高斯模糊</h2>
<p>高斯模糊函数是最常见的模糊，对成像系统和光学测量系统来说，许多因素共同决定了系统的退化函数，综合的结果就是使退化函数趋于高斯模型。光学相机和&nbsp;CCD&nbsp;摄像机、显微光学系统、CT&nbsp;机等等都属于这类系统。大气湍流和水下湍流也一样都会近似为高斯函数，其数学模糊可表示为：</p>
<p style="text-align:center;"><img alt="" class="has" height="193" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801102044509.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d3cGxvdmVraW1p,size_16,color_FFFFFF,t_70" width="805"></p>
<h2 id="%E8%BF%90%E5%8A%A8%E6%A8%A1%E7%B3%8A">运动模糊</h2>
<p>运动模糊图像形成于目标的成像过程中，主要是因为在相机曝光的过程中拍摄目标与相机镜头之间发生相对位移而产生的一种图像退化现象，其数学模糊可表示为：</p>
<p style="text-align:center;"><img alt="" class="has" height="213" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801102158652.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d3cGxvdmVraW1p,size_16,color_FFFFFF,t_70" width="640"></p>
<h2 id="%E6%95%A3%E7%84%A6%E6%A8%A1%E7%B3%8A">散焦模糊</h2>
<p>一般，一个理想的点在成像平面上呈圆盘状光斑的现象叫做离焦模糊，这种模糊是由于成像系统未能达到理想的对焦状态而产生的。常采用的基于几何光学中提出的圆盘离焦模型，能很好的近似点扩散函数，有效解决离焦模糊的去模糊问题。用一个灰度值服从均匀分布的圆盘状光斑来表示&nbsp;PSF，其数学模糊可表示为：</p>
<p style="text-align:center;"><img alt="" class="has" height="169" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801102254677.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d3cGxvdmVraW1p,size_16,color_FFFFFF,t_70" width="718"></p>
<p>&nbsp;</p>
<h1 id="%E5%9B%BE%E5%83%8F%E8%B4%A8%E9%87%8F%E8%AF%84%E4%BB%B7%E6%A0%87%E5%87%86">图像质量评价标准</h1>
<p>图像质量评价指标是评估图像处理算法好坏的重要指标。图像质量通常指图像逼真度和图像可懂度。在图像处理的许多技术中，如：压缩、增强、超分、去噪、去模糊、去摩尔纹、复原等，都会涉及到图像质量评价。图像质量的含义主要包括图像的逼真度和图像的可懂度两个方面，其质量主要受成像装备的光学性能、仪器噪声和成像条件等多种因素的影响。图像质量评价方法主要分为两类：分别为主观图像质量评价方法和客观质量评价方法</p>
<p>对于客观质量的评价方法又分为有参考和无参考评价</p>
<p style="text-align:center;"><img alt="" class="has" height="350" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190801095512354.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d3cGxvdmVraW1p,size_16,color_FFFFFF,t_70" width="466"></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<h1 id="%E5%8F%82%E8%80%83%E8%B5%84%E6%96%99%EF%BC%9A">参考资料：</h1>
<p>《基于卷积神经网络的水下图像增强算法研究_丁雪妍》</p>
<p>《水下图像复原方法研究_王婷》</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
</p></div>
</div>
]]></content:encoded>
										</item>
		<item>
		<title>高斯滤波详解</title>
		<link>https://uzzz.org/article/3073.html</link>
				<pubDate>Tue, 21 May 2019 10:55:24 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[DeepLearning]]></category>
		<category><![CDATA[图像处理]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/3073.html</guid>
				<description><![CDATA[高斯滤波 1.高斯卷积核是如何在高斯函数上取值的？ 一维高斯函数的公式： 二维高斯分布的公式： 卷积核每个位置的权重值，就取对应位置对应的二维高斯函数值,如下表 f(-1,-1) f(-1,0) f(1,0) f(0,,-1) f(0,0) f(0,1) f(1,-1) f(1,0) f(1,1) &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; 卷积核的取值 #2.高斯滤波的计算公式 # #(其中，&#160;是归一化系数，保证高斯核中的权重值之和等于1,1) 2.为什么的取值会决定了高斯核半径的大小(二者知道一个另一个就随之固定)? 因为高斯函数的3原则（x取值在[-3, 3]之间的概率大于90%），根据高斯函数的图像可以看出，σ的值越大高斯函数的曲线越“平坦”（红黄蓝曲线），以一维高斯函数图像为例： 而我们知道，高斯核各个位置的权重=像素点的位置坐标对应到二维高斯函数上的函数值 当的值较小的时候(如0.2)，从上面的图像可以看到： 当x&#60;-1、x&#62;1的时候，f(x)的取值已经趋近于0了，这就代表着更远位置的像素值已经对计算当前位置的像素没有意义了，即小就等价于高斯核半径小。 3. 高斯滤波为什么会让图像变模糊？ 高斯滤波通过高斯核对图像的逐个像素进行卷积，从而得到每个像素的值。在卷积的过程中，利用周围像素的值，将距离作为权重计算卷积核中心位置的像素。(离中心位置越近的点对像素值计算的贡献越大，选用高斯函数的原因就是因为它恰好满足这一条件) &#160; 高斯滤波是一种低通滤波，也可以说是一种数据平滑算法。“模糊”可以理解成每一个像素都取周边像素的平均值，在数值上这是一种“平滑化”，在图像上就表现出“模糊”的效果，中间点失去细节。 模糊半径越大，模糊效果越明显。考虑到图像中像素点越靠近的点关系越密切，因此加权平均是更加合理的选择。而正态分布（高斯函数）显然是一种可取的权重分配模式。 权重矩阵中所有点的权重和为1（不为1也可以吧？会使整体变暗\亮） &#160;]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div class="htmledit_views" id="content_views">
<h1>高斯滤波</h1>
<h3>1.高斯卷积核是如何在高斯函数上取值的？</h3>
<p>一维高斯函数的公式：</p>
<p><img alt="f(x) = \frac{1}{\sqrt{2\pi}\sigma}\,exp(-\frac{(x-\mu)^2}{2\sigma^2})" class="mathcode" src="https://private.codecogs.com/gif.latex?f%28x%29%20%3D%20%5Cfrac%7B1%7D%7B%5Csqrt%7B2%5Cpi%7D%5Csigma%7D%5C%2Cexp%28-%5Cfrac%7B%28x-%5Cmu%29%5E2%7D%7B2%5Csigma%5E2%7D%29"></p>
<p>二维高斯分布的公式：</p>
<p>卷积核每个位置的权重值，就取对应<img alt="(x, y)" class="mathcode" src="https://private.codecogs.com/gif.latex?%28x%2C%20y%29">位置对应的二维高斯函数值<img alt="f(x, y)" class="mathcode" src="https://private.codecogs.com/gif.latex?f%28x%2C%20y%29">,如下表</p>
<table border="1" cellpadding="1" cellspacing="1" style="width:150px;">
<tbody>
<tr>
<td>f(-1,-1)</td>
<td>f(-1,0)</td>
<td>f(1,0)</td>
</tr>
<tr>
<td>f(0,,-1)</td>
<td>f(0,0)</td>
<td>f(0,1)</td>
</tr>
<tr>
<td>f(1,-1)</td>
<td>f(1,0)</td>
<td>f(1,1)</td>
</tr>
</tbody>
</table>
<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 卷积核的取值</p>
<p><span style="color:#ffbb66;">#2.高斯滤波的计算公式</span></p>
<p><span style="color:#ffbb66;">#<img alt="h(X)= k_d^{-1}(X)\int_{-\infty}^{\infty}\,\int_{-\infty}^{\infty}f(\xi)c(\xi,X)\,d\xi" class="mathcode" src="https://private.codecogs.com/gif.latex?h%28X%29%3D%20k_d%5E%7B-1%7D%28X%29%5Cint_%7B-%5Cinfty%7D%5E%7B%5Cinfty%7D%5C%2C%5Cint_%7B-%5Cinfty%7D%5E%7B%5Cinfty%7Df%28%5Cxi%29c%28%5Cxi%2CX%29%5C%2Cd%5Cxi"></span></p>
<p><span style="color:#ffbb66;">#(其中，<img alt="k_d(X)= \int_{-\infty}^{\infty}\,\int_{-\infty}^{\infty}c(\xi,X)\,d\xi" class="mathcode" src="https://private.codecogs.com/gif.latex?k_d%28X%29%3D%20%5Cint_%7B-%5Cinfty%7D%5E%7B%5Cinfty%7D%5C%2C%5Cint_%7B-%5Cinfty%7D%5E%7B%5Cinfty%7Dc%28%5Cxi%2CX%29%5C%2Cd%5Cxi">&nbsp;是归一化系数，保证高斯核中的权重值之和等于1,1)</span></p>
<h3>2.为什么<strong><img alt="\sigmaσ" class="mathcode" src="https://private.codecogs.com/gif.latex?%5Csigma%25u03C3"></strong>的取值会决定了高斯核半径的大小(二者知道一个另一个就随之固定)?</h3>
<p> 因为高斯函数的3<img alt="\sigmaσ" class="mathcode" src="https://private.codecogs.com/gif.latex?%5Csigma%25u03C3">原则（x取值在[-3<img alt="\sigmaσ" class="mathcode" src="https://private.codecogs.com/gif.latex?%5Csigma%25u03C3">, 3<img alt="\sigmaσ" class="mathcode" src="https://private.codecogs.com/gif.latex?%5Csigma%25u03C3">]之间的概率大于90%），根据高斯函数的图像可以看出，σ的值越大高斯函数的曲线越“平坦”（红黄蓝曲线），以一维高斯函数图像为例：</p>
<p><img alt="" class="has" src="https://uzshare.com/_p?https://images2015.cnblogs.com/blog/587932/201603/587932-20160314152918287-183820148.jpg"></p>
<p>而我们知道，高斯核各个位置的权重=像素点的位置坐标对应到二维高斯函数上的函数值<br /> 当<img alt="\sigma" class="mathcode" src="https://private.codecogs.com/gif.latex?%5Csigma">的值较小的时候(如0.2)，从上面的图像可以看到<img alt="" class="mathcode" src="https://private.codecogs.com/gif.latex?">：</p>
<p>当x&lt;-1、x&gt;1的时候，f(x)的取值已经趋近于0了，这就代表着更远位置的像素值已经对计算当前位置的像素没有意义了，即<img alt="\sigma" class="mathcode" src="https://private.codecogs.com/gif.latex?%5Csigma">小就等价于高斯核半径小。</p>
<h3>3. 高斯滤波为什么会让图像变模糊？</h3>
<p>高斯滤波通过高斯核对图像的逐个像素进行卷积，从而得到每个像素的值。在卷积的过程中，利用周围像素的值，将距离作为权重计算卷积核中心位置的像素。(离中心位置越近的点对像素值计算的贡献越大，选用高斯函数的原因就是因为它恰好满足这一条件)</p>
<p>&nbsp;</p>
<p>高斯滤波是一种低通滤波，也可以说是一种数据平滑算法。“模糊”可以理解成每一个像素都取周边像素的<strong>平均值</strong>，在数值上这是一种“平滑化”，在图像上就表现出“模糊”的效果，中间点失去细节。</p>
<p>模糊半径越大，模糊效果越明显。考虑到图像中像素点越靠近的点关系越密切，因此加权平均是更加合理的选择。而正态分布（高斯函数）显然是一种可取的权重分配模式。</p>
<p><img alt="" class="has" height="316" src="http://www.ruanyifeng.com/blogimg/asset/201211/bg2012111407.png" width="600"></p>
<p>权重矩阵中所有点的权重和为1（不为1也可以吧？会使整体变暗\亮）</p>
<p>&nbsp;</p>
</p></div>
</div>
]]></content:encoded>
										</item>
		<item>
		<title>echart相关操作xAxis,yAxis,series,grid,(包括x轴样式，y轴样式，折现样式，网格样式，折现阴影，折线上方显示数据，x轴文字倾斜)</title>
		<link>https://uzzz.org/article/2882.html</link>
				<pubDate>Thu, 16 May 2019 07:49:52 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[前端]]></category>
		<category><![CDATA[图像处理]]></category>
		<category><![CDATA[移动开发]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/2882.html</guid>
				<description><![CDATA[样式截图大概如下： &#160; &#160; &#160; 1. x，y轴相关操作：xAxis，yAxis &#160; &#160; &#160;(1)&#160; x，y轴的颜色： &#160; &#160; &#160; &#160; &#160; &#160; axisLine: { lineStyle: { color: '#2898e5', }, }, &#160; &#160; (2) x，y轴文字颜色： &#160; &#160; &#160; axisLabel: { show: true, textStyle: { color: '#019bf8' } } &#160; &#160; &#160;（3）x，y轴刻度颜色： &#160; &#160; axisTick: { lineStyle: { color: '#2898e5' } } &#160; &#160; &#160; &#160;(4) x，y轴坐标文字太长显示不全：,倾斜rotate &#160; &#160; &#160; &#160; &#160; &#160;&#160; axisLabel: { show: true, interval: 0, rotate: 20 }, &#160; &#160; &#160; （5）x ,y 轴网格线的颜色： &#160; &#160; &#160;&#160; splitLine: { show: true, lineStyle: { color: ['rgb(1,155,246,0.3)'], //网格线 width: 1, } }, &#160; 2. 折现 的样式 &#160; &#160; （1） 折现的平滑度series： &#160; &#160; &#160; &#160; &#160; &#160; &#160;&#160; symbol: 'circle', //实心点 symbolSize: 6, //实心点的大小 smooth: true, //折现平滑 &#160; &#160; （2）折现的颜色： itemStyle: { normal: { color: 'transparent' } }, &#160; &#160; &#160;（3）折现阴影变色： &#160; &#160;&#160; areaStyle: { normal: { color: new echarts.graphic.LinearGradient(0, 0, 0, 1, [{ offset: 0, color: 'rgb(52,214,145)' //渐变上边颜色 }, { offset: 1, color: 'transparent' //渐变下边颜色 }]) } }, &#160; &#160; &#160;（4）折线上方显示文字： &#160; &#160; &#160; &#160; &#160; &#160; label: { normal: { show: true, position: 'top', //头上显示数据]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div class="htmledit_views" id="content_views">
<p>样式截图大概如下：</p>
<p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190516155254827.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NzkwNjQ0,size_16,color_FFFFFF,t_70"></p>
<p>&nbsp;<img alt="" class="has" height="178" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190516155214221.png" width="368"></p>
<p><img alt="" class="has" height="192" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190516155229329.png" width="376"></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
<p>1. x，y轴相关操作：xAxis，yAxis</p>
<p>&nbsp; &nbsp; &nbsp;(1)&nbsp; x，y轴的颜色：</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p>
<pre class="has">
<code>  axisLine: {
             lineStyle: {
                  color: '#2898e5',
                },
            },</code></pre>
<p>&nbsp; &nbsp; (2) x，y轴文字颜色：</p>
<p>&nbsp; &nbsp; &nbsp;</p>
<pre class="has">
<code>     axisLabel: {
            show: true,
            textStyle: {
              color: '#019bf8'
            }
          }</code></pre>
<p>&nbsp; &nbsp; &nbsp;（3）x，y轴刻度颜色：</p>
<p>&nbsp; &nbsp;</p>
<pre class="has">
<code> axisTick: {
          lineStyle: { color: '#2898e5' } 
        }</code></pre>
<p>&nbsp; &nbsp; &nbsp; &nbsp;(4) x，y轴坐标文字太长显示不全：,倾斜rotate</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</p>
<pre class="has">
<code> axisLabel: {
          show: true,
          interval: 0,
          rotate: 20
  },</code></pre>
<p>&nbsp; &nbsp; &nbsp; （5）x ,y 轴网格线的颜色：</p>
<p>&nbsp; &nbsp; &nbsp;&nbsp;</p>
<pre class="has">
<code> splitLine: {
          show: true,
          lineStyle: {
            color: ['rgb(1,155,246,0.3)'],  //网格线
            width: 1,
          }
 },</code></pre>
<p>&nbsp;</p>
<p>2. 折现 的样式</p>
<p>&nbsp; &nbsp; （1） 折现的平滑度series：</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;</p>
<pre class="has">
<code>symbol: 'circle',  //实心点
symbolSize: 6,     //实心点的大小
smooth: true,      //折现平滑</code></pre>
<p>&nbsp; &nbsp; （2）折现的颜色：</p>
<pre class="has">
<code>  itemStyle: {
          normal: {
            color: 'transparent'
          }
        },</code></pre>
<p>&nbsp; &nbsp; &nbsp;（3）折现阴影变色：</p>
<p>&nbsp; &nbsp;&nbsp;</p>
<pre class="has">
<code> areaStyle: {
          normal: {
            color: new echarts.graphic.LinearGradient(0, 0, 0, 1, [{
              offset: 0,
              color: 'rgb(52,214,145)'  //渐变上边颜色
            }, {
              offset: 1,
              color: 'transparent'      //渐变下边颜色
            }])
          }
        },</code></pre>
<p>&nbsp; &nbsp; &nbsp;（4）折线上方显示文字：</p>
<p>&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p>
<pre class="has">
<code>  label: {
          normal: {
            show: true,
            position: 'top',  //头上显示数据
            color: 'rgb(0,255,255)'  //显示文字颜色
          }
   },</code></pre>
<p>3. grid图区域距离四周的距离：</p>
<p>&nbsp; &nbsp;&nbsp;在grid绘图网格里,containLabel(grid 区域是否包含坐标轴的刻度标签,默认不包含)为true的情况下,无法使图表紧贴着画布显示,&nbsp; &nbsp; &nbsp; 但可以防止标签标签长度动态变化时溢出容器或者覆盖其他组件,将containLabel设置为false即可解决;</p>
<p>&nbsp; &nbsp;&nbsp;</p>
<pre class="has">
<code> grid: {
        left: '3%',
        right: '4%',
        bottom: '15%',
        top: '15%',
        containLabel: true
  },</code></pre>
<p>&nbsp; &nbsp;&nbsp;</p>
<p>4.&nbsp;完整代码示例如下：</p>
<p>&nbsp; &nbsp;</p>
<pre class="has">
<code>var option = {
      xAxis: {
        type: 'category',
        boundaryGap: false,
        data: ['福州市', '无锡市', '兰州市', '合肥市', '广州市', '贵阳市', '长沙市'],
        axisLine: {       
          lineStyle: {        
            color: '#2898e5',   //轴颜色
          },

        },
        axisLabel: {     
          interval: 0,
          rotate: 40,    //倾斜度
          show: true,
          textStyle: {     //轴上文字
            color: '#019bf8'   //颜色
          }
        },

        axisTick: {
          lineStyle: { color: '#2898e5' },    // 刻度的颜色
        },

      },
      grid: {           //距离
        left: '3%',
        right: '4%',
        bottom: '15%',
        top: '15%',
        containLabel: true   //保留文字距离
      },
      yAxis: {
        type: 'value',
        axisLine: {
          lineStyle: {
            color: '#2898e5',  //轴
          },
        },
        axisLabel: {
          show: true,
          textStyle: {
            color: '#019bf8'  //轴字体
          }
        },
        splitLine: {
          show: true,
          lineStyle: {
            color: ['rgb(1,155,246,0.3)'],  //网格线颜色
            width: 1,
          }
        },
        axisTick: {
          lineStyle: { color: '#2898e5' }    // x轴刻度的颜色
        }

      },
      series: [{
        data: [1000, 920, 856, 601, 934, 1090, 802, 1000],
        symbol: 'circle',     //折线拐点实心圆
        symbolSize: 6,        //实心圆大小
        smooth: true,         //折线平滑
        label: {               
          normal: {
            show: true,
            position: 'top',  //折线上方显示数据
            color: 'rgb(0,255,255)'
          }
        },
        itemStyle: {
          normal: {
            color: 'rgb(0,255,255)'    //折线颜色
          }
        },
        areaStyle: {     //阴影颜色
          normal: {
            color: new echarts.graphic.LinearGradient(0, 0, 0, 1, [{
              offset: 0,
              color: '#019bf8'   //渐变色上方颜色
            }, {
              offset: 1,
              color: 'transparent'    //渐变色下方颜色
            }])
          }
        },
        type: 'line'
      }]
    };
</code></pre>
<p>&nbsp;</p>
</p></div>
</div>
]]></content:encoded>
										</item>
		<item>
		<title>LIME:低光照下图像增强c++代码</title>
		<link>https://uzzz.org/article/3124.html</link>
				<pubDate>Fri, 19 Apr 2019 06:34:48 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[图像处理]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/3124.html</guid>
				<description><![CDATA[非matlab验证代码，非加密p代码，这里提供C++版本，有助于项目开发，如vSLAM、车道线检测等 代码地址：https://github.com/zj611/LIME_Processing 对比效果: 声明：转载请引用本文链接]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div id="content_views" class="markdown_views prism-atom-one-dark">
  <!-- flowchart 箭头图标 勿删 --><br />
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> </p>
<h1><a id="matlabpCvSLAM_1"></a>非matlab验证代码，非加密p代码，这里提供C++版本，有助于项目开发，如vSLAM、车道线检测等</h1>
<p>代码地址：<a href="https://github.com/zj611/LIME_Processing" rel="nofollow" data-token="92f4b1bff26be4c7ed154989425cdcf9">https://github.com/zj611/LIME_Processing</a></p>
<p>对比效果:<br /> <img src="https://github.com/zj611/LIME_Processing/blob/master/test/data/3.png?raw=true" alt="Alt"><br /> <img src="https://github.com/zj611/LIME_Processing/blob/master/test/data/3_lime.png?raw=true" alt="Alt"></p>
<p><strong>声明：转载请引用本文链接</strong></p>
</p></div>
<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-526ced5128.css" rel="stylesheet">
</div>
]]></content:encoded>
										</item>
		<item>
		<title>为什么要将8位图像的0～255的灰度值归一化为0～1？</title>
		<link>https://uzzz.org/article/3410.html</link>
				<pubDate>Sat, 16 Mar 2019 02:48:24 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[图像处理]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/3410.html</guid>
				<description><![CDATA[一、简介 &#160; &#160; &#160;&#160; 图像归一化是计算机视觉、模式识别等领域广泛使用的一种技术。所谓图像归一化, 就是通过一系列变换, 将待处理的原始图像转换成相应的唯一标准形式(该标准形式图像对平移、旋转、缩放等仿射变换具有不变特性)。 近年来, 基于矩的图像归一化技术受到了人们的普遍关注, 其基本工作原理为: 首先利用图像中对仿射变换具有不变性的矩来确定变换函数的参数, 然后利用此参数确定的变换函数把原始图像变换为一个标准形式的图像(该图像与仿射变换无关)。一般说来, 基于矩的图像归一化过程包括 4 个步骤，即坐标中心化、x-shearing 归一化、缩放归一化和旋转归一化。 &#160; &#160; &#160; &#160; 基本上归一化思想是：利用图像的不变矩寻找一组参数使其能够消除其他变换函数对图像变换的影响。也就是转换成唯一的标准形式以抵抗仿射变换。图像归一化使得图像可以抵抗几何变换的攻击，它能够找出图像中的那些不变量，从而得知这些图像原本就是一样的或者一个系列的。以下你要知道的： 1、归一化处理并没有改变图像的对比度 2、归一化处理很简单，假设原图像是8位灰度图像，那么读入的像素矩阵最大值为256，最小值为1，定义矩阵为I，J＝I／256，就是归一化的图像矩阵，就是说归一化之后所有的像素值都在［0，1］区间内。 二、什么是归一化 &#160; &#160; &#160;&#160; 归一化就是通过一系列变换（即利用图像的不变矩寻找一组参数使其能够消除其他变换函数对图像变换的影响），将待处理的原始图像转换成相应的唯一标准形式(该标准形式图像对平移、旋转、缩放等仿射变换具有不变特性)。 基于矩的图像归一化技术基本工作原理为：首先利用图像中对仿射变换具有不变性的矩来确定变换函数的参数， 然后利用此参数确定的变换函数把原始图像变换为一个标准形式的图像(该图像与仿射变换无关)。 一般说来，基于矩的图像归一化过程包括4个步骤，即坐标中心化、x-shearing 归一化、缩放归一化和旋转归一化。 图像归一化使得图像可以抵抗几何变换的攻击，它能够找出图像中的那些不变量，从而得知这些图像原本就是一样的或者一个系列的。 三、为什么归一化 1、基本上归一化思想是利用图像的不变矩寻找一组参数使其能够消除其他变换函数对图像变换的影响。也就是转换成唯一的标准形式以抵抗仿射变换。图像归一化使得图像可以抵抗几何变换的攻击，它能够找出图像中的那些不变量，从而得知这些图像原本就是一样的或者一个系列的。 2、matlab里图像数据有时候必须是浮点型才能处理，而图像数据本身是0-255的UNIT型数据所以需要归一化，转换到0-1之间。 3、归一化是一种简化计算的方式，即将有量纲的表达式，经过变换，化为无量纲的表达式，成为纯量。目的是为了： &#160;(1)、避免具有不同物理意义和量纲的输入变量不能平等使用 &#160;(2)、bp中常采用sigmoid函数作为转移函数，归一化能够防止净输入绝对值过大引起的神经元输出饱和现象 &#160;(3)、保证输出数据中数值小的不被吞食 3、神经网络中归一化的原因： &#160; &#160; &#160;&#160; 归一化是为了加快训练网络的收敛性，可以不进行归一化处理； &#160; &#160; &#160;&#160; 归一化的具体作用是归纳统一样本的统计分布性。归一化在0-1之间是统计的概率分布，归一化在-1&#8211;+1之间是统计的坐标分布。归一化有同一、统一和合一的意思。无论是为了建模还是为了计算，首先基本度量单位要同一，神经网络是以样本在事件中的统计分别几率来进行训练（概率计算）和预测的，归一化是同一在0-1之间的统计概率分布；当所有样本的输入信号都为正值时，与第一隐含层神经元相连的权值只能同时增加或减小，从而导致学习速度很慢。为了避免出现这种情况，加快网络学习速度，可以对输入信号进行归一化，使得所有样本的输入信号其均值接近于0或与其均方差相比很小。 &#160; &#160; &#160;&#160; 归一化是因为sigmoid函数的取值是0到1之间的，网络最后一个节点的输出也是如此，所以经常要对样本的输出归一化处理。所以这样做分类的问题时用[0.9 0.1 0.1]就要比用[1 0 0]要好。 &#160; &#160; &#160; 但是归一化处理并不总是合适的，根据输出值的分布情况，标准化等其它统计变换方法有时可能更好。 &#160;]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div class="htmledit_views" id="content_views">
<h1>一、简介</h1>
<p> &nbsp; &nbsp; &nbsp;&nbsp; 图像归一化是计算机视觉、模式识别等领域广泛使用的一种技术。所谓图像归一化, 就是通过一系列变换, 将待处理的原始图像转换成相应的唯一标准形式(该标准形式图像对平移、旋转、缩放等仿射变换具有不变特性)。 近年来, 基于矩的图像归一化技术受到了人们的普遍关注, 其基本工作原理为: 首先利用图像中对仿射变换具有不变性的矩来确定变换函数的参数, 然后利用此参数确定的变换函数把原始图像变换为一个标准形式的图像(该图像与仿射变换无关)。一般说来, 基于矩的图像归一化过程包括 4 个步骤，即坐标中心化、x-shearing 归一化、缩放归一化和旋转归一化。<br /> &nbsp; &nbsp; &nbsp; &nbsp; 基本上归一化思想是：利用图像的不变矩寻找一组参数使其能够消除其他变换函数对图像变换的影响。也就是转换成唯一的标准形式以抵抗仿射变换。图像归一化使得图像可以抵抗几何变换的攻击，它能够找出图像中的那些不变量，从而得知这些图像原本就是一样的或者一个系列的。以下你要知道的：</p>
<p> 1、归一化处理并没有改变图像的对比度<br /> 2、归一化处理很简单，假设原图像是8位灰度图像，那么读入的像素矩阵最大值为256，最小值为1，定义矩阵为I，J＝I／256，就是归一化的图像矩阵，就是说归一化之后所有的像素值都在［0，1］区间内。</p>
<h1> 二、什么是归一化</h1>
<p> &nbsp; &nbsp; &nbsp;&nbsp; 归一化就是通过一系列变换（即利用图像的不变矩寻找一组参数使其能够消除其他变换函数对图像变换的影响），将待处理的原始图像转换成相应的唯一标准形式(该标准形式图像对平移、旋转、缩放等仿射变换具有不变特性)。<br /> 基于矩的图像归一化技术基本工作原理为：首先利用图像中对仿射变换具有不变性的矩来确定变换函数的参数， 然后利用此参数确定的变换函数把原始图像变换为一个标准形式的图像(该图像与仿射变换无关)。 一般说来，基于矩的图像归一化过程包括4个步骤，即坐标中心化、x-shearing 归一化、缩放归一化和旋转归一化。<br /> 图像归一化使得图像可以抵抗几何变换的攻击，它能够找出图像中的那些不变量，从而得知这些图像原本就是一样的或者一个系列的。</p>
<h1> 三、为什么归一化</h1>
<p> 1、基本上归一化思想是利用图像的不变矩寻找一组参数使其能够消除其他变换函数对图像变换的影响。也就是转换成唯一的标准形式以抵抗仿射变换。图像归一化使得图像可以抵抗几何变换的攻击，它能够找出图像中的那些不变量，从而得知这些图像原本就是一样的或者一个系列的。</p>
<p> 2、matlab里图像数据有时候必须是浮点型才能处理，而图像数据本身是0-255的UNIT型数据所以需要归一化，转换到0-1之间。</p>
<p> 3、归一化是一种简化计算的方式，即将有量纲的表达式，经过变换，化为无量纲的表达式，成为纯量。目的是为了：</p>
<p> &nbsp;(1)、避免具有不同物理意义和量纲的输入变量不能平等使用<br /> &nbsp;(2)、bp中常采用sigmoid函数作为转移函数，归一化能够防止净输入绝对值过大引起的神经元输出饱和现象<br /> &nbsp;(3)、保证输出数据中数值小的不被吞食</p>
<h1> 3、神经网络中归一化的原因：</h1>
<p> &nbsp; &nbsp; &nbsp;&nbsp; 归一化是为了加快训练网络的收敛性，可以不进行归一化处理；<br /> &nbsp; &nbsp; &nbsp;&nbsp; 归一化的具体作用是归纳统一样本的统计分布性。归一化在0-1之间是统计的概率分布，归一化在-1&#8211;+1之间是统计的坐标分布。归一化有同一、统一和合一的意思。无论是为了建模还是为了计算，首先基本度量单位要同一，神经网络是以样本在事件中的统计分别几率来进行训练（概率计算）和预测的，归一化是同一在0-1之间的统计概率分布；当所有样本的输入信号都为正值时，与第一隐含层神经元相连的权值只能同时增加或减小，从而导致学习速度很慢。为了避免出现这种情况，加快网络学习速度，可以对输入信号进行归一化，使得所有样本的输入信号其均值接近于0或与其均方差相比很小。<br /> &nbsp; &nbsp; &nbsp;&nbsp; 归一化是因为sigmoid函数的取值是0到1之间的，网络最后一个节点的输出也是如此，所以经常要对样本的输出归一化处理。所以这样做分类的问题时用[0.9 0.1 0.1]就要比用[1 0 0]要好。<br /> &nbsp; &nbsp; &nbsp; 但是归一化处理并不总是合适的，根据输出值的分布情况，标准化等其它统计变换方法有时可能更好。<br /> &nbsp;</p>
</p></div>
</div>
]]></content:encoded>
										</item>
		<item>
		<title>【整理】3dsMax烘焙纹理模糊</title>
		<link>https://uzzz.org/article/3302.html</link>
				<pubDate>Fri, 15 Mar 2019 03:47:05 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[图像处理]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/3302.html</guid>
				<description><![CDATA[【2013年4月19日】 【出现问题】 3dsMax烘焙贴图时，纹理模糊。 【问题原因】 UV分布不合理；渲染器设置问题。 【解决方案】 1、合理分面，合理展UV，烘焙UV通道中的面的大小比例应与实际一致。 2、Vary渲染器设置： 1）全局开关中，关闭默认灯光。 2）环境设置中，GI天光使用“天蓝色”。 3）间接照明中，打开折射、反射；一次反弹0.5，二次反弹0.3. 4）发光贴图，预设为高。 5）光缓存，细分为600. 6）系统，渲染区域细分，X为30。 【备注说明】 很久之前整理的了，有待实践考证。。。 &#160; &#160;]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div class="htmledit_views" id="content_views">
<p>【2013年4月19日】</p>
<p>【出现问题】</p>
<p>3dsMax烘焙贴图时，纹理模糊。</p>
<p>【问题原因】</p>
<p>UV分布不合理；渲染器设置问题。</p>
<p>【解决方案】</p>
<p>1、合理分面，合理展UV，烘焙UV通道中的面的大小比例应与实际一致。</p>
<p>2、Vary渲染器设置：</p>
<p style="text-indent:50px;">1）全局开关中，关闭默认灯光。</p>
<p style="text-indent:50px;">2）环境设置中，GI天光使用“天蓝色”。</p>
<p style="text-indent:50px;">3）间接照明中，打开折射、反射；一次反弹0.5，二次反弹0.3.</p>
<p style="text-indent:50px;">4）发光贴图，预设为高。</p>
<p style="text-indent:50px;">5）光缓存，细分为600.</p>
<p style="text-indent:50px;">6）系统，渲染区域细分，X为30。</p>
<p style="text-indent:0;">【备注说明】</p>
<p style="text-indent:0;">很久之前整理的了，有待实践考证。。。</p>
<p>&nbsp;</p>
<p>&nbsp;</p>
</p></div>
</div>
]]></content:encoded>
										</item>
		<item>
		<title>python实现图像模糊</title>
		<link>https://uzzz.org/article/3208.html</link>
				<pubDate>Fri, 08 Mar 2019 12:35:59 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[图像处理]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/3208.html</guid>
				<description><![CDATA[代码：高斯模糊 from PIL import Image, ImageFilter import numpy as np img = Image.open("./1.jpg").filter(ImageFilter.GaussianBlur) img.save("1_.jpg") 原图：&#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; &#160; 高斯模糊： &#160;]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div class="htmledit_views" id="content_views">
<p>代码：高斯模糊</p>
<pre class="has">
<code class="language-python">from PIL import Image, ImageFilter
import numpy as np

img = Image.open("./1.jpg").filter(ImageFilter.GaussianBlur)
img.save("1_.jpg")
</code></pre>
<p>原图：&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 高斯模糊：</p>
<p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190308203238639.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0dlb2ZmcmV5X01U,size_16,color_FFFFFF,t_70"><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190308203429258.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L0dlb2ZmcmV5X01U,size_16,color_FFFFFF,t_70"></p>
<p>&nbsp;</p>
</p></div>
</div>
]]></content:encoded>
										</item>
		<item>
		<title>【HISI系列】海思芯片驱动使用方法</title>
		<link>https://uzzz.org/article/3222.html</link>
				<pubDate>Sat, 23 Feb 2019 05:56:56 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[图像处理]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/3222.html</guid>
				<description><![CDATA[DATE: 2019-2-22 前言     在调试不同海思芯片的编码器时，遇到了需要加载和卸载驱动的情况，并且调试过程中出现不同硬件层面和编码的错误，特将问题定位方法记录一下以供后续参考。 1、海思芯片驱动使用方法     设备SDK包中的ko文件夹中存放了海思硬件运行需要的不同模块驱动，设备正常运行需要加载相应的驱动程序才可以。 HISI芯片驱动加载和卸载方法： 以Hi3559AV100为例： cd ko ./load3559av100 -a -sensor imx334 查看已经安装的驱动模块： lsmod 注意事项：不同模块驱动之间存在依赖关系，卸载模块驱动时存在先后顺序。 模块KO之间的依赖关系：参考文档：《HiMPP 媒体处理软件 FAQ.pdf》 每个加载上去的KO模块，有显示依赖关系的，lsmod查看时，会有Used by的标识。存在这种关系的KO之间需要按照顺序加载和相反顺序卸载。 有些模块KO是隐形依赖的，比如公共基础KO模块mmz.ko、hi_media.ko等需要先加载，这些KO模块若中途单独卸载再加载可能引起一些异常。 2、调试和问题定位方法 在运行海思编码器demo时，编码报错一般是由于编码API使用不当造成的，比如参数超出合法范围，系统驱动没有加载等。 2.1、MPP API调试工具 问题定位方法： 1、首先根据错误码（如下图6.5所示）大致定位问题的原因和方向。 2、查看mpp log信息： cat /dev/logmpp 注：mpp log信息中会具体指定错误类型以及错误的原因和位置。 调用HISI SDK API接口出现错误怎么办? 下面参考自：https://blog.csdn.net/listener51/article/details/87891633 【现象】  需要查看日志和调整 log 日志的等级。 【分析】 Log 日志记录 SDK 运行时错误的原因、大致位置以及一些系统运行状态等信息。因此可通过查看 log 日志，辅助错误定位。 目前日志分为 7 个等级，默认设置为等级 3 。等级设置的越高，表示记录到日志中的信息量就越多，当等级为 7 时，系统的整个运行状态实时的被记录到日志中，此时的信息量非常庞大，会大大降低系统的整体性能。因此，通常情况下，推荐设置为等级 3 ，因为此时只有发生错误的情况下，才会将信息记录到日志中，辅助定位绝大多数的错误。 【解决】  获取日志记录或修改日志等级时用到的命令如下： 查看各模块的日志等级，可以使用命令 cat /proc/umap/logmpp ，此命令会列出所有模块日志等级。 修改某个模块的日志等级，可使用命令 echo “venc=4” &#62; /proc/umap/logmpp ，其中 venc 是模块名，与 cat 命令列出的模块名一致即可。 修改所有模块的日志等级，可以使用命令 echo “all=4” &#62; /proc/umap/logmpp 。 获取日志记录，可以使用命令 cat /dev/logmpp ，此命令将打印出所有的日志信息；如果日志已读空，命令会阻塞并等待新的日志信息，可以使用 Ctl+C 退出。如果不想阻塞等待日志信息，可以使用命令 echo wait=0 &#62; /proc/umap/logmpp 取消 阻塞等待。也可以使用 open 、 read 等系统调用来操作 /dev/logmpp 这个设备节点。 参考文档：《HiMPP 媒体处理软件 FAQ.pdf》 2.2、模块和内存调试工具 OS内存分配 cat /proc/meminfo MMZ内存分配 /proc/media-mem 这里记录了当前MMZ内存被分配至哪些模块，被谁使用了。 各个模块调试信息 /proc/umap/* 各个模块的调试信息，当然也包括内存的一些使用情况。 比如： /proc/umap/rc //查看码率控制模块调试信息 /proc/umap/h264e //查看H.264编码通道模块调试信息 /proc/umap/h265e //查看H.265编码通道模块调试信息 /proc/umap/vb //查看视频缓存池模块的调试信息 附录：视频编码API错误码： 系统控制 SYS API错误码： 视频缓存池 VB API错误码： THE END!]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div id="content_views" class="markdown_views prism-atom-one-dark">
  <!-- flowchart 箭头图标 勿删 --><br />
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> </p>
<h4><a id="DATE_2019222_0"></a>DATE: 2019-2-22</h4>
<hr>
<h5><a id="_2"></a>前言</h5>
<p>    在调试不同海思芯片的编码器时，遇到了需要加载和卸载驱动的情况，并且调试过程中出现不同硬件层面和编码的错误，特将问题定位方法记录一下以供后续参考。</p>
<h5><a id="1_4"></a>1、海思芯片驱动使用方法</h5>
<p>    设备SDK包中的ko文件夹中存放了海思硬件运行需要的不同模块驱动，设备正常运行需要加载相应的驱动程序才可以。<br /> <strong>HISI芯片驱动加载和卸载方法：</strong><br /> 以Hi3559AV100为例：</p>
<pre><code class="prism language-m">cd ko
./load3559av100 -a -sensor imx334
</code></pre>
<p>查看已经安装的驱动模块：</p>
<pre><code class="prism language-m">lsmod
</code></pre>
<blockquote>
<p>注意事项：不同模块驱动之间存在依赖关系，卸载模块驱动时存在先后顺序。<br /> 模块KO之间的依赖关系：参考文档：《HiMPP 媒体处理软件 FAQ.pdf》</p>
<ul>
<li>每个加载上去的KO模块，有显示依赖关系的，lsmod查看时，会有Used by的标识。存在这种关系的KO之间需要按照顺序加载和相反顺序卸载。</li>
<li>有些模块KO是隐形依赖的，比如公共基础KO模块mmz.ko、hi_media.ko等需要先加载，这些KO模块若中途单独卸载再加载可能引起一些异常。</li>
</ul>
</blockquote>
<h5><a id="2_22"></a>2、调试和问题定位方法</h5>
<p>在运行海思编码器demo时，编码报错一般是由于编码API使用不当造成的，比如参数超出合法范围，系统驱动没有加载等。</p>
<h6><a id="21MPP_API_24"></a>2.1、MPP API调试工具</h6>
<p><strong>问题定位方法：</strong><br /> 1、首先根据错误码（<mark>如下图6.5所示</mark>）大致定位问题的原因和方向。<br /> 2、查看mpp log信息：</p>
<pre><code class="prism language-m">cat /dev/logmpp
</code></pre>
<blockquote>
<p>注：mpp log信息中会具体指定错误类型以及错误的原因和位置。</p>
</blockquote>
<p><strong>调用HISI SDK API接口出现错误怎么办?</strong></p>
<p>下面参考自：<a href="https://blog.csdn.net/listener51/article/details/87891633" rel="nofollow" data-token="fe54398c391fc280e1f5e7328e854108">https://blog.csdn.net/listener51/article/details/87891633</a></p>
<p><strong>【现象】</strong><br />  需要查看日志和调整 log 日志的等级。</p>
<p><strong>【分析】</strong><br /> <font color="red">Log 日志记录 SDK 运行时错误的原因、大致位置以及一些系统运行状态等信息。因此可通过查看 log 日志，辅助错误定位。</font><br /> 目前日志分为 7 个等级，默认设置为等级 3 。等级设置的越高，表示记录到日志中的信息量就越多，当等级为 7 时，系统的整个运行状态实时的被记录到日志中，此时的信息量非常庞大，会大大降低系统的整体性能。因此，通常情况下，推荐设置为等级 3 ，因为此时只有发生错误的情况下，才会将信息记录到日志中，辅助定位绝大多数的错误。</p>
<p><strong>【解决】</strong><br />  获取日志记录或修改日志等级时用到的命令如下：</p>
<ul>
<li>查看各模块的日志等级，可以使用命令 cat /proc/umap/logmpp ，此命令会列出所有模块日志等级。</li>
<li>修改某个模块的日志等级，可使用命令 echo “venc=4” &gt; /proc/umap/logmpp ，其中 venc 是模块名，与 cat 命令列出的模块名一致即可。<br /> 修改所有模块的日志等级，可以使用命令 echo “all=4” &gt; /proc/umap/logmpp 。</li>
<li>获取日志记录，可以使用命令 cat /dev/logmpp ，此命令将打印出所有的日志信息；如果日志已读空，命令会阻塞并等待新的日志信息，可以使用 Ctl+C 退出。如果不想阻塞等待日志信息，可以使用命令 echo wait=0 &gt; /proc/umap/logmpp 取消<br /> 阻塞等待。也可以使用 open 、 read 等系统调用来操作 /dev/logmpp 这个设备节点。</li>
</ul>
<p>参考文档：《HiMPP 媒体处理软件 FAQ.pdf》</p>
<h6><a id="22_54"></a>2.2、模块和内存调试工具</h6>
<ul>
<li>OS内存分配</li>
</ul>
<pre><code class="prism language-m">cat  /proc/meminfo
</code></pre>
<ul>
<li>MMZ内存分配</li>
</ul>
<pre><code class="prism language-m"> /proc/media-mem
</code></pre>
<p>这里记录了当前MMZ内存被分配至哪些模块，被谁使用了。</p>
<ul>
<li>各个模块调试信息</li>
</ul>
<pre><code class="prism language-m">/proc/umap/*
</code></pre>
<p>各个模块的调试信息，当然也包括内存的一些使用情况。<br /> 比如：</p>
<pre><code class="prism language-c"><span class="token operator">/</span>proc<span class="token operator">/</span>umap<span class="token operator">/</span>rc  	   <span class="token comment">//查看码率控制模块调试信息</span>
<span class="token operator">/</span>proc<span class="token operator">/</span>umap<span class="token operator">/</span>h264e   <span class="token comment">//查看H.264编码通道模块调试信息</span>
<span class="token operator">/</span>proc<span class="token operator">/</span>umap<span class="token operator">/</span>h265e   <span class="token comment">//查看H.265编码通道模块调试信息</span>
<span class="token operator">/</span>proc<span class="token operator">/</span>umap<span class="token operator">/</span>vb	   <span class="token comment">//查看视频缓存池模块的调试信息</span>
</code></pre>
<hr>
<p>附录：视频编码API错误码：<br /> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190223135217364.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NvYXJpbmdMZWVfZmlnaHRpbmc=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br /> 系统控制 SYS API错误码：<br /> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190227194013274.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NvYXJpbmdMZWVfZmlnaHRpbmc=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"><br /> 视频缓存池 VB API错误码：<br /> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190227194140650.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L1NvYXJpbmdMZWVfZmlnaHRpbmc=,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<hr>
<h2><a id="font_colorred_THE__END_91"></a><font color="red"><strong>THE END!</strong></font></h2>
<p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190309160031199.gif" alt="在这里插入图片描述"></p>
</p></div>
<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-526ced5128.css" rel="stylesheet">
</div>
]]></content:encoded>
										</item>
		<item>
		<title>图像去雾算法</title>
		<link>https://uzzz.org/article/2380.html</link>
				<pubDate>Wed, 13 Feb 2019 13:49:20 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[图像处理]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/2380.html</guid>
				<description><![CDATA[何凯明经典图像去雾算法：https://www.cnblogs.com/molakejin/p/5708883.html 暗通道 卷积神经网络网络去雾DehazeNet：https://blog.csdn.net/Julialove102123/article/details/80199276 大气散射模型 去雾总结：https://blog.csdn.net/u012556077/article/details/53364438 参考文献： 上：https://blog.csdn.net/baimafujinji/article/details/27206237 下：https://blog.csdn.net/baimafujinji/article/details/30060161 内容丰富：http://www.cnblogs.com/Imageshop/p/3281703.html 课件：http://www.cnblogs.com/changkaizhao/p/3266798.html matlab代码： https://blog.csdn.net/chongshangyunxiao321/article/details/51076800 https://blog.csdn.net/shenziheng1/article/details/56951002 https://www.cnblogs.com/pursuit1996/p/4912202.html]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div class="htmledit_views" id="content_views">
<p>何凯明经典图像去雾算法：<a href="https://www.cnblogs.com/molakejin/p/5708883.html" rel="nofollow" data-token="efce215f46c5248b363cf7b420ff7b6e">https://www.cnblogs.com/molakejin/p/5708883.html</a></p>
<p>暗通道</p>
<p>卷积神经网络网络去雾DehazeNet：<a href="https://blog.csdn.net/Julialove102123/article/details/80199276" rel="nofollow" data-token="995f9c96e1e5541c0650d45e7a58de75">https://blog.csdn.net/Julialove102123/article/details/80199276</a></p>
<p>大气散射模型</p>
<p>去雾总结：<a href="https://blog.csdn.net/u012556077/article/details/53364438" rel="nofollow" data-token="6131165111abf338ee0a2cdd074675ae">https://blog.csdn.net/u012556077/article/details/53364438</a></p>
<p>参考文献：</p>
<p>上：<a href="https://blog.csdn.net/baimafujinji/article/details/27206237" rel="nofollow" data-token="c5d44c52e67f956dbfab3bd0a3584694">https://blog.csdn.net/baimafujinji/article/details/27206237</a></p>
<p>下：<a href="https://blog.csdn.net/baimafujinji/article/details/30060161" rel="nofollow" data-token="775e75146ba2f1f30750cc76ac06462b">https://blog.csdn.net/baimafujinji/article/details/30060161</a></p>
<p>内容丰富：<a href="http://www.cnblogs.com/Imageshop/p/3281703.html" rel="nofollow" data-token="4faa0d2bed9ec86d8c4513cb57143bb8">http://www.cnblogs.com/Imageshop/p/3281703.html</a></p>
<p>课件：<a href="http://www.cnblogs.com/changkaizhao/p/3266798.html" rel="nofollow" data-token="77d34c371bab381d700c9cc6fef15478">http://www.cnblogs.com/changkaizhao/p/3266798.html</a></p>
<p>matlab代码：</p>
<p><a href="https://blog.csdn.net/chongshangyunxiao321/article/details/51076800" rel="nofollow" data-token="eb302a8f21ed38e4c32587c6c3fc8a4f">https://blog.csdn.net/chongshangyunxiao321/article/details/51076800</a></p>
<p><a href="https://blog.csdn.net/shenziheng1/article/details/56951002" rel="nofollow" data-token="4816b8ec14beb814b90431330cd79ded">https://blog.csdn.net/shenziheng1/article/details/56951002</a></p>
<p><a href="https://www.cnblogs.com/pursuit1996/p/4912202.html" rel="nofollow" data-token="3ce46ae9b20e4eb6ccb5ee40f163cc65">https://www.cnblogs.com/pursuit1996/p/4912202.html</a></p>
</p></div>
</div>
]]></content:encoded>
										</item>
	</channel>
</rss>
