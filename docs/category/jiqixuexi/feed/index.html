<?xml version="1.0" encoding="UTF-8"?><rss version="2.0"
	xmlns:content="http://purl.org/rss/1.0/modules/content/"
	xmlns:wfw="http://wellformedweb.org/CommentAPI/"
	xmlns:dc="http://purl.org/dc/elements/1.1/"
	xmlns:atom="http://www.w3.org/2005/Atom"
	xmlns:sy="http://purl.org/rss/1.0/modules/syndication/"
	xmlns:slash="http://purl.org/rss/1.0/modules/slash/"
	>

<channel>
	<title>机器学习 &#8211; 有组织在!</title>
	<atom:link href="https://uzzz.org/category/jiqixuexi/feed" rel="self" type="application/rss+xml" />
	<link>https://uzzz.org/</link>
	<description></description>
	<lastBuildDate>Mon, 27 May 2019 02:38:59 +0000</lastBuildDate>
	<language>en-US</language>
	<sy:updatePeriod>
	hourly	</sy:updatePeriod>
	<sy:updateFrequency>
	1	</sy:updateFrequency>
	<generator>https://wordpress.org/?v=5.2.4</generator>

<image>
	<url>https://uzzz.org/wp-content/uploads/2019/10/cropped-icon-32x32.png</url>
	<title>机器学习 &#8211; 有组织在!</title>
	<link>https://uzzz.org/</link>
	<width>32</width>
	<height>32</height>
</image> 
	<item>
		<title>AI：问题思考</title>
		<link>https://uzzz.org/article/2424.html</link>
				<pubDate>Mon, 27 May 2019 02:38:59 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[机器学习]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/2424.html</guid>
				<description><![CDATA[人类在识别物体的时候也是分层次进行识别的，如果物体是一个比较简单的易于识别的物体，那么可能很快就会被识别出来，但是一个比较复杂的物体（比如被遮挡的物体，或者是明暗不明显的物体）可能需要进行仔细的观察然后才能识别出物体的具体信息。 该想法是否可以应用到AI领域（卷积神经网络中），即在卷积神经网络的不同层对已经识别的特征进行输出，这样可以减少网络的计算量，如果在较浅层无法输出清晰正确的结果，那么可以在深层继续进行输出。 在图片分类中采用线性分类，更多的是一种对颜色敏感的分类模型，如果是采用灰度图像，那么线性分类器的效果可能会很差。 对图片的线性分类中的权重矩阵W，可以取出每一行的数据，将其还原成和原始图片大小相同的图片，可以还原出和分类数量相同的图片数量。还原的每一张图片表示其分类中的颜色权重值。 正则化的作用： a. 增加模型的泛化作用 b. 对权重矩阵进行特征选择，L2可以让权重矩阵更加的平局，L1可以获得稀疏的权重空间，本质上正则化就是权重矩阵W解空间的一个选择器 ，在同样满足条件的W空间中，选取具有想要特征的W值 比较不同损失函数之间的区别 softmax 加交叉熵的损失 SVM hinge loss softmax 会考虑到所有的输出数值，而svm只会考虑到和真值相聚较小的数值（相距较大的数值被忽略，不会对损失造成影响） softmax计算损失的时候，为什么需要对数化目标概率 为了更加方便的计算，同时可以将损失缩放还原到一个相对合理的计算空间中。 也是为了数学上的优美]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div id="content_views" class="markdown_views prism-atom-one-dark">
  <!-- flowchart 箭头图标 勿删 --><br />
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> </p>
<ol>
<li>人类在识别物体的时候也是分层次进行识别的，如果物体是一个比较简单的易于识别的物体，那么可能很快就会被识别出来，但是一个比较复杂的物体（比如被遮挡的物体，或者是明暗不明显的物体）可能需要进行仔细的观察然后才能识别出物体的具体信息。<br /> 该想法是否可以应用到AI领域（卷积神经网络中），即在卷积神经网络的不同层对已经识别的特征进行输出，这样可以减少网络的计算量，如果在较浅层无法输出清晰正确的结果，那么可以在深层继续进行输出。</li>
<li>在图片分类中采用线性分类，更多的是一种对颜色敏感的分类模型，如果是采用灰度图像，那么线性分类器的效果可能会很差。</li>
<li>对图片的线性分类中的权重矩阵W，可以取出每一行的数据，将其还原成和原始图片大小相同的图片，可以还原出和分类数量相同的图片数量。还原的每一张图片表示其分类中的颜色权重值。</li>
<li>正则化的作用：<br /> a. 增加模型的泛化作用<br /> b. 对权重矩阵进行特征选择，L2可以让权重矩阵更加的平局，L1可以获得稀疏的权重空间，本质上正则化就是权重矩阵W解空间的一个选择器 ，在同样满足条件的W空间中，选取具有想要特征的W值</li>
<li>比较不同损失函数之间的区别<br /> softmax 加交叉熵的损失<br /> SVM hinge loss<br /> softmax 会考虑到所有的输出数值，而svm只会考虑到和真值相聚较小的数值（相距较大的数值被忽略，不会对损失造成影响）</li>
<li>softmax计算损失的时候，为什么需要对数化目标概率<br /> 为了更加方便的计算，同时可以将损失缩放还原到一个相对合理的计算空间中。<br /> 也是为了数学上的优美</li>
</ol></div>
<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-526ced5128.css" rel="stylesheet">
</div>
]]></content:encoded>
										</item>
		<item>
		<title>matlab中关于矩阵数组数据图像化的方法总结</title>
		<link>https://uzzz.org/article/2558.html</link>
				<pubDate>Wed, 24 Apr 2019 02:10:07 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[机器学习]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/2558.html</guid>
				<description><![CDATA[应用目的 1、材料研究中试样接头处不同部位的硬度是不一样的，有时候为了形象的表示该现象，需要将不同位置的硬度数据图像化。 2、能谱面扫描时，牛津仪器给出的图像时依据明暗调节的，图像并不好看，如果可以保留原始数据，zaimatlab中将明暗做成云图将会让结果非常好看。 源数据类型 与位置相关的数据。可以理解为一个大的二维矩阵，每个位置存在不同的数据。 方法及命令 imshow等。 原始数据 。。。。。。。。。。。。。。。 方法0：最笨的方法 X=[对应每个点的横坐标,,,,,,,,,,] Y=[对应每个点的纵坐标,,,,,,,,,,] Z=[对应每个点的具体数值,,,,,,,,,] fill(X,Y,Z) shading interp; colorbar; axis equal; 方法1： 首先需要导入excel数据并保存呈mat格式 将mat格式打开并采用table2array命令转换成矩阵 然后采用imshow命令 load(hardness.mat) A=table2array(hardness)&#160; %该函数可以将table数据变为数组，即double. imshow(A) 然而存在如下问题 1 图片为白色；2 图片为灰度图 &#160;在matlab中，我们常使用imshow()函数来显示图像，而此时的图像矩阵可能经过了某种运算。在matlab中，为了保证精度，经过了运算的图像矩阵A其数据类型会从unit8型变成double型。如果直接运行imshow(A)，我们会发现显示的是一个白色的图像。这是因为imshow()显示图像时对double型是认为在0~1范围内，即大于1时都是显示为白色，而imshow显示uint8型时是0~255范围。而经过运算的范围在0-255之间的double型数据就被不正常得显示为白色图像了。 即使采用采取各个数据与最大值相除，然而=1的位置仍为白色，因此imshow命令并不合适 imshow(B,[])等效于C=B/max(max(B)) imshow(C,[]) 方法2： linspace是Matlab中的一个指令，用于产生指定范围内的指定数量点数，相邻数据跨度相同，并返回一个行向量。 调用方法：linspace(x1,x2,N) 功 能：用于产生x1，x2之间的N点行矢量，相邻数据跨度相同。其中x1、x2、N分别为起始值、终止值、元素个数。若缺省N，默认点数为100。 举个例子 A=linspace（-6，6，4） 运行结果如下：A=-6 -2 2 6 意思就是 -6为起点 6为终点 4指向量的个数 且是均匀的分段的。 如在命令窗口中输入： X=linspace(5,100,20) 将输出： X = 5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100 这和X=[5:5:100]的效果是一样的。 所以 X=linspace(1,10,10) Y=linspace(1,30,30) matlab中 hold on&#160;的作用是在作下一幅图时保留已有图像 方法3 最终在发现可以采用imagesc函数解决。 需要注意的是 1、imagesc函数得到的图像时块状图，需要meshgrid函数重新网格细化，线性插值，重新得到outData后，再采用imagesc即可 2、一定注意将数据table转换为数组形式。A=table2array(B);imagesc(A);enter 例子代码如下 %// Define your data data = [1 1 1 1 1 1 1 1 1 1; 1 1.04 1.04 1.04 1.03 1 1.01 1.01 1.03 1.01; 1.36 1.3 1.25 1.2 1.15 1.1 1.2 1.13 1.07 1.11; 3.65 3.16 2.94 2.68 2.39 2.22 2.17 1.95 1.79 1.81; 5.91 5.75 5.47 5.3 4.98 4.79 4.62 4.55 4.38 4.19; 6 6 5.99 5.83 5.49 5.33 5.14 4.94 4.77 4.74]; &#160; &#160; %// Define integer grid of coordinates for the above data [X,Y] = meshgrid(1:size(data,2), 1:size(data,1)); %// Define a finer grid of points [X2,Y2] =]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div class="htmledit_views" id="content_views">
<p>应用目的</p>
<p>1、材料研究中试样接头处不同部位的硬度是不一样的，有时候为了形象的表示该现象，需要将不同位置的硬度数据图像化。</p>
<p>2、能谱面扫描时，牛津仪器给出的图像时依据明暗调节的，图像并不好看，如果可以保留原始数据，zaimatlab中将明暗做成云图将会让结果非常好看。</p>
<p>源数据类型</p>
<p>与位置相关的数据。可以理解为一个大的二维矩阵，每个位置存在不同的数据。</p>
<p>方法及命令</p>
<p>imshow等。</p>
<p>原始数据</p>
<p>。。。。。。。。。。。。。。。</p>
<p>方法0：最笨的方法</p>
<p>X=[对应每个点的横坐标,,,,,,,,,,]</p>
<p>Y=[对应每个点的纵坐标,,,,,,,,,,]</p>
<p>Z=[对应每个点的具体数值,,,,,,,,,]</p>
<p>fill(X,Y,Z)<br /> shading interp;<br /> colorbar;<br /> axis equal;</p>
<p><em><strong><span style="color:#f33b45;">方法1：</span></strong></em></p>
<p>首先需要导入excel数据并保存呈mat格式</p>
<p>将mat格式打开并采用table2array命令转换成矩阵</p>
<p>然后采用imshow命令</p>
<p>load(hardness.mat)</p>
<p><em><strong>A=table2array(hardness)&nbsp; %该函数可以将table数据变为数组，即double.</strong></em></p>
<p>imshow(A)</p>
<p>然而存在如下问题</p>
<p>1 图片为白色；2 图片为灰度图</p>
<p>&nbsp;在matlab中，我们常使用imshow()函数来显示图像，而此时的图像矩阵可能经过了某种运算。在matlab中，为了保证精度，经过了运算的图像矩阵A其数据类型会从unit8型变成double型。如果直接运行imshow(A)，我们会发现显示的是一个白色的图像。这是因为imshow()显示图像时对double型是认为在0~1范围内，即大于1时都是显示为白色，而imshow显示uint8型时是0~255范围。而经过运算的范围在0-255之间的double型数据就被不正常得显示为白色图像了。</p>
<p>即使采用采取各个数据与最大值相除，然而=1的位置仍为白色，因此imshow命令并不合适</p>
<p>imshow(B,[])等效于C=B/max(max(B)) imshow(C,[])</p>
<p><span style="color:#f33b45;"><em><strong>方法2：</strong></em></span></p>
<p>linspace是Matlab中的一个指令，用于产生指定范围内的指定数量点数，相邻数据跨度相同，并返回一个行向量。</p>
<p>调用方法：linspace(x1,x2,N)</p>
<p>功 能：用于产生x1，x2之间的N点行矢量，相邻数据跨度相同。其中x1、x2、N分别为起始值、终止值、元素个数。若缺省N，默认点数为100。</p>
<p>举个例子 A=linspace（-6，6，4）</p>
<p>运行结果如下：A=-6 -2 2 6</p>
<p>意思就是 -6为起点 6为终点 4指向量的个数 且是均匀的分段的。</p>
<p>如在命令窗口中输入：</p>
<p>X=linspace(5,100,20)</p>
<p>将输出：</p>
<p>X =</p>
<p>5 10 15 20 25 30 35 40 45 50 55 60 65 70 75 80 85 90 95 100</p>
<p>这和X=[5:5:100]的效果是一样的。</p>
<p>所以</p>
<p>X=linspace(1,10,10)</p>
<p>Y=linspace(1,30,30)</p>
<p>matlab中 hold on&nbsp;的作用是在作下一幅图时保留已有图像</p>
<p><em><strong><span style="color:#f33b45;">方法3</span></strong></em></p>
<p><em><strong><span style="color:#f33b45;">最终在发现可以采用imagesc函数解决。</span></strong></em></p>
<p><em><strong><span style="color:#f33b45;">需要注意的是</span></strong></em></p>
<p><em><strong><span style="color:#f33b45;">1、imagesc函数得到的图像时块状图，需要meshgrid函数重新网格细化，线性插值，重新得到outData后，再采用imagesc即可</span></strong></em></p>
<p><em><strong><span style="color:#f33b45;">2、一定注意将数据table转换为数组形式。A=table2array(B);imagesc(A);enter</span></strong></em></p>
<p><em><strong><span style="color:#f33b45;">例子代码如下</span></strong></em></p>
<p><span>%// Define your data<br /> data = [1 1 1 1 1 1 1 1 1 1; 1 1.04 1.04 1.04 1.03 1 1.01 1.01 1.03 1.01; 1.36 1.3 1.25 1.2 1.15 1.1 1.2 1.13 1.07 1.11; 3.65 3.16 2.94 2.68 2.39 2.22 2.17 1.95 1.79 1.81; 5.91 5.75 5.47 5.3 4.98 4.79 4.62 4.55 4.38 4.19; 6 6 5.99 5.83 5.49 5.33 5.14 4.94 4.77 4.74]; &nbsp; &nbsp;</span></p>
<p><span>%// Define integer grid of coordinates for the above data<br /> [X,Y] = meshgrid(1:size(data,2), 1:size(data,1));</span></p>
<p><span>%// Define a finer grid of points<br /> [X2,Y2] = meshgrid(1:0.01:size(data,2), 1:0.01:size(data,1));</span></p>
<p><span>%// Interpolate the data and show the output<br /> outData = interp2(X, Y, data, X2, Y2, &#8216;linear&#8217;);<br /> imagesc(outData);</span></p>
<p><span>%// Cosmetic changes for the axes<br /> set(gca, &#8216;XTick&#8217;, linspace(1,size(X2,2),size(X,2)));&nbsp;<br /> set(gca, &#8216;YTick&#8217;, linspace(1,size(X2,1),size(X,1)));<br /> set(gca, &#8216;XTickLabel&#8217;, 1:size(X,2));<br /> set(gca, &#8216;YTickLabel&#8217;, 1:size(X,1));</span></p>
<p><span>%// Add colour bar<br /> colorbar;</span></p>
<p>&nbsp;</p>
</p></div>
</div>
]]></content:encoded>
										</item>
		<item>
		<title>全局低照度图像增强matlab</title>
		<link>https://uzzz.org/article/3421.html</link>
				<pubDate>Sun, 20 Jan 2019 10:51:05 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[机器学习]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/3421.html</guid>
				<description><![CDATA[clear; clc; close all; %读入图片 A=imread('before.png'); % A= rgb2gray(A); % mean2(A) % std2(A) %显示源图片 figure ; imshow(A); title('RGB Original Image') %调用ALTM outval = ALTM(A); % mean2(outval) % std2(outval) %输出目标图像 figure ; imshow(outval); %图像增强函数 function outval = ALTM(I) II = im2double(I); Ir=double(II(:,:,1)); Ig=double(II(:,:,2)); Ib=double(II(:,:,3)); % % % % Global Adaptation % input world luminance values Lw = 0.299 * Ir + 0.587 * Ig + 0.114 * Ib; % Lw = im2double(I); % % % the maximum luminance value Lwmax = max(max(Lw)); [m, n] = size(Lw);%[]矩阵表示 % % % log-average luminance Lwaver = exp(sum(sum(log(0.001 + Lw))) / (m * n)); Lg = log(Lw / Lwaver + 1) / log(Lwmax / Lwaver + 1); gain = Lg ./ Lw; gain(find(Lw == 0)) = 0; outval = cat(3, gain .* Ir, gain .* Ig, gain .* Ib); % outval = gain .* Lw; end 结果如下： 原图片： 效果图片： 原图片： 效果图片：]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div class="htmledit_views" id="content_views">
<pre class="has">
<code> 
clear;
clc;
close all;
%读入图片
A=imread('before.png');
% A= rgb2gray(A);
% mean2(A)
% std2(A)
%显示源图片
figure ;
imshow(A);
title('RGB Original Image')
%调用ALTM
outval = ALTM(A);
% mean2(outval)
% std2(outval)
%输出目标图像
figure ;
imshow(outval);
%图像增强函数
function outval = ALTM(I)
II = im2double(I);
Ir=double(II(:,:,1));
Ig=double(II(:,:,2));
Ib=double(II(:,:,3));
% 
% % % Global Adaptation
% input world luminance values
Lw = 0.299 * Ir + 0.587 * Ig + 0.114 * Ib;
% Lw = im2double(I);
% % % the maximum luminance value
Lwmax = max(max(Lw));
[m, n] = size(Lw);%[]矩阵表示
% % % log-average luminance
Lwaver = exp(sum(sum(log(0.001 + Lw))) / (m * n));
Lg = log(Lw / Lwaver + 1) / log(Lwmax / Lwaver + 1);
gain = Lg ./ Lw;
gain(find(Lw == 0)) = 0;
outval = cat(3, gain .* Ir, gain .* Ig, gain .* Ib);
% outval = gain .* Lw;
 
end

</code></pre>
<p>结果如下：</p>
<p>原图片：</p>
<p><img alt="" class="has" height="282" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190120184811903.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzI5MjUwNDk3,size_16,color_FFFFFF,t_70" width="566"></p>
<p>效果图片：</p>
<p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190120184929345.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzI5MjUwNDk3,size_16,color_FFFFFF,t_70"></p>
<p>原图片：</p>
<p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190120185013569.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzI5MjUwNDk3,size_16,color_FFFFFF,t_70"></p>
<p>效果图片：</p>
<p><img alt="" class="has" src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190120185042124.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3NpbmF0XzI5MjUwNDk3,size_16,color_FFFFFF,t_70"></p>
</p></div>
</div>
]]></content:encoded>
										</item>
		<item>
		<title>MATLAB中如何设置网格线的颜色，透明度，粗细等</title>
		<link>https://uzzz.org/article/2932.html</link>
				<pubDate>Fri, 07 Dec 2018 08:29:53 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[机器学习]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/2932.html</guid>
				<description><![CDATA[在MATLAB的命令窗中输入： help grid 打开grid的帮助页，最下面会有各种属性的设置命令： 从图中可见，GridColor可以调整颜色，GridAlpha可以调整网格线颜色深浅（也可以说是透明度），LineWidth可以调整线宽等等。 使用举例： set(gca,'ygrid','on','gridlinestyle','--','Gridalpha',0.4)]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div id="content_views" class="markdown_views prism-atom-one-dark">
  <!-- flowchart 箭头图标 勿删 --><br />
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> </p>
<p>在MATLAB的命令窗中输入：</p>
<pre><code>help grid
</code></pre>
<p>打开grid的帮助页，最下面会有各种属性的设置命令：<br /> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20181207162532667.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQyOTczNTYy,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></p>
<p>从图中可见，GridColor可以调整颜色，GridAlpha可以调整网格线颜色深浅（也可以说是透明度），LineWidth可以调整线宽等等。<br /> 使用举例：</p>
<pre><code>set(gca,'ygrid','on','gridlinestyle','--','Gridalpha',0.4)
</code></pre>
</p></div>
<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-526ced5128.css" rel="stylesheet">
</div>
]]></content:encoded>
										</item>
		<item>
		<title>MATLAB中的plot()函数</title>
		<link>https://uzzz.org/article/2641.html</link>
				<pubDate>Thu, 15 Nov 2018 08:38:57 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[机器学习]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/2641.html</guid>
				<description><![CDATA[xk=315:0.01:1575;&#160;&#160; temp=157.5; a=temp ./xk; plot(xk,a); %hold on %plot(xk,a); %hold off grid minor; axis([250 1650 0 0.6]); xlabel('5级暗纹的距离'); ylabel('a的距离'); grid minor;&#160; 添加细密的网格线 grid&#160;on；添加网格线 axis([xmin xmax ymin ymax]);&#160;设置最大最小的xy坐标范围 xlabel(&#8216;5级暗纹的距离&#8217;);&#160; 设置xy坐标的名称 ylabel(&#8216;a的距离&#8217;); hold on&#160;继续向plot()函数图像上添加图像 hold off&#160;结束这个动作 &#160; &#160;]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div class="htmledit_views" id="content_views">
<hr>
<pre class="has">
<code>xk=315:0.01:1575;&nbsp;&nbsp;
temp=157.5;
a=temp ./xk;

plot(xk,a);

%hold on
%plot(xk,a);
%hold off

grid minor;
axis([250 1650 0 0.6]);
xlabel('5级暗纹的距离');
ylabel('a的距离');</code></pre>
<hr>
<p><strong>grid minor;&nbsp; 添加细密的网格线</strong></p>
<p><strong>grid&nbsp;on；添加网格线</strong></p>
<p><strong>axis([xmin xmax ymin ymax]);&nbsp;设置最大最小的xy坐标范围</strong></p>
<p><strong>xlabel(&#8216;5级暗纹的距离&#8217;);&nbsp; 设置xy坐标的名称<br /> ylabel(&#8216;a的距离&#8217;); </strong></p>
<p><strong>hold on&nbsp;继续向plot()函数图像上添加图像</strong></p>
<p><strong>hold off&nbsp;结束这个动作</strong></p>
<p>&nbsp;</p>
<p>&nbsp;</p>
</p></div>
</div>
]]></content:encoded>
										</item>
		<item>
		<title>MNIST手写数字数据集的读取，基于python3</title>
		<link>https://uzzz.org/article/3008.html</link>
				<pubDate>Sun, 23 Sep 2018 10:20:15 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[机器学习]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/3008.html</guid>
				<description><![CDATA[MNIST 是一个入门级别的计算机视觉数据库，也是机器学习领域最有名的数据集之一。当我们开始学习编程的时候，第一件事往往就是打“Hello world”。而在机器学习中，识别 MNIST 就相当于编程中的“Hello world”。 MNIST 中包含了手写数字0~9的图片以及他们对应的标签。如下图所示： MNIST 数据集的官网是http://yann.lecun.com/exdb/mnist/，我们可以从这里手动下载数据集。 你可以在官网上下载到下面四个压缩包： train-images-idx3-ubyte.gz train-labels-idx1-ubyte.gz t10k-images-idx3-ubyte.gz t10k-labels-idx1-ubyte.gz 解压后得到四个文件： 训练集图像：t10k-images.idx3-ubyte 训练集标签：t10k-labels.idx1-ubyte 测试集图像：train-images.idx3-ubyte 测试集标签：train-labels.idx1-ubyte MNIST数据集文件格式说明 训练集中有60,000个样本，测试集中有5,000个样本。所有图像都被标准化为28*28像素，像素值在0~255之间，0表示背景，255表示前景。 文件格式说明（以训练集为例）： 图片文件格式说明： ---------------------------------------- [字节位置] [类型] [值] [描述] 0000 32位整型 2051 幻数 0004 32位整型 60000 图片数 0008 32位整型 28 行数 0012 32位整型 28 列数 0016 无符号字节 ?? 像素 0017 无符号字节 ?? 像素 ...... xxxx 无符号字节 ?? 像素 ---------------------------------------- 标签文件格式说明： ---------------------------------------- [字节位置] [类型] [值] [描述] 0000 32位整型 2049 幻数 0004 32位整型 60000 标签数 0008 无符号字节 ?? 标签 0009 无符号字节 ?? 标签 ...... xxxx 无符号字节 ?? 标签 ---------------------------------------- 注：这里的整形指的都是无符号整型 上述的32位整形遵循**“MSB first”**，即高位字节在左边，如十进制8，二进制储存形式为1000。 幻数是一个固定值，它占据文件的前4个字节，实际上表示的是这个文件储存的是图片还是标签，没有具体用处，我们可以忽略它。 图片数与标签数占据文件4~7个字节的位置，在训练集中，它为60,000，表示这个文件有60,000个图片或标签，在测试集中，它为5,000。 行数和列数描述的是每张图片的大小，它们也是固定值，都为28。 每张图片有28*28=784个像素，所以从图片文件第16个字节位置开始，每隔784个字节为一张新图片，其中每个像素的像素值为0~255。 从标签文件的第8个字节位置开始，每个字节都对应着一张图片的数字，标签的值为0~9。 程序实现 我们已将了解了数据集文件的格式，现在我们将实现读取数据集的程序。在这里我使用了Python3来实现它。 我在这里使用了Python内置模块struct中的unpack函数和Numpy库。 import numpy as np from struct import unpack 然后我以读取图片文件为例： def read_image(path): with open(path, 'rb') as f: magic, num, rows, cols = unpack('&#62;4I', f.read(16)) img = np.fromfile(f, dtype=np.uint8).reshape(num, 784) return img 内置模块struct可以处理存储在文件中的二进制数据，通过此模块的unpack函数，可以实现对二进制文件的转换。unpack的定义如下： unpack(fmt, buffer) -&#62; (v1, v2, ...) 返回一个元组，其中包含根据格式字符串fmt解压缩的值。fmt是格式字符串，buffer是被解压缩的字符串或二进制 关于格式字符串的详细信息可以去官网或者专门介绍此模块的博客中查看。 在我们的程序中，’&#62;4I’表示的是以大端的转换4个无符号整型变量（4个字节，非负数）。unpack示意图如下： np.fromfile是通过一种使用已知数据类型读取二进制数据的函数，它返回的是一个ndarray类型的数组。我们根据文件的结构，选择了uint8这个数据类型。np.fromfile的定义如下： numpy.fromfile(file, dtype=float, count=-1, sep='') 根据文本或二进制文件中的数据构造数组。 参数： file : file或str 打开文件对象或文件名。 dtype : data-type 返回的数组的数据类型。对于二进制文件，它用于确定文件中项目的大小和字节顺序。 count : int 要读取的项目数。-1表示所有项目（即完整文件）。 sep : str 如果文件是文本文件，则在项目之间分隔。空（""）分隔符表示该文件应被视为二进制文件。 分隔符中的空格（""）匹配零个或多个空格字符。仅包含空格的分隔符必须至少匹配一个空格。 当我们通过np.fromfile读入文件后，会返回一个一维数组，我们现在需要把每张照片都拿出来，所以我使用了reshape这个函数，这个函数返回一个具相同数据但形状不同的数组，可以以一张图来简单演示： 同理，我也可以读取标签文件。代码如下： def read_label(path): with open(path, 'rb') as f: magic, num = unpack('&#62;2I', f.read(8)) lab = np.fromfile(f, dtype=np.uint8)]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div id="content_views" class="markdown_views prism-tomorrow-night-eighties">
  <!-- flowchart 箭头图标 勿删 --><br />
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> </p>
<p>MNIST 是一个入门级别的计算机视觉数据库，也是机器学习领域最有名的数据集之一。当我们开始学习编程的时候，第一件事往往就是打“Hello world”。而在机器学习中，识别 MNIST 就相当于编程中的“Hello world”。</p>
<p>MNIST 中包含了手写数字0~9的图片以及他们对应的标签。如下图所示：<br /> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190320215629108.png#pic_center" alt=""><br /> MNIST 数据集的官网是<a href="http://yann.lecun.com/exdb/mnist/" rel="nofollow" data-token="c7e3d02de55d407fcaf4160149376eb9">http://yann.lecun.com/exdb/mnist/</a>，我们可以从这里手动下载数据集。</p>
<p>你可以在官网上下载到下面四个压缩包：</p>
<ul>
<li>train-images-idx3-ubyte.gz</li>
<li>train-labels-idx1-ubyte.gz</li>
<li>t10k-images-idx3-ubyte.gz</li>
<li>t10k-labels-idx1-ubyte.gz</li>
</ul>
<p>解压后得到四个文件：</p>
<ul>
<li>训练集图像：t10k-images.idx3-ubyte</li>
<li>训练集标签：t10k-labels.idx1-ubyte</li>
<li>测试集图像：train-images.idx3-ubyte</li>
<li>测试集标签：train-labels.idx1-ubyte</li>
</ul>
<h2><a id="MNIST_18"></a>MNIST数据集文件格式说明</h2>
<p>训练集中有60,000个样本，测试集中有5,000个样本。所有图像都被标准化为28*28像素，像素值在0~255之间，0表示背景，255表示前景。</p>
<h3><a id="_21"></a>文件格式说明（以训练集为例）：</h3>
<pre><code>图片文件格式说明：
----------------------------------------
[字节位置]   [类型]       [值]      [描述] 
0000        32位整型     2051      幻数
0004        32位整型     60000     图片数
0008        32位整型     28        行数 
0012        32位整型     28        列数 
0016        无符号字节    ??        像素 
0017        无符号字节    ??        像素 
......
xxxx        无符号字节    ??        像素
----------------------------------------

标签文件格式说明：
----------------------------------------
[字节位置]   [类型]       [值]      [描述] 
0000        32位整型     2049      幻数
0004        32位整型     60000     标签数
0008        无符号字节    ??        标签 
0009        无符号字节    ??        标签 
......
xxxx        无符号字节    ??        标签
----------------------------------------
注：这里的整形指的都是无符号整型
</code></pre>
<p>上述的32位整形遵循**“MSB first”**，即高位字节在左边，如十进制8，二进制储存形式为1000。</p>
<p><strong>幻数</strong>是一个固定值，它占据文件的前4个字节，实际上表示的是这个文件储存的是图片还是标签，没有具体用处，我们可以忽略它。</p>
<p><strong>图片数</strong>与<strong>标签数</strong>占据文件4~7个字节的位置，在训练集中，它为60,000，表示这个文件有60,000个图片或标签，在测试集中，它为5,000。</p>
<p><strong>行数</strong>和<strong>列数</strong>描述的是每张图片的大小，它们也是固定值，都为28。</p>
<p>每张图片有28*28=784个<strong>像素</strong>，所以从图片文件第16个字节位置开始，每隔784个字节为一张新图片，其中每个像素的像素值为0~255。</p>
<p>从<strong>标签</strong>文件的第8个字节位置开始，每个字节都对应着一张图片的数字，标签的值为0~9。</p>
<h2><a id="_59"></a>程序实现</h2>
<p>我们已将了解了数据集文件的格式，现在我们将实现读取数据集的程序。在这里我使用了Python3来实现它。</p>
<p>我在这里使用了Python内置模块struct中的unpack函数和Numpy库。</p>
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> struct <span class="token keyword">import</span> unpack
</code></pre>
<p>然后我以读取图片文件为例：</p>
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">read_image</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        magic<span class="token punctuation">,</span> num<span class="token punctuation">,</span> rows<span class="token punctuation">,</span> cols <span class="token operator">=</span> unpack<span class="token punctuation">(</span><span class="token string">'&gt;4I'</span><span class="token punctuation">,</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        img <span class="token operator">=</span> np<span class="token punctuation">.</span>fromfile<span class="token punctuation">(</span>f<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>num<span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> img
</code></pre>
<p>内置模块struct可以处理存储在文件中的二进制数据，通过此模块的unpack函数，可以实现对二进制文件的转换。unpack的定义如下：</p>
<pre><code>unpack(fmt, buffer) -&gt; (v1, v2, ...)
返回一个元组，其中包含根据格式字符串fmt解压缩的值。fmt是格式字符串，buffer是被解压缩的字符串或二进制
</code></pre>
<p>关于格式字符串的详细信息可以去官网或者专门介绍此模块的博客中查看。</p>
<p>在我们的程序中，’&gt;4I’表示的是以大端的转换4个无符号整型变量（4个字节，非负数）。unpack示意图如下：</p>
<p><img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190320215723229.png#pic_center" alt=""><br /> np.fromfile是通过一种使用已知数据类型读取二进制数据的函数，它返回的是一个ndarray类型的数组。我们根据文件的结构，选择了uint8这个数据类型。np.fromfile的定义如下：</p>
<pre><code>numpy.fromfile(file, dtype=float, count=-1, sep='')
    根据文本或二进制文件中的数据构造数组。
	参数：
        file : file或str
            打开文件对象或文件名。
        dtype : data-type
            返回的数组的数据类型。对于二进制文件，它用于确定文件中项目的大小和字节顺序。
        count : int
            要读取的项目数。-1表示所有项目（即完整文件）。
        sep : str
			如果文件是文本文件，则在项目之间分隔。空（""）分隔符表示该文件应被视为二进制文件。
			分隔符中的空格（""）匹配零个或多个空格字符。仅包含空格的分隔符必须至少匹配一个空格。
</code></pre>
<p>当我们通过np.fromfile读入文件后，会返回一个一维数组，我们现在需要把每张照片都拿出来，所以我使用了reshape这个函数，这个函数返回一个具相同数据但形状不同的数组，可以以一张图来简单演示：<br /> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/20190320215837788.png#pic_center" alt="在这里插入图片描述"><br /> 同理，我也可以读取标签文件。代码如下：</p>
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">read_label</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">:</span>
<span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
    magic<span class="token punctuation">,</span> num <span class="token operator">=</span> unpack<span class="token punctuation">(</span><span class="token string">'&gt;2I'</span><span class="token punctuation">,</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    lab <span class="token operator">=</span> np<span class="token punctuation">.</span>fromfile<span class="token punctuation">(</span>f<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span>
<span class="token keyword">return</span> lab
</code></pre>
<p>读取标签的原理与读入图片的原理相同，就不在重复一遍了。</p>
<blockquote>
<p>注：当你没有解压文件，即你的文件后缀名为.gz的时候，可以用以下方法读取：</p>
</blockquote>
<pre><code class="prism language-python"><span class="token comment">#其他代码正常</span>
<span class="token keyword">import</span> gzip
<span class="token keyword">with</span> gzip<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span><span class="token string">'data/train-images-idx3-ubyte.gz'</span><span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre>
<h2><a id="MNIST_120"></a>MNIST数据处理</h2>
<p>我们总是希望数据的格式能符合我们的要求，所以在使用数据之前，我们需要对它进行一些处理。</p>
<h4><a id="0010_123"></a>将图像的像素值正规化为0.0~1.0</h4>
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">normalize_image</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token punctuation">:</span>
    img <span class="token operator">=</span> image<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span>
    <span class="token keyword">return</span> img
</code></pre>
<h4><a id="one_hot_129"></a>将标签转化为one_hot编码</h4>
<pre><code class="prism language-python"><span class="token keyword">def</span> <span class="token function">one_hot_label</span><span class="token punctuation">(</span>label<span class="token punctuation">)</span><span class="token punctuation">:</span>
    lab <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>label<span class="token punctuation">.</span>size<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> row <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>lab<span class="token punctuation">)</span><span class="token punctuation">:</span>
        row<span class="token punctuation">[</span>label<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
    <span class="token keyword">return</span> lab
</code></pre>
<p>举例说明one_hot编码：假如一共有4类（数字0~3），0的ont_hot为1000，1的one_hot为0100，2的one_hot为0010，3的one_hot为0001。只有一个位为1，1所在的位置就代表第几类。如下图所示：<br /> <img src="https://uzshare.com/_p?https://img-blog.csdnimg.cn/2019032021591833.png#pic_center" alt=""></p>
<h2><a id="MNIST_140"></a>MNIST读取函数</h2>
<p>以下是全部代码：</p>
<pre><code class="prism language-python"><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np
<span class="token keyword">from</span> struct <span class="token keyword">import</span> unpack

<span class="token keyword">def</span> <span class="token function">__read_image</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        magic<span class="token punctuation">,</span> num<span class="token punctuation">,</span> rows<span class="token punctuation">,</span> cols <span class="token operator">=</span> unpack<span class="token punctuation">(</span><span class="token string">'&gt;4I'</span><span class="token punctuation">,</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token number">16</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        img <span class="token operator">=</span> np<span class="token punctuation">.</span>fromfile<span class="token punctuation">(</span>f<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span><span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>num<span class="token punctuation">,</span> <span class="token number">784</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> img

<span class="token keyword">def</span> <span class="token function">__read_label</span><span class="token punctuation">(</span>path<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">with</span> <span class="token builtin">open</span><span class="token punctuation">(</span>path<span class="token punctuation">,</span> <span class="token string">'rb'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> f<span class="token punctuation">:</span>
        magic<span class="token punctuation">,</span> num <span class="token operator">=</span> unpack<span class="token punctuation">(</span><span class="token string">'&gt;2I'</span><span class="token punctuation">,</span> f<span class="token punctuation">.</span>read<span class="token punctuation">(</span><span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
        lab <span class="token operator">=</span> np<span class="token punctuation">.</span>fromfile<span class="token punctuation">(</span>f<span class="token punctuation">,</span> dtype<span class="token operator">=</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span>
    <span class="token keyword">return</span> lab
    
<span class="token keyword">def</span> <span class="token function">__normalize_image</span><span class="token punctuation">(</span>image<span class="token punctuation">)</span><span class="token punctuation">:</span>
    img <span class="token operator">=</span> image<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token number">255.0</span>
    <span class="token keyword">return</span> img

<span class="token keyword">def</span> <span class="token function">__one_hot_label</span><span class="token punctuation">(</span>label<span class="token punctuation">)</span><span class="token punctuation">:</span>
    lab <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>label<span class="token punctuation">.</span>size<span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> i<span class="token punctuation">,</span> row <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>lab<span class="token punctuation">)</span><span class="token punctuation">:</span>
        row<span class="token punctuation">[</span>label<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
    <span class="token keyword">return</span> lab

<span class="token keyword">def</span> <span class="token function">load_mnist</span><span class="token punctuation">(</span>train_image_path<span class="token punctuation">,</span> train_label_path<span class="token punctuation">,</span> test_image_path<span class="token punctuation">,</span> test_label_path<span class="token punctuation">,</span> normalize<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> one_hot<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">'''读入MNIST数据集 Parameters ---------- normalize : 将图像的像素值正规化为0.0~1.0 one_hot_label : one_hot为True的情况下，标签作为one-hot数组返回 one-hot数组是指[0,0,1,0,0,0,0,0,0,0]这样的数组 Returns ---------- (训练图像, 训练标签), (测试图像, 测试标签) '''</span>
    image <span class="token operator">=</span> <span class="token punctuation">{</span>
        <span class="token string">'train'</span> <span class="token punctuation">:</span> __read_image<span class="token punctuation">(</span>train_image_path<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">'test'</span>  <span class="token punctuation">:</span> __read_image<span class="token punctuation">(</span>test_image_path<span class="token punctuation">)</span>
    <span class="token punctuation">}</span>

    label <span class="token operator">=</span> <span class="token punctuation">{</span>
        <span class="token string">'train'</span> <span class="token punctuation">:</span> __read_label<span class="token punctuation">(</span>train_label_path<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token string">'test'</span>  <span class="token punctuation">:</span> __read_label<span class="token punctuation">(</span>test_label_path<span class="token punctuation">)</span>
    <span class="token punctuation">}</span>
    
    <span class="token keyword">if</span> normalize<span class="token punctuation">:</span>
        <span class="token keyword">for</span> key <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            image<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> __normalize_image<span class="token punctuation">(</span>image<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">if</span> one_hot<span class="token punctuation">:</span>
        <span class="token keyword">for</span> key <span class="token keyword">in</span> <span class="token punctuation">(</span><span class="token string">'train'</span><span class="token punctuation">,</span> <span class="token string">'test'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
            label<span class="token punctuation">[</span>key<span class="token punctuation">]</span> <span class="token operator">=</span> __one_hot_label<span class="token punctuation">(</span>label<span class="token punctuation">[</span>key<span class="token punctuation">]</span><span class="token punctuation">)</span>

    <span class="token keyword">return</span> <span class="token punctuation">(</span>image<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token punctuation">[</span><span class="token string">'train'</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span>image<span class="token punctuation">[</span><span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> label<span class="token punctuation">[</span><span class="token string">'test'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre>
<blockquote>
<p>参考文献：<br /> [1] 斋藤康毅.陆宇杰.深度学习入门：基于Python的理论与实现[M].北京:人民邮电出版社,2018.</p>
</blockquote></div>
<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-526ced5128.css" rel="stylesheet">
</div>
]]></content:encoded>
										</item>
		<item>
		<title>MATLAB打开USB摄像头的操作以及常见问题</title>
		<link>https://uzzz.org/article/3140.html</link>
				<pubDate>Mon, 30 Jul 2018 07:48:39 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[机器学习]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/3140.html</guid>
				<description><![CDATA[1 前言 2 打开USB摄像头并写视频 2.1 摄像头相关操作 2.2 写视频相关操作 3 查询摄像头设备信息指令 4 常见问题 1 前言 　　如果你是视频技术处理研究领域的工程人员，那么用MATLAB&#38;OpenCV打开摄像头，以及获取相关信息，是再常规不过的操作了。 　　本文是对MATLAB打开USB摄像头操作的知识点梳理和总结。 　　 　　操作环境 MATLAB 2015b Logitech HD720P Windows 10 Enterprise 64Bit 2 打开USB摄像头并写视频 2.1 摄像头相关操作 video_source = videoinput('winvideo',1); preview(video_source); 　　这两行指令就可以打开USB摄像头，并预览显示了，当然，这里采用的都是默认参数，如果想控制视频参数，可以通过set方法。 video_source = videoinput('winvideo',1，‘RGB24_640x480’); set(video_source,'ReturnedColorSpace','rgb'); preview(video_source); 　　此时打开摄像头成功，会有一个弹窗出现显示实时的画面。 如果想在某一时刻获取视频帧，可以这样操作 frame = getsnapshot(video_source); image(frame); 　　获取的帧是从视频输入流中直接获取，可以通过时间函数来控制获取的频率，获取的帧可以存储在一个矩阵当中，作为一个视频流，方便计算。 2.2 写视频相关操作 　　打开摄像头，更多的操作是保存一段视频，这要用到一个保存操作。 video_source = videoinput('winvideo',1,'RGB24_640x480'); set(video_source,'ReturnedColorSpace','rgb'); preview(video_source); file_name = 'test.avi'; % 创建一个写文件的对象 writer = VideoWriter(file_name,'Motion JPEG AVI'); writer.FrameRate = 30.0; % 通过总帧数来控制视频长度 length = 300; % MATLAB里的视频文件其实是包含了两个部分的复合结构体， % 这两个部分，一个是色域colormap，一个是视频数据内容 file.colormap=[]; % 打开对象，开始录制 open(writer); for i=1:length frame = getsnapshot(video_source); file.cdata = frame; writeVideo(writer,file); end % 随手把该关的对象全关掉，是个好习惯 close(writer); closepreview; delete(video_source); 　　此时你会发现你的根目录文件夹里多了一个test.avi的文件。VideoWriter能做的事情还有很多，比如使用set方法更改一些视频录制参数等。 3 查询摄像头设备信息指令 　　有些时候需要用到一些硬件信息，如视频编码格式。摄像头的硬件性能决定了其视频编码范围，相比于软件编码近乎万能的超凡能力（FFMPEG），硬件设备的硬编码能力十分有限，所以我们需要知道我们用的摄像头都有哪些信息和功能。 win_info = imaqhwinfo('winvideo'); 　　此时会打开一个结构体，这个结构体几乎包含了我们所需要的一切了，简单一点，可以直接从工作站里面点击打开其中内容，其中最常用的是DeviceInfo字段，里面包含其所支持的所有编码格式： 　　相对应的，其编码格式的完整查询指令： win_info = imaqhwinfo('winvideo'); win_info.DeviceInfo.SupportedFormats； 　　可能更直观一点—— 　　顺便吐槽一下，不知道为什么，网上的技术贴总是把视频编码的查询写得那么复杂，明明2行就能解决问题的事情，非要写七八行…… 4 常见问题 videoinput函数报错问题 　　如果你是第一次使用MATLAB操作摄像头，有时候可能需要你安装一个插件来支持你的硬件设备，比如这种情况—— 　　点击Support Package Installer，安装一个插件就行了，不需要重启MATLAB 　　如果你打不开这个界面，那么可能你的MATLAB没有破解完整，最糟糕的情况，可能需要重装MATLAB。 帧率问题 　　**软件手段只能在硬件范围内起控制作用。**尽管我们有一个设置帧率的set函数，但麻烦的是，硬件有时候并不受软件控制，比如你设置帧率为100fps，但是一般USB摄像头只能支持到30fps了，100+都是高速摄像机的水平（好几万的那种），所以只能到30fps。更常见的情况是，当时用笔记本电脑，笔记笨使用内置电池，电量低的时候，摄像头受操作系统电量管理的影响，此时帧率会变得可能只有10fps左右（就是画面看起来糊糊的那种）。所以帧率有时候真的很难控制，因情况而异，如果你需要帧率作为计算参数，可以考虑通过统计时间，通过总帧数反推实际帧率，得到真实值。 编码格式的问题 　　图像色域、视频编码格式、文件格式，这是三个概念，这里不再详细展开，但一般而言，几乎所有的设备都是支持RGB色域和RGB编码格式的，文件格式默认avi即可。如果对其他格式有想法，硬件又不支持，可以考虑使用视频转码（推荐使用FFMPEG）。 #5 总结 　　这些操作其实没有技术含量，如果需要更深入的探索，可以钻研MATLAB DOC。这里写个帖子，以记录自己过去所学的知识点。]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div id="content_views" class="markdown_views prism-atelier-sulphurpool-light">
  <!-- flowchart 箭头图标 勿删 --><br />
  <svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
   <path stroke-linecap="round" d="M5,0 0,2.5 5,5z" id="raphael-marker-block" style="-webkit-tap-highlight-color: rgba(0, 0, 0, 0);"></path>
  </svg> </p>
<hr>
<div class="toc">
<h3> </h3>
<ul>
<li><a href="#1__4" rel="nofollow" data-token="cd2689696e1426fbc4ad0d90d2145872">1 前言</a></li>
<li><a href="#2_USB_14" rel="nofollow" data-token="d9e4b50b503e17ea1270b3a06204338b">2 打开USB摄像头并写视频</a></li>
<ul>
<li><a href="#21__15" rel="nofollow" data-token="ab3c8328a16b0f78e5d4a0f44ceda2a8">2.1 摄像头相关操作</a></li>
<li><a href="#22__37" rel="nofollow" data-token="d13a7b54aa97a53d09aa942c1a9af95e">2.2 写视频相关操作</a></li>
</ul>
<li><a href="#3__69" rel="nofollow" data-token="5c045ec65a5b3ba8f2572dae65a616f3">3 查询摄像头设备信息指令</a></li>
<li><a href="#4__85" rel="nofollow" data-token="1c847f36caf1c9309058819a20a3d2ed">4 常见问题</a></li>
</ul></div>
</p>
<hr>
<h1><a id="1__4"></a>1 前言</h1>
<p><font face="楷体" size="4">　　如果你是视频技术处理研究领域的工程人员，那么用MATLAB&amp;OpenCV打开摄像头，以及获取相关信息，是再常规不过的操作了。<br /> 　　本文是对MATLAB打开USB摄像头操作的知识点梳理和总结。</font><br /> 　　<br /> 　　<font size="5" color="red"><strong>操作环境</strong></font></p>
<ul>
<li><strong>MATLAB 2015b</strong></li>
<li><strong>Logitech HD720P</strong></li>
<li><strong>Windows 10 Enterprise 64Bit</strong></li>
</ul>
<h1><a id="2_USB_14"></a>2 打开USB摄像头并写视频</h1>
<h2><a id="21__15"></a>2.1 摄像头相关操作</h2>
<pre><code class="prism language-cpp">video_source <span class="token operator">=</span> <span class="token function">videoinput</span><span class="token punctuation">(</span><span class="token string">'winvideo'</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">preview</span><span class="token punctuation">(</span>video_source<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p><font face="楷体" size="4">　　这两行指令就可以打开USB摄像头，并预览显示了，当然，这里采用的都是默认参数，如果想控制视频参数，可以通过set方法。</font></p>
<pre><code class="prism language-cpp">video_source <span class="token operator">=</span> <span class="token function">videoinput</span><span class="token punctuation">(</span><span class="token string">'winvideo'</span><span class="token punctuation">,</span><span class="token number">1</span>，‘RGB24_640x480’<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">set</span><span class="token punctuation">(</span>video_source<span class="token punctuation">,</span><span class="token string">'ReturnedColorSpace'</span><span class="token punctuation">,</span><span class="token string">'rgb'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">preview</span><span class="token punctuation">(</span>video_source<span class="token punctuation">)</span><span class="token punctuation">;</span>

</code></pre>
<p><font face="楷体" size="4">　　此时打开摄像头成功，会有一个弹窗出现显示实时的画面。<br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180730150620647" alt="这里写图片描述"></font></p>
<p>如果想在某一时刻获取视频帧，可以这样操作</p>
<pre><code class="prism language-cpp">frame <span class="token operator">=</span> <span class="token function">getsnapshot</span><span class="token punctuation">(</span>video_source<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">image</span><span class="token punctuation">(</span>frame<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p><font face="楷体" size="4">　　获取的帧是从视频输入流中直接获取，可以通过时间函数来控制获取的频率，获取的帧可以存储在一个矩阵当中，作为一个视频流，方便计算。</font></p>
<h2><a id="22__37"></a>2.2 写视频相关操作</h2>
<p><font face="楷体" size="4">　　打开摄像头，更多的操作是保存一段视频，这要用到一个保存操作。</font></p>
<pre><code class="prism language-cpp">
video_source <span class="token operator">=</span> <span class="token function">videoinput</span><span class="token punctuation">(</span><span class="token string">'winvideo'</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token string">'RGB24_640x480'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token function">set</span><span class="token punctuation">(</span>video_source<span class="token punctuation">,</span><span class="token string">'ReturnedColorSpace'</span><span class="token punctuation">,</span><span class="token string">'rgb'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token function">preview</span><span class="token punctuation">(</span>video_source<span class="token punctuation">)</span><span class="token punctuation">;</span>

file_name <span class="token operator">=</span> <span class="token string">'test.avi'</span><span class="token punctuation">;</span>
<span class="token operator">%</span> 创建一个写文件的对象
writer <span class="token operator">=</span> <span class="token function">VideoWriter</span><span class="token punctuation">(</span>file_name<span class="token punctuation">,</span><span class="token string">'Motion JPEG AVI'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
writer<span class="token punctuation">.</span>FrameRate <span class="token operator">=</span> <span class="token number">30.0</span><span class="token punctuation">;</span>
<span class="token operator">%</span> 通过总帧数来控制视频长度
length <span class="token operator">=</span> <span class="token number">300</span><span class="token punctuation">;</span>
<span class="token operator">%</span> MATLAB里的视频文件其实是包含了两个部分的复合结构体，
<span class="token operator">%</span> 这两个部分，一个是色域colormap，一个是视频数据内容
file<span class="token punctuation">.</span>colormap<span class="token operator">=</span><span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">;</span>
<span class="token operator">%</span> 打开对象，开始录制
<span class="token function">open</span><span class="token punctuation">(</span>writer<span class="token punctuation">)</span><span class="token punctuation">;</span>

<span class="token keyword">for</span> i<span class="token operator">=</span><span class="token number">1</span><span class="token operator">:</span>length
    frame <span class="token operator">=</span> <span class="token function">getsnapshot</span><span class="token punctuation">(</span>video_source<span class="token punctuation">)</span><span class="token punctuation">;</span>
    file<span class="token punctuation">.</span>cdata <span class="token operator">=</span> frame<span class="token punctuation">;</span>
    <span class="token function">writeVideo</span><span class="token punctuation">(</span>writer<span class="token punctuation">,</span>file<span class="token punctuation">)</span><span class="token punctuation">;</span>
end
<span class="token operator">%</span> 随手把该关的对象全关掉，是个好习惯
<span class="token function">close</span><span class="token punctuation">(</span>writer<span class="token punctuation">)</span><span class="token punctuation">;</span>
closepreview<span class="token punctuation">;</span>
<span class="token keyword">delete</span><span class="token punctuation">(</span>video_source<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p><font face="楷体" size="4">　　此时你会发现你的根目录文件夹里多了一个<code>test.avi</code>的文件。VideoWriter能做的事情还有很多，比如使用set方法更改一些视频录制参数等。</font></p>
<h1><a id="3__69"></a>3 查询摄像头设备信息指令</h1>
<p><font face="楷体" size="4">　　有些时候需要用到一些硬件信息，如视频编码格式。摄像头的硬件性能决定了其视频编码范围，相比于软件编码近乎万能的超凡能力（FFMPEG），硬件设备的硬编码能力十分有限，所以我们需要知道我们用的摄像头都有哪些信息和功能。</font></p>
<pre><code class="prism language-cpp">win_info <span class="token operator">=</span> <span class="token function">imaqhwinfo</span><span class="token punctuation">(</span><span class="token string">'winvideo'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre>
<p><font face="楷体" size="4">　　此时会打开一个结构体，这个结构体几乎包含了我们所需要的一切了，简单一点，可以直接从工作站里面点击打开其中内容，其中最常用的是<code>DeviceInfo</code>字段，里面包含其所支持的所有编码格式：<br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180730153240980" alt="这里写图片描述"><br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180730153254678" alt="这里写图片描述"><br /> <font face="楷体" size="4">　　相对应的，其编码格式的完整查询指令：</font></font></p>
<pre><code class="prism language-cpp">win_info <span class="token operator">=</span> <span class="token function">imaqhwinfo</span><span class="token punctuation">(</span><span class="token string">'winvideo'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
win_info<span class="token punctuation">.</span>DeviceInfo<span class="token punctuation">.</span>SupportedFormats；
</code></pre>
<p><font face="楷体" size="4">　　可能更直观一点——<br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180730153551556" alt="这里写图片描述"><br /> <font face="楷体" size="4">　　顺便吐槽一下，不知道为什么，网上的技术贴总是把视频编码的查询写得那么复杂，明明2行就能解决问题的事情，非要写七八行……</font></font></p>
<h1><a id="4__85"></a>4 常见问题</h1>
<p><font size="4" color="#009990"><strong>videoinput函数报错问题</strong></font><br /> <font face="楷体" size="4">　　如果你是第一次使用MATLAB操作摄像头，有时候可能需要你安装一个插件来支持你的硬件设备，比如这种情况——<br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180730153704976" alt="这里写图片描述"><br /> <font face="楷体" size="4">　　点击Support Package Installer，安装一个插件就行了，不需要重启MATLAB<br /> <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180730153746742" alt="这里写图片描述"><br /> <font face="楷体" size="4">　　如果你打不开这个界面，那么可能你的MATLAB没有破解完整，最糟糕的情况，可能需要重装MATLAB。</font></font></font></p>
<p><font size="4" color="#00FFFF"><strong>帧率问题</strong></font><br /> <font face="楷体" size="4">　　**软件手段只能在硬件范围内起控制作用。**尽管我们有一个设置帧率的set函数，但麻烦的是，硬件有时候并不受软件控制，比如你设置帧率为100fps，但是一般USB摄像头只能支持到30fps了，100+都是高速摄像机的水平（好几万的那种），所以只能到30fps。更常见的情况是，当时用笔记本电脑，笔记笨使用内置电池，电量低的时候，摄像头受操作系统电量管理的影响，此时帧率会变得可能只有10fps左右（就是画面看起来糊糊的那种）。所以帧率有时候真的很难控制，因情况而异，如果你需要帧率作为计算参数，可以考虑通过统计时间，通过总帧数反推实际帧率，得到真实值。</font></p>
<p><font size="4" color="#00FFFF"><strong>编码格式的问题</strong></font><br /> <font face="楷体" size="4">　　图像色域、视频编码格式、文件格式，这是三个概念，这里不再详细展开，但一般而言，几乎所有的设备都是支持RGB色域和RGB编码格式的，文件格式默认avi即可。如果对其他格式有想法，硬件又不支持，可以考虑使用视频转码（推荐使用FFMPEG）。<br /> #5 总结<br /> <font face="楷体" size="4">　　这些操作其实没有技术含量，如果需要更深入的探索，可以钻研MATLAB DOC。这里写个帖子，以记录自己过去所学的知识点。</font></font></p>
</p></div>
<link href="https://csdnimg.cn/release/phoenix/mdeditor/markdown_views-526ced5128.css" rel="stylesheet">
</div>
]]></content:encoded>
										</item>
		<item>
		<title>2017CS231n李飞飞深度视觉识别笔记（一）——计算机视觉概述和历史背景</title>
		<link>https://uzzz.org/article/2672.html</link>
				<pubDate>Mon, 09 Jul 2018 12:26:35 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[机器学习]]></category>
		<category><![CDATA[计算机]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/2672.html</guid>
				<description><![CDATA[第一章&#160;计算机视觉概述和历史背景 课时1 计算机视觉概述 &#160;&#160;&#160;&#160;计算机视觉：针对视觉数据的研究。 &#160;&#160;&#160;&#160;关键是如何用算法来开发可以利用和理解的数据，视觉数据存在的问题是它们很难理解，有时把视觉数据称为“互联网的暗物质”，它们构成了网络上传输的大部分数据。 &#160;&#160;&#160;&#160;根据YouTube的一个统计实例：大概每秒钟，有长达5小时的数据内容会被上传到YouTube，所以通过人工给每个视频标上注释、分类是非常困难甚至不可能的，计算机视觉是解决这种问题的重要技术，它能够对照片进行标签、分类，处理视频的每一帧。 &#160;&#160;&#160;&#160;计算机视觉是一个与很多领域紧密关联的学科，它涉及到比如说工程、物理、生物等许多不同的领域： &#160;&#160;&#160;&#160;对于CS231n这么课程，它专注于一类特定的算法，围绕神经网络，特别是卷积神经网络，并将其应用于各种视觉识别任务。 &#160; 课时2 计算机视觉历史背景 &#160;&#160;&#160;&#160;视觉的历史可以追溯到很久以前，动物拥有视觉的开端： &#160;&#160;&#160;&#160;如今，视觉成为了最重要的感知系统，人类的大脑皮层中有几乎一半的神经元与视觉有关，这项最重要的感知系统可以使人们生存、工作、运动等等，视觉对人们真的至关重要。 &#160;&#160;&#160;&#160;以上谈到了人类的视觉，那么人类让计算机获得视觉的历史又是怎么样的呢？ &#160;&#160;&#160;&#160;现在知道的最早的相机追溯到17世纪文艺复兴时期的暗箱，这是一种通过小孔成像的相机，这和动物早期的眼睛非常相似，通过小孔接收光线，后面的平板手机信息并且投影成像。 &#160;&#160;&#160;&#160;同时，生物学家开始研究视觉的机理，最具影响力并且启发了计算机视觉的一项研究是在五六十年代，休伯尔和威泽尔使用电生理学的研究，他们提出了“哺乳动物的视觉处理机制是怎样的”，通过观察何种刺激会引起视觉皮层神经的激烈反应，他们发现猫的大脑的初级视觉皮层有各种各样的细胞，其中最重要的是当它们朝着某个特定方向运动时，对面向边缘产生回应的细胞。 &#160;&#160;&#160;&#160;他们发现视觉处理是始于视觉世界的简单结构，面向边缘，沿着视觉处理的途径的移动信息也在变化，大脑建立了复杂的视觉信息，直到它可以识别更为复杂的视觉世界。 &#160;&#160;&#160;&#160;计算机视觉的历史是从60年代开始，从Larry Roberts的计算机视觉的第一篇博士论文开始。 &#160;&#160;&#160;&#160;1966年，一个如今非常著名的MIT暑期项目“Summer Vision Project”，它试图有效的使用暑期工作时间来构建视觉系统的重要组成部分，五十年来，计算机视觉领域已经从哪个夏季项目发展成为全球数千名研究人员的领域，并且仍然处理一些最根本的问题，这个领域已经成长为人工智能领域最重要和发展最快的领域之一。 &#160;&#160;&#160;&#160;70年代后期David Marr撰写的一本非常有影响力的书，内容包括了他是如何理解计算机视觉和应该如何开发可以使计算机识别世界的算法，他指出了为了拍摄一幅图像并获得视觉世界的最终全面3D表现必须经历的几个过程，如下图所示： &#160;&#160;&#160;&#160;这是一个非常理想化的思想过程，也是一个非常直观化的方式并考虑如何解构视觉信息。 &#160;&#160;&#160;&#160;70年代另一个重要的开创性问题：如何越过简单的块状世界并开始识别或表示现实世界的对象？ &#160;&#160;&#160;&#160;一个被称为“广义圆柱体”，一个被称为“图形结构”，他们的基本思想是每个对象都是由简单的几何图形单位组成，所以任何一种表示方法是将物体的复杂结构简约成一个集合体。 &#160;&#160;&#160;&#160;80年代David lowe思考的如何重建或识别由简单的物体结构组成的视觉空间，它尝试识别剃须刀，通过线和边缘进行构建，其中大部分是直线之间的组合。 &#160;&#160;&#160;&#160;从60年代到80年代，考虑的问题是计算机视觉的任务是什么，要解决物体识别的问题非常难。所以，当思考解决视觉问题过程中出现的问题时，另一个重要的问题产生：如果识别目标太难，首先要做的是目标分割。 &#160;&#160;&#160;&#160;这个任务就是把一张图片中的像素点归类到有意义的区域，可能不知道这些像素点组合到一起是一个人形，但可以把属于人的像素点从背景中抠出来，这个过程就叫作图像分割。 &#160;&#160;&#160;&#160;下面是Malik和Jianbo shi完成的用一个算法对图像进行分割： &#160;&#160;&#160;&#160;还有一个重要的研究是由Paul Viola和Michael Jones完成的，使用AdaBoost算法进行实时面部检测，在这个研究后不久推出了第一个能在数码相机中实现实时面部检测的数码相机，所以这是从基础科学研究到实际应用的一个快速转化。 &#160;&#160;&#160;&#160;关于如何做到更好的目标识别，是可以继续研究的领域，，所以在90年代末和21世纪的前几年，一个重要的思想方法就是基于特征的目标识别。由David Lowe完成的叫做SIFT特征，思路是匹配整个目标。 &#160;&#160;&#160;&#160;通过观察目标的某些部分、某些特征，它们往往能够在变化中具有表现性和不变性，所以目标识别的首要任务是在目标上确认这些关键的特征，然后把这些特征与相似的目标进行匹配，它比匹配整个目标要容易的多。例如，上图中一个stop标识中的SIFT特征与另一个stop标识中的SIFT特征相匹配。 &#160;&#160;&#160;&#160;有些工作是把这些特征放在一起以后，研究如何在实际图片中比较合理地设计人体姿态和辨认人体姿态，这方面一个工作被称为“方向梯度直方图”，另一个被称为“可变部件模型”。 &#160;&#160;&#160;&#160;所以，从60年代、70年代、80年代一直到21世纪，图片的质量随着互联网的发展，计算机视觉领域也能拥有更好的数据了，直到21世纪早期，才开始真正拥有标注的数据集能够衡量在目标识别方面取得的成果，其实一个最著名的数据集叫做PASCAL Visual Challenge。 &#160;&#160;&#160;&#160;与此同时，提出了一个重要的问题：是否具备了识别真是世界中的每一个物体的能力或者说大部分物体。这个问题也是由机器学习中的一个现象驱动：大部分的机器学习算法，无论是图模型还是SVM、AdaBoost都可能会在训练过程中过拟合。因此，有这两方面的动力，一是单纯想识别自然界中的万物，二是要回归机器学习克服瓶颈—过拟合问题，开始开展了一个ImageNet的项目，汇集所有能找到的图片，组建一个尽可能大的数据集。 &#160;&#160;&#160;&#160;这是当时AI领域最大的数据集，将目标检测算法的发展推到了一个新的高度，尤其重要的是如何推动基准测试的进展。 &#160;&#160;&#160;&#160;下面是ImageNet挑战赛的从2010到2015的图像分类结果： &#160;&#160;&#160;&#160;横轴表示年份，纵轴表示比赛结果的错误率，可以看到错误率正在稳步下降。可以看到图中2012的错误率下降的非常显著，这一年的算法是一种卷积神经网络模型，这也将是这门课程学习的重点，深入研究什么是卷积神经网络模型，也就是现在被熟知的深度学习。 &#160; 课时3 CS321n课程概述 &#160;&#160;&#160;&#160;CS321n将聚焦于视觉识别问题，第一个主要问题就是图像分类问题：让算法接收一张图作为输入，从固定的类别集合中选出该图像所属的类别。这个基本的分类器在很多地方都有不同的应用。 &#160;&#160;&#160;&#160;在CS231n课程中，将讨论一些其他的视觉识别问题，它们都建立在专门为图像分类而开发的各种工具之上，一些和图像分类的问题，比如目标检测或图像摘要生成。 &#160;&#160;&#160;&#160;图像分类关注的是大图整体，目标检测则告诉你物体具体出现在图片的哪个位置以及物体之间的联系是什么，图像摘要是当给到一幅图像，需要生成一段句子来描述这幅图像。 &#160;&#160; CNN，卷积神经网络只是深度学习架构的一种，但是它的成功是压倒性的，成为了目标识别的重要工具。回到ImageNet挑战赛中，2012年Krizhevsky和他的导师提出了卷积神经网络，并夺得了冠军；而在这之前，一直都是特征+支持向量机的结构，一种分层结构；而在这之后，获得冠军的算法都是卷积神经网络。 &#160;&#160;&#160;&#160;然而，卷积神经网络并不是一夜之间就成功的，事实上，这些算法可以追溯到更早的时候，与卷积神经网络有关的其中一项基础性工作是由Yann LeCun和他的伙伴于90年代完成的，1998年他们利用卷积神经网络进行数字识别。 &#160;&#160;&#160;&#160;所有既然这些算法在90年代就很突出，为什么到最近几年才变得这么流行呢？从数学的角度来说，有很重要的两点引起了深度学习架构的复兴，一个是摩尔定律，计算能力在变得越来越高；另一个是数据，算法需要大量的数据，需要给它们提供非常多的带标签的图像和像素，以便能最终取得更好的效果，有了大数据集，可以实现更强大的模型。 &#160;&#160;&#160;&#160;在计算机视觉领域，正尝试着制造一个拥有和人类一样视觉能力的机器，这样可以利用这些视觉系统可以实现很多惊奇的事情，但是当继续在该领域深入的时候，仍然有着大量的挑战和问题亟待解决，比如对整个照片进行密集标记、感知分组、使能够确定每个像素点的归属，这些仍是研究中的问题，所以需要持续不断地改进算法，从而做到更好。 &#160;&#160;&#160;&#160;与简单的“在物体上贴标签”比起来，我们往往希望深入地理解图片中的人们在做什么、各个物体之间的关系是什么，于是我们开始探究物体之间的联系，这是一个被称为视觉基因组的项目。 &#160;&#160;&#160;&#160;计算机视觉领域的一个愿景即是“看图说故事”，人类的生物视觉系统是非常强大的，看到一张图片，就能够描述图片的内容，并且只需不到一秒种的时间，如果能够让计算机也能做的同样的事情，那毋庸置疑是一项重大的突破；如果要实现真实深刻的图像理解，如今的计算机视觉算法仍然有很长的路要走。 &#160;&#160;&#160;&#160;计算机视觉能让世界变得更加美好，它还可以被应用到类似医学诊断、自动驾驶、机器人或者和这些完全版不同的领域。 &#160;]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div class="htmledit_views" id="content_views">
<p><strong><span style="color:#000000;"><span style="font-size:18px;">第一章&nbsp;计算机视觉概述和历史背景</span></span></strong></p>
<p><strong><span style="color:#000000;">课时1 计算机视觉概述</span></strong></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;计算机视觉：针对视觉数据的研究。</span></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;关键是如何用算法来开发可以利用和理解的数据，视觉数据存在的问题是它们很难理解，有时把视觉数据称为“互联网的暗物质”，它们构成了网络上传输的大部分数据。</span></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;根据YouTube的一个统计实例：大概每秒钟，有长达5小时的数据内容会被上传到YouTube，所以通过人工给每个视频标上注释、分类是非常困难甚至不可能的，计算机视觉是解决这种问题的重要技术，它能够对照片进行标签、分类，处理视频的每一帧。</span></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;计算机视觉是一个与很多领域紧密关联的学科，它涉及到比如说工程、物理、生物等许多不同的领域：</span></p>
<p align="center"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201827973?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;对于CS231n这么课程，它专注于一类特定的算法，围绕神经网络，特别是卷积神经网络，并将其应用于各种视觉识别任务。</span></p>
<p><strong><span style="color:#000000;">&nbsp;</span></strong></p>
<p><strong><span style="color:#000000;">课时2 计算机视觉历史背景</span></strong></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;视觉的历史可以追溯到很久以前，动物拥有视觉的开端：</span></p>
<p align="center"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201848797?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;如今，视觉成为了最重要的感知系统，人类的大脑皮层中有几乎一半的神经元与视觉有关，这项最重要的感知系统可以使人们生存、工作、运动等等，视觉对人们真的至关重要。</span></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;以上谈到了人类的视觉，那么人类让计算机获得视觉的历史又是怎么样的呢？</span></p>
<p align="center"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201854715?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;现在知道的最早的相机追溯到17世纪文艺复兴时期的暗箱，这是一种通过小孔成像的相机，这和动物早期的眼睛非常相似，通过小孔接收光线，后面的平板手机信息并且投影成像。</span></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;同时，生物学家开始研究视觉的机理，最具影响力并且启发了计算机视觉的一项研究是在五六十年代，休伯尔和威泽尔使用电生理学的研究，他们提出了“哺乳动物的视觉处理机制是怎样的”，通过观察何种刺激会引起视觉皮层神经的激烈反应，他们发现猫的大脑的初级视觉皮层有各种各样的细胞，其中最重要的是当它们朝着某个特定方向运动时，对面向边缘产生回应的细胞。</span></p>
<p align="center"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201902678?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;他们发现视觉处理是始于视觉世界的简单结构，面向边缘，沿着视觉处理的途径的移动信息也在变化，大脑建立了复杂的视觉信息，直到它可以识别更为复杂的视觉世界。</span></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;计算机视觉的历史是从60年代开始，从Larry Roberts的计算机视觉的第一篇博士论文开始。</span></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;1966年，一个如今非常著名的MIT暑期项目“Summer Vision Project”，它试图有效的使用暑期工作时间来构建视觉系统的重要组成部分，五十年来，计算机视觉领域已经从哪个夏季项目发展成为全球数千名研究人员的领域，并且仍然处理一些最根本的问题，这个领域已经成长为人工智能领域最重要和发展最快的领域之一。</span></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;70年代后期David Marr撰写的一本非常有影响力的书，内容包括了他是如何理解计算机视觉和应该如何开发可以使计算机识别世界的算法，他指出了为了拍摄一幅图像并获得视觉世界的最终全面3D表现必须经历的几个过程，如下图所示：</span></p>
<p align="center"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201912570?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;这是一个非常理想化的思想过程，也是一个非常直观化的方式并考虑如何解构视觉信息。</span></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;70年代另一个重要的开创性问题：如何越过简单的块状世界并开始识别或表示现实世界的对象？</span></p>
<p align="center"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201921962?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;一个被称为“广义圆柱体”，一个被称为“图形结构”，他们的基本思想是每个对象都是由简单的几何图形单位组成，所以任何一种表示方法是将物体的复杂结构简约成一个集合体。</span></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;80年代David lowe思考的如何重建或识别由简单的物体结构组成的视觉空间，它尝试识别剃须刀，通过线和边缘进行构建，其中大部分是直线之间的组合。</span></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;从60年代到80年代，考虑的问题是计算机视觉的任务是什么，要解决物体识别的问题非常难。所以，当思考解决视觉问题过程中出现的问题时，另一个重要的问题产生：如果识别目标太难，首先要做的是目标分割。</span></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;这个任务就是把一张图片中的像素点归类到有意义的区域，可能不知道这些像素点组合到一起是一个人形，但可以把属于人的像素点从背景中抠出来，这个过程就叫作图像分割。</span></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;下面是Malik和Jianbo shi完成的用一个算法对图像进行分割：</span></p>
<p align="center"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201932661?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;还有一个重要的研究是由Paul Viola和Michael Jones完成的，使用AdaBoost算法进行实时面部检测，在这个研究后不久推出了第一个能在数码相机中实现实时面部检测的数码相机，所以这是从基础科学研究到实际应用的一个快速转化。</span></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;关于如何做到更好的目标识别，是可以继续研究的领域，，所以在90年代末和21世纪的前几年，一个重要的思想方法就是基于特征的目标识别。由David Lowe完成的叫做SIFT特征，思路是匹配整个目标。</span></p>
<p align="center"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201941468?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;通过观察目标的某些部分、某些特征，它们往往能够在变化中具有表现性和不变性，所以目标识别的首要任务是在目标上确认这些关键的特征，然后把这些特征与相似的目标进行匹配，它比匹配整个目标要容易的多。例如，上图中一个stop标识中的SIFT特征与另一个stop标识中的SIFT特征相匹配。</span></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;有些工作是把这些特征放在一起以后，研究如何在实际图片中比较合理地设计人体姿态和辨认人体姿态，这方面一个工作被称为“方向梯度直方图”，另一个被称为“可变部件模型”。</span></p>
<p align="center"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201949391?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;所以，从60年代、70年代、80年代一直到21世纪，图片的质量随着互联网的发展，计算机视觉领域也能拥有更好的数据了，直到21世纪早期，才开始真正拥有标注的数据集能够衡量在目标识别方面取得的成果，其实一个最著名的数据集叫做PASCAL Visual Challenge。</span></p>
<p align="center"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709201955857?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;与此同时，提出了一个重要的问题：是否具备了识别真是世界中的每一个物体的能力或者说大部分物体。这个问题也是由机器学习中的一个现象驱动：大部分的机器学习算法，无论是图模型还是SVM、AdaBoost都可能会在训练过程中过拟合。因此，有这两方面的动力，一是单纯想识别自然界中的万物，二是要回归机器学习克服瓶颈—过拟合问题，开始开展了一个ImageNet的项目，汇集所有能找到的图片，组建一个尽可能大的数据集。</span></p>
<p align="center"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709202003416?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;这是当时AI领域最大的数据集，将目标检测算法的发展推到了一个新的高度，尤其重要的是如何推动基准测试的进展。</span></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;下面是ImageNet挑战赛的从2010到2015的图像分类结果：</span></p>
<p align="center"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709202009561?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;横轴表示年份，纵轴表示比赛结果的错误率，可以看到错误率正在稳步下降。可以看到图中2012的错误率下降的非常显著，这一年的算法是一种卷积神经网络模型，这也将是这门课程学习的重点，深入研究什么是卷积神经网络模型，也就是现在被熟知的深度学习。</span></p>
<p><span style="color:#000000;">&nbsp;</span></p>
<p><strong><span style="color:#000000;">课时3 CS321n课程概述</span></strong></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;CS321n将聚焦于视觉识别问题，第一个主要问题就是图像分类问题：让算法接收一张图作为输入，从固定的类别集合中选出该图像所属的类别。这个基本的分类器在很多地方都有不同的应用。</span></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;在CS231n课程中，将讨论一些其他的视觉识别问题，它们都建立在专门为图像分类而开发的各种工具之上，一些和图像分类的问题，比如目标检测或图像摘要生成。</span></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;图像分类关注的是大图整体，目标检测则告诉你物体具体出现在图片的哪个位置以及物体之间的联系是什么，图像摘要是当给到一幅图像，需要生成一段句子来描述这幅图像。</span></p>
<p align="center"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709202023289?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>
<p><span style="color:#000000;">&nbsp;&nbsp; CNN，卷积神经网络只是深度学习架构的一种，但是它的成功是压倒性的，成为了目标识别的重要工具。回到ImageNet挑战赛中，2012年Krizhevsky和他的导师提出了卷积神经网络，并夺得了冠军；而在这之前，一直都是特征+支持向量机的结构，一种分层结构；而在这之后，获得冠军的算法都是卷积神经网络。</span></p>
<p align="center"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709202104412?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;然而，卷积神经网络并不是一夜之间就成功的，事实上，这些算法可以追溯到更早的时候，与卷积神经网络有关的其中一项基础性工作是由Yann LeCun和他的伙伴于90年代完成的，1998年他们利用卷积神经网络进行数字识别。</span></p>
<p align="center"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709202111782?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;所有既然这些算法在90年代就很突出，为什么到最近几年才变得这么流行呢？从数学的角度来说，有很重要的两点引起了深度学习架构的复兴，一个是摩尔定律，计算能力在变得越来越高；另一个是数据，算法需要大量的数据，需要给它们提供非常多的带标签的图像和像素，以便能最终取得更好的效果，有了大数据集，可以实现更强大的模型。</span></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;在计算机视觉领域，正尝试着制造一个拥有和人类一样视觉能力的机器，这样可以利用这些视觉系统可以实现很多惊奇的事情，但是当继续在该领域深入的时候，仍然有着大量的挑战和问题亟待解决，比如对整个照片进行密集标记、感知分组、使能够确定每个像素点的归属，这些仍是研究中的问题，所以需要持续不断地改进算法，从而做到更好。</span></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;与简单的“在物体上贴标签”比起来，我们往往希望深入地理解图片中的人们在做什么、各个物体之间的关系是什么，于是我们开始探究物体之间的联系，这是一个被称为视觉基因组的项目。</span></p>
<p align="center"><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180709202122653?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM0NjExNTc5/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;计算机视觉领域的一个愿景即是“看图说故事”，人类的生物视觉系统是非常强大的，看到一张图片，就能够描述图片的内容，并且只需不到一秒种的时间，如果能够让计算机也能做的同样的事情，那毋庸置疑是一项重大的突破；如果要实现真实深刻的图像理解，如今的计算机视觉算法仍然有很长的路要走。</span></p>
<p><span style="color:#000000;">&nbsp;&nbsp;&nbsp;&nbsp;计算机视觉能让世界变得更加美好，它还可以被应用到类似医学诊断、自动驾驶、机器人或者和这些完全版不同的领域。</span></p>
<p><span style="color:#000000;">&nbsp;</span></p>
</p></div>
</div>
]]></content:encoded>
										</item>
		<item>
		<title>DL学习笔记-图像预处理</title>
		<link>https://uzzz.org/article/3037.html</link>
				<pubDate>Mon, 11 Jun 2018 08:43:58 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[机器学习]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/3037.html</guid>
				<description><![CDATA[一、为什么使用图像预处理 1、图像的亮度、对比度等属性对图像的影响是非常大的，相同物体在不同的亮度，对比度下差别非常大。在图像识别的问题中，我们经常会遇到阴影、强曝光之类的图片，这些因素都不应该影响最后的识别结果，所以我们要对图像进行预处理，使得得到的神经网络模型尽可能小的被无关因素所影响。 2、在我们遇到图像样本过少，或者不均衡时，也可以使用图像预处理，增加样本数量。 3、有时物体拍摄的角度不同，也会有很大的差异，所以刻意将图像进行随机的翻转，可以提高模型健壮性。 二、图像处理函数 1、读取图像的原始数据。 图像在存储是并不是直接记录这些矩阵中的数字，而是记录经过压缩编码之后的结果，所以要将一个图片还原成三维矩阵，需要一个解码的过程。 image_raw_data = tf.gfile.FastGFile('images/image_0043.jpg', 'rb').read() img_data = tf.image.decode_jpeg(image_raw_data) 2、图像大小调整 图像大小调整有两种方法， 第一种是通过算法使得新的图像尽量保存原始图像上的所有信息。 第二种是对图像进行裁剪或者填充，只获得感兴趣区域。 TensorFlow提供了四种缩放图像的算法，注意要加入截断函数，防止数值越界。 #重新调整图片大小 def resize(image_data): with tf.Session() as sess: image_data = tf.image.convert_image_dtype(image_data, dtype=tf.float32) methods=['Bilinear Interpolation', 'Nearest neighbor interpolation', 'Bicubic interpolation', 'Area interpolation'] plt.subplot(231), plt.imshow(image_data.eval()), plt.title('original') step = 231 for i in range(4): step += 1 resized = tf.image.resize_images(image_data, [300, 300], method=i) resized = tf.clip_by_value(resized, 0.0, 1.0) plt.subplot(step),plt.imshow(resized.eval()), plt.title(methods[i]) plt.show() 显示图像如下： 剪裁和填充图片，通过tf.image.resize_image_with_crop_or_pad函数实现，第一参数是输入图像，后面是裁剪以后的大小。如果小于输入图像，那么就裁剪输入图像居中部分的大小；如果大于输入图像，就填充输入图像四周。 #裁剪和填充图片 def crop_and_pad(image_data): with tf.Session() as sess: #resize_image_with_crop_or_pad 如果输入图像尺寸大于输出图像，截取原始图像中居中的部分 #如果输入小于输出，会在原始图像四周填充全0背景 croped_1 = tf.image.resize_image_with_crop_or_pad(image_data, 300, 300) croped_2 = tf.image.resize_image_with_crop_or_pad(image_data, 1000, 1000) padded = tf.image.resize_image_with_crop_or_pad(image_data, 3000, 3000) show(croped_1) show(croped_2) show(padded) 也提供了按比例调整图像大小的函数，tf.image.ecntral_crop， #截取中间50%的图片 def central_crop(image_data): with tf.Session() as sess: central_croped = tf.image.central_crop(image_data, 0.5) plt.imshow(central_croped.eval()) plt.show() 还有固定尺寸的裁剪，第二三个参数是起始点的坐标，第四五个参数是宽高 #固定边框提取 def bounding_box(image_raw_data): with tf.Session() as sess: image_data = tf.image.decode_jpeg(image_raw_data) # crop_to_bounding_box(image, offset_height, offset_width, target_height,arget_width) #第二个第三个参数是起始点的坐标， 四五是宽高 box_croped = tf.image.crop_to_bounding_box(image_data, 100, 100, 300, 300) # 二三是原始图像在目标图像上所在的起始坐标，四五是目标图像的大小 box_padded = tf.image.pad_to_bounding_box(image_data,100, 100, 3000, 3000) plt.imshow(box_croped.eval()) plt.show() plt.imshow(box_padded.eval()) plt.show() 3、图像翻转 #图像翻转 def flip(image_raw_data): with tf.Session() as sess: image_data = tf.image.decode_jpeg(image_raw_data) #上下翻转 flipped_up = tf.image.flip_up_down(image_data) #左右翻转 flipped_left = tf.image.flip_left_right(image_data) #对角翻转 transposed = tf.image.transpose_image(image_data) plt.imshow(flipped_up.eval()) plt.show() plt.imshow(flipped_left.eval()) plt.show() plt.imshow(transposed.eval()) plt.show() #以50%的概率上下翻转图像 flipped_up_random = tf.image.random_flip_up_down(image_data)]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div class="htmledit_views" id="content_views">
<div>
   一、为什么使用图像预处理
  </div>
<div>
   1、图像的亮度、对比度等属性对图像的影响是非常大的，相同物体在不同的亮度，对比度下差别非常大。在图像识别的问题中，我们经常会遇到阴影、强曝光之类的图片，这些因素都不应该影响最后的识别结果，所以我们要对图像进行预处理，使得得到的神经网络模型尽可能小的被无关因素所影响。
  </div>
<div>
   2、在我们遇到图像样本过少，或者不均衡时，也可以使用图像预处理，增加样本数量。
  </div>
</p>
<div>
   3、有时物体拍摄的角度不同，也会有很大的差异，所以刻意将图像进行随机的翻转，可以提高模型健壮性。
  </div>
<div>
   二、图像处理函数
  </div>
</p>
<div>
   1、读取图像的原始数据。
  </div>
<div>
   图像在存储是并不是直接记录这些矩阵中的数字，而是记录经过压缩编码之后的结果，所以要将一个图片还原成三维矩阵，需要一个解码的过程。
  </div>
</p>
<div>
<pre style="background-color:#ffffff;color:#000000;font-family:'宋体';font-size:9pt;">image_raw_data = tf.gfile.FastGFile(<span style="color:#008080;"><strong>'images/image_0043.jpg'</strong></span>, <span style="color:#008080;"><strong>'rb'</strong></span>).read()
img_data = tf.image.decode_jpeg(image_raw_data)</pre>
</p></div>
<div>
   2、图像大小调整
  </div>
</p>
<div>
   图像大小调整有两种方法，
  </div>
<div>
   第一种是通过算法使得新的图像尽量保存原始图像上的所有信息。
  </div>
<div>
   第二种是对图像进行裁剪或者填充，只获得感兴趣区域。
  </div>
<div>
   TensorFlow提供了四种缩放图像的算法，注意要加入截断函数，防止数值越界。
  </div>
<div>
   <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180611155233733?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2Mzg3Njgz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="">
  </div>
<div>
<pre style="background-color:#ffffff;color:#000000;font-family:'宋体';font-size:9pt;"><span style="color:#808080;"><em>#重新调整图片大小 </em></span><span style="color:#000080;"><strong>def </strong></span>resize(image_data):
    <span style="color:#000080;"><strong>with </strong></span>tf.Session() <span style="color:#000080;"><strong>as </strong></span><span style="color:#808080;">sess</span>:
        image_data = tf.image.convert_image_dtype(image_data, <span style="color:#660099;">dtype</span>=tf.float32)
        methods=[<span style="color:#008080;"><strong>'Bilinear Interpolation'</strong></span>, <span style="color:#008080;"><strong>'Nearest neighbor interpolation'</strong></span>, <span style="color:#008080;"><strong>'Bicubic interpolation'</strong></span>, <span style="color:#008080;"><strong>'Area interpolation'</strong></span>]
        plt.subplot(<span style="color:#0000ff;">231</span>), plt.imshow(image_data.eval()), plt.title(<span style="color:#008080;"><strong>'original'</strong></span>)
        step = <span style="color:#0000ff;">231
</span><span style="color:#0000ff;">        </span><span style="color:#000080;"><strong>for </strong></span>i <span style="color:#000080;"><strong>in </strong></span><span style="color:#000080;">range</span>(<span style="color:#0000ff;">4</span>):
            step += <span style="color:#0000ff;">1
</span><span style="color:#0000ff;">            </span>resized = tf.image.resize_images(image_data, [<span style="color:#0000ff;">300</span>, <span style="color:#0000ff;">300</span>], <span style="color:#660099;">method</span>=i)
            resized = tf.clip_by_value(resized, <span style="color:#0000ff;">0.0</span>, <span style="color:#0000ff;">1.0</span>)
            plt.subplot(step),plt.imshow(resized.eval()), plt.title(methods[i])

        plt.show()
</pre>
</p></div>
<div>
   显示图像如下：
  </div>
<div>
   <img src="https://uzshare.com/_p?https://img-blog.csdn.net/201806111553340?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2Mzg3Njgz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="">
  </div>
<div>
   剪裁和填充图片，通过tf.image.resize_image_with_crop_or_pad函数实现，第一参数是输入图像，后面是裁剪以后的大小。如果小于输入图像，那么就裁剪输入图像居中部分的大小；如果大于输入图像，就填充输入图像四周。
  </div>
<div>
<pre style="background-color:#ffffff;color:#000000;font-family:'宋体';font-size:9pt;"><span style="color:#808080;"><em>#裁剪和填充图片 </em></span><span style="color:#000080;"><strong>def </strong></span>crop_and_pad(image_data):
    <span style="color:#000080;"><strong>with </strong></span>tf.Session() <span style="color:#000080;"><strong>as </strong></span><span style="color:#808080;">sess</span>:
        <span style="color:#808080;"><em>#resize_image_with_crop_or_pad 如果输入图像尺寸大于输出图像，截取原始图像中居中的部分 </em></span><span style="color:#808080;"><em> #如果输入小于输出，会在原始图像四周填充全0背景 </em></span><span style="color:#808080;"><em> </em></span>croped_1 = tf.image.resize_image_with_crop_or_pad(image_data, <span style="color:#0000ff;">300</span>, <span style="color:#0000ff;">300</span>)
        croped_2 = tf.image.resize_image_with_crop_or_pad(image_data, <span style="color:#0000ff;">1000</span>, <span style="color:#0000ff;">1000</span>)
        padded = tf.image.resize_image_with_crop_or_pad(image_data, <span style="color:#0000ff;">3000</span>, <span style="color:#0000ff;">3000</span>)
        show(croped_1)
        show(croped_2)
        show(padded)</pre>
</p></div>
<div>
   也提供了按比例调整图像大小的函数，tf.image.ecntral_crop，
  </div>
<div>
   
  </div>
</p>
<pre style="background-color:#ffffff;color:#000000;font-family:'宋体';font-size:9pt;"></pre>
<div>
   <span style="color:#808080;"><em>#截取中间50%的图片 </em></span><br />
   <span style="color:#000080;"><strong>def </strong></span>central_crop(image_data):<br />
   <span style="color:#000080;"><strong>with </strong></span>tf.Session()<br />
   <span style="color:#000080;"><strong>as </strong></span><br />
   <span style="color:#808080;">sess</span>: central_croped = tf.image.central_crop(image_data,<br />
   <span style="color:#0000ff;">0.5</span>) plt.imshow(central_croped.eval()) plt.show()
  </div>
<div>
  </div>
</p>
</p>
<div>
   还有固定尺寸的裁剪，第二三个参数是起始点的坐标，第四五个参数是宽高</p>
<pre style="background-color:#ffffff;color:#000000;font-family:'宋体';font-size:9pt;"></pre>
<pre style="background-color:#ffffff;color:#000000;font-family:'宋体';font-size:9pt;"><span style="color:#808080;"><em>#固定边框提取 </em></span><span style="color:#000080;"><strong>def </strong></span>bounding_box(image_raw_data):
    <span style="color:#000080;"><strong>with </strong></span>tf.Session() <span style="color:#000080;"><strong>as </strong></span><span style="color:#808080;">sess</span>:

        image_data = tf.image.decode_jpeg(image_raw_data)
        <span style="color:#808080;"><em># crop_to_bounding_box(image, offset_height, offset_width, target_height,arget_width) </em></span><span style="color:#808080;"><em> #第二个第三个参数是起始点的坐标， 四五是宽高 </em></span><span style="color:#808080;"><em> </em></span>box_croped = tf.image.crop_to_bounding_box(image_data, <span style="color:#0000ff;">100</span>, <span style="color:#0000ff;">100</span>, <span style="color:#0000ff;">300</span>, <span style="color:#0000ff;">300</span>)
        <span style="color:#808080;"><em># 二三是原始图像在目标图像上所在的起始坐标，四五是目标图像的大小 </em></span><span style="color:#808080;"><em> </em></span>box_padded = tf.image.pad_to_bounding_box(image_data,<span style="color:#0000ff;">100</span>, <span style="color:#0000ff;">100</span>, <span style="color:#0000ff;">3000</span>, <span style="color:#0000ff;">3000</span>)
        plt.imshow(box_croped.eval())
        plt.show()
        plt.imshow(box_padded.eval())
        plt.show()</pre>
</p></div>
<div>
   3、图像翻转
  </div>
</p>
<pre style="background-color:#ffffff;color:#000000;font-family:'宋体';font-size:9pt;"><span style="color:#808080;"><em>#图像翻转 </em></span><span style="color:#000080;"><strong>def </strong></span>flip(image_raw_data):
    <span style="color:#000080;"><strong>with </strong></span>tf.Session() <span style="color:#000080;"><strong>as </strong></span><span style="color:#808080;">sess</span>:
        image_data = tf.image.decode_jpeg(image_raw_data)
        <span style="color:#808080;"><em>#上下翻转 </em></span><span style="color:#808080;"><em> </em></span>flipped_up = tf.image.flip_up_down(image_data)
        <span style="color:#808080;"><em>#左右翻转 </em></span><span style="color:#808080;"><em> </em></span>flipped_left = tf.image.flip_left_right(image_data)
        <span style="color:#808080;"><em>#对角翻转 </em></span><span style="color:#808080;"><em> </em></span>transposed = tf.image.transpose_image(image_data)

        plt.imshow(flipped_up.eval())
        plt.show()
        plt.imshow(flipped_left.eval())
        plt.show()
        plt.imshow(transposed.eval())
        plt.show()

        <span style="color:#808080;"><em>#以50%的概率上下翻转图像 </em></span><span style="color:#808080;"><em> </em></span>flipped_up_random = tf.image.random_flip_up_down(image_data)
        <span style="color:#808080;"><em>#以50%的概率左右翻转图像 </em></span><span style="color:#808080;"><em> </em></span>flipped_left_random = tf.image.random_flip_left_right(image_data)

        plt.imshow(flipped_up_random.eval())
        plt.show()
        plt.imshow(flipped_left_random.eval())
        plt.show()</pre>
<div>
   <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180611163903276?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2Mzg3Njgz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt="">
  </div>
<div>
   4、图像色彩调整
  </div>
<pre style="background-color:#ffffff;color:#000000;font-family:'宋体';font-size:9pt;"><span style="color:#808080;"><em>#图像亮度调整 </em></span><span style="color:#000080;"><strong>def </strong></span>brightness(image_raw_data):
    <span style="color:#000080;"><strong>with </strong></span>tf.Session() <span style="color:#000080;"><strong>as </strong></span><span style="color:#808080;">sess</span>:
        image_data = tf.image.decode_jpeg(image_raw_data)
        <span style="color:#808080;"><em>#将图像的亮度-0.5 </em></span><span style="color:#808080;"><em> </em></span>adjusted = tf.image.adjust_brightness(image_data,-<span style="color:#0000ff;">0.5</span>)
        <span style="color:#808080;"><em>#为了防止像素超出，要进行截断处理 </em></span><span style="color:#808080;"><em> # adjusted = tf.clip_by_value(adjusted, 0.0, 1.0) </em></span><span style="color:#808080;"><em> </em></span><span style="color:#808080;"><em> </em></span>plt.imshow(adjusted.eval())
        plt.show()

        <span style="color:#808080;"><em>#将图像亮度+0.5 </em></span><span style="color:#808080;"><em> </em></span>adjusted = tf.image.adjust_brightness(image_data, <span style="color:#0000ff;">0.5</span>)
        plt.imshow(adjusted.eval())
        plt.show()

        <span style="color:#808080;"><em>#在【max_delta, max_delax】的范围内随机调整 </em></span><span style="color:#808080;"><em> </em></span>adjusted = tf.image.random_brightness(image_data,<span style="color:#0000ff;">0.5</span>)
        plt.imshow(adjusted.eval())
        plt.show()</pre>
<div>
   图像对比度
  </div>
<div>
<pre style="background-color:#ffffff;color:#000000;font-family:'宋体';font-size:9pt;"><span style="color:#808080;"><em>#调整图像的对比度 </em></span><span style="color:#000080;"><strong>def </strong></span>contrast(image_raw_data):
    <span style="color:#000080;"><strong>with </strong></span>tf.Session() <span style="color:#000080;"><strong>as </strong></span><span style="color:#808080;">sess</span>:

        image_data = tf.image.decode_jpeg(image_raw_data)

        <span style="color:#808080;"><em>#将图像的对比度减少到0.5 </em></span><span style="color:#808080;"><em> </em></span>adjusted = tf.image.adjust_contrast(image_data, <span style="color:#0000ff;">0.5</span>)
        plt.imshow(adjusted.eval())
        plt.show()

        <span style="color:#808080;"><em>#将图像的对比度增加5倍 </em></span><span style="color:#808080;"><em> </em></span>adjusted = tf.image.adjust_contrast(image_data, <span style="color:#0000ff;">5</span>)
        plt.imshow(adjusted.eval())
        plt.show()

        <span style="color:#808080;"><em>#在【lower, upper】之间随机调整 </em></span><span style="color:#808080;"><em> </em></span>adjusted = tf.image.random_contrast(image_data, <span style="color:#0000ff;">0.5</span>, <span style="color:#0000ff;">5</span>)
        plt.imshow(adjusted.eval())
        plt.show()</pre>
</p></div>
<div>
   图像色相
  </div>
<pre style="background-color:#ffffff;color:#000000;font-family:'宋体';font-size:9pt;"><span style="color:#808080;"><em>#调整图像色相 </em></span><span style="color:#000080;"><strong>def </strong></span>hue(image_data):
    <span style="color:#000080;"><strong>with </strong></span>tf.Session() <span style="color:#000080;"><strong>as </strong></span><span style="color:#808080;">sess</span>:
        plt.subplot(<span style="color:#0000ff;">231</span>),plt.imshow(image_data.eval()),plt.title(<span style="color:#008080;"><strong>'original'</strong></span>)
        <span style="color:#808080;"><em>#色相加0.1 </em></span><span style="color:#808080;"><em> </em></span>adjusted = tf.image.adjust_hue(image_data, <span style="color:#0000ff;">0.1</span>)
        plt.subplot(<span style="color:#0000ff;">232</span>),plt.imshow(adjusted.eval()),plt.title(<span style="color:#008080;"><strong>'+0.1'</strong></span>)
        adjusted = tf.image.adjust_hue(image_data, <span style="color:#0000ff;">0.3</span>)
        plt.subplot(<span style="color:#0000ff;">233</span>), plt.imshow(adjusted.eval()), plt.title(<span style="color:#008080;"><strong>'+0.3'</strong></span>)
        adjusted = tf.image.adjust_hue(image_data, <span style="color:#0000ff;">0.6</span>)
        plt.subplot(<span style="color:#0000ff;">234</span>), plt.imshow(adjusted.eval()), plt.title(<span style="color:#008080;"><strong>'+0.6'</strong></span>)
        adjusted = tf.image.adjust_hue(image_data, <span style="color:#0000ff;">0.9</span>)
        plt.subplot(<span style="color:#0000ff;">235</span>), plt.imshow(adjusted.eval()), plt.title(<span style="color:#008080;"><strong>'+0.9'</strong></span>)
        plt.show()

        <span style="color:#808080;"><em>#max_delta 的取值在[0， 0.5]之间 </em></span><span style="color:#808080;"><em> </em></span>adjusted = tf.image.random_hue(image_data, <span style="color:#0000ff;">0.5</span>)
        plt.subplot(<span style="color:#0000ff;">236</span>), plt.imshow(adjusted.eval()), plt.title(<span style="color:#008080;"><strong>'random'</strong></span>)
        plt.show()</pre>
<div>
   图像饱和度
  </div>
<div>
<pre style="background-color:#ffffff;color:#000000;font-family:'宋体';font-size:9pt;"><span style="color:#808080;"><em>#调整饱和度 </em></span><span style="color:#000080;"><strong>def </strong></span>saturation(image_data):
    <span style="color:#000080;"><strong>with </strong></span>tf.Session() <span style="color:#000080;"><strong>as </strong></span><span style="color:#808080;">sess</span>:
        plt.subplot(<span style="color:#0000ff;">221</span>), plt.imshow(image_data.eval()), plt.title(<span style="color:#008080;"><strong>'original'</strong></span>)
        <span style="color:#808080;"><em>#图像饱和度减5 </em></span><span style="color:#808080;"><em> </em></span>adjusted = tf.image.adjust_saturation(image_data, -<span style="color:#0000ff;">5</span>)
        plt.subplot(<span style="color:#0000ff;">222</span>), plt.imshow(adjusted.eval()), plt.title(<span style="color:#008080;"><strong>'-5'</strong></span>)
        <span style="color:#808080;"><em>#图像饱和度加5 </em></span><span style="color:#808080;"><em> </em></span>adjusted = tf.image.adjust_saturation(image_data, <span style="color:#0000ff;">5</span>)
        plt.subplot(<span style="color:#0000ff;">223</span>), plt.imshow(adjusted.eval()), plt.title(<span style="color:#008080;"><strong>'5'</strong></span>)
        <span style="color:#808080;"><em>#在[lower，upper]的范围内随机调整图像的饱和度 lower must be non-negative </em></span><span style="color:#808080;"><em> </em></span>adjusted = tf.image.random_saturation(image_data, <span style="color:#0000ff;">0.</span>, <span style="color:#0000ff;">5.</span>)
        plt.subplot(<span style="color:#0000ff;">224</span>), plt.imshow(adjusted.eval()), plt.title(<span style="color:#008080;"><strong>'random'</strong></span>)
        plt.show()</pre>
</p></div>
<div>
   图片gamma校正
  </div>
<pre style="background-color:#ffffff;color:#000000;font-family:'宋体';font-size:9pt;"><span style="color:#808080;"><em>#图像gamma校正 </em></span><span style="color:#000080;"><strong>def </strong></span>mamma(image_data):
    <span style="color:#000080;"><strong>with </strong></span>tf.Session() <span style="color:#000080;"><strong>as </strong></span><span style="color:#808080;">sess</span>:
        image_data = tf.image.convert_image_dtype(image_data, <span style="color:#660099;">dtype</span>=tf.float32)
        adjusted = tf.image.adjust_gamma(image_data, <span style="color:#660099;">gain</span>=<span style="color:#0000ff;">1.0</span>, <span style="color:#660099;">gamma</span>=<span style="color:#0000ff;">4.0</span>)
        plt.imshow(adjusted.eval())
        plt.show()</pre>
<div>
   图像标准化
  </div>
<div>
<pre style="background-color:#ffffff;color:#000000;font-family:'宋体';font-size:9pt;"><span style="color:#808080;"><em>#图像标准化 </em></span><span style="color:#000080;"><strong>def </strong></span>standardization(image_data):
    <span style="color:#000080;"><strong>with </strong></span>tf.Session() <span style="color:#000080;"><strong>as </strong></span><span style="color:#808080;">sess</span>:
        <span style="color:#000080;">print</span>(image_data)
        h,w = tf.shape(image_data).eval()[:<span style="color:#0000ff;">2</span>]
        <span style="color:#808080;"><em>#将输入图像 </em></span><span style="color:#808080;"><em> </em></span>reshaped = tf.reshape(image_data.eval(), [h*w, -<span style="color:#0000ff;">1</span>])
        <span style="color:#000080;">print</span>(reshaped.eval())
        plt.subplot(<span style="color:#0000ff;">211</span>),plt.hist(reshaped.eval()),plt.title(<span style="color:#008080;"><strong>'original'</strong></span>)
        <span style="color:#808080;"><em>#图像标准化 </em></span><span style="color:#808080;"><em> </em></span>adjusted = tf.image.per_image_standardization(image_data)
        adjusted_reshaped = tf.reshape(adjusted.eval(), [h*w, -<span style="color:#0000ff;">1</span>])
        plt.subplot(<span style="color:#0000ff;">212</span>), plt.hist(adjusted_reshaped.eval()), plt.title(<span style="color:#008080;"><strong>'adjusted'</strong></span>)
        plt.show()</pre>
</p></div>
<div>
   图像预处理完整样例
  </div>
<pre style="background-color:#ffffff;color:#000000;font-family:'宋体';font-size:9pt;"><span style="color:#000080;"><strong>import </strong></span>tensorflow <span style="color:#000080;"><strong>as </strong></span>tf
<span style="color:#000080;"><strong>import </strong></span>numpy <span style="color:#000080;"><strong>as </strong></span>np
<span style="color:#000080;"><strong>import </strong></span>matplotlib.pyplot <span style="color:#000080;"><strong>as </strong></span>plt

<span style="color:#000080;"><strong>def </strong></span>distort_color(image, color_orderding=<span style="color:#0000ff;">0</span>):
    <span style="color:#000080;"><strong>if </strong></span>color_orderding == <span style="color:#0000ff;">0</span>:
        image = tf.image.random_brightness(image, <span style="color:#660099;">max_delta</span>= <span style="color:#0000ff;">32. </span>/ <span style="color:#0000ff;">255.</span>)
        image = tf.image.random_saturation(image, <span style="color:#660099;">lower</span>=<span style="color:#0000ff;">0.5</span>, <span style="color:#660099;">upper</span>=<span style="color:#0000ff;">1.5</span>)
        image = tf.image.random_hue(image, <span style="color:#660099;">max_delta</span>=<span style="color:#0000ff;">0.2</span>)
        image = tf.image.random_contrast(image, <span style="color:#660099;">lower</span>=<span style="color:#0000ff;">0.5</span>, <span style="color:#660099;">upper</span>=<span style="color:#0000ff;">1.5</span>)
    <span style="color:#000080;"><strong>elif </strong></span>color_orderding == <span style="color:#0000ff;">1</span>:
        image = tf.image.random_saturation(image, <span style="color:#660099;">lower</span>=<span style="color:#0000ff;">0.5</span>, <span style="color:#660099;">upper</span>=<span style="color:#0000ff;">1.5</span>)
        image = tf.image.random_brightness(image, <span style="color:#660099;">max_delta</span>= <span style="color:#0000ff;">32. </span>/<span style="color:#0000ff;">255.</span>)
        image = tf.image.random_contrast(image, <span style="color:#660099;">lower</span>=<span style="color:#0000ff;">0.5</span>, <span style="color:#660099;">upper</span>=<span style="color:#0000ff;">1.5</span>)
        image = tf.image.random_hue(image, <span style="color:#660099;">max_delta</span>=<span style="color:#0000ff;">0.2</span>)
    <span style="color:#000080;"><strong>elif </strong></span>color_orderding == <span style="color:#0000ff;">2</span>:
        image = tf.image.random_contrast(image, <span style="color:#660099;">lower</span>=<span style="color:#0000ff;">0.5</span>, <span style="color:#660099;">upper</span>=<span style="color:#0000ff;">1.5</span>)
        image = tf.image.random_saturation(image, <span style="color:#660099;">lower</span>=<span style="color:#0000ff;">0.5</span>, <span style="color:#660099;">upper</span>=<span style="color:#0000ff;">1.5</span>)
        image = tf.image.random_brightness(image, <span style="color:#660099;">max_delta</span>=<span style="color:#0000ff;">32. </span>/ <span style="color:#0000ff;">255.</span>)
        image = tf.image.random_hue(image, <span style="color:#660099;">max_delta</span>=<span style="color:#0000ff;">0.2</span>)
    <span style="color:#000080;"><strong>elif </strong></span>color_orderding == <span style="color:#0000ff;">3</span>:
        image = tf.image.random_hue(image, <span style="color:#660099;">max_delta</span>=<span style="color:#0000ff;">0.2</span>)
        image = tf.image.random_contrast(image, <span style="color:#660099;">lower</span>=<span style="color:#0000ff;">0.5</span>, <span style="color:#660099;">upper</span>=<span style="color:#0000ff;">1.5</span>)
        image = tf.image.random_saturation(image, <span style="color:#660099;">lower</span>=<span style="color:#0000ff;">0.5</span>, <span style="color:#660099;">upper</span>=<span style="color:#0000ff;">1.5</span>)
        image = tf.image.random_brightness(image, <span style="color:#660099;">max_delta</span>=<span style="color:#0000ff;">32. </span>/ <span style="color:#0000ff;">255.</span>)
    <span style="color:#000080;"><strong>else</strong></span>:
        image = tf.image.random_hue(image, <span style="color:#660099;">max_delta</span>=<span style="color:#0000ff;">0.2</span>)
        image = tf.image.random_saturation(image, <span style="color:#660099;">lower</span>=<span style="color:#0000ff;">0.5</span>, <span style="color:#660099;">upper</span>=<span style="color:#0000ff;">1.5</span>)
        image = tf.image.random_contrast(image, <span style="color:#660099;">lower</span>=<span style="color:#0000ff;">0.5</span>, <span style="color:#660099;">upper</span>=<span style="color:#0000ff;">1.5</span>)
        image = tf.image.random_brightness(image, <span style="color:#660099;">max_delta</span>=<span style="color:#0000ff;">32. </span>/ <span style="color:#0000ff;">255.</span>)
    <span style="color:#000080;"><strong>return </strong></span>tf.clip_by_value(image, <span style="color:#0000ff;">0.0</span>, <span style="color:#0000ff;">1.0</span>) <span style="color:#808080;"><em># 进行像素截断，防止越界 </em></span><span style="color:#808080;"><em> </em></span><span style="color:#808080;"><em> </em></span><span style="color:#000080;"><strong>def </strong></span>perprocess_for_train(image, height, width, bbox):
    <span style="color:#000080;"><strong>if </strong></span>bbox <span style="color:#000080;"><strong>is None</strong></span>:
        bbox = tf.constant([<span style="color:#0000ff;">0.0</span>, <span style="color:#0000ff;">0.0</span>, <span style="color:#0000ff;">1.0</span>, <span style="color:#0000ff;">1.0</span>], <span style="color:#660099;">dtype</span>=tf.float32, <span style="color:#660099;">shape</span>=[<span style="color:#0000ff;">1</span>, <span style="color:#0000ff;">1</span>, <span style="color:#0000ff;">4</span>])
    <span style="color:#808080;"><em>#转换图像的张量类型 </em></span><span style="color:#808080;"><em> </em></span><span style="color:#000080;"><strong>if </strong></span>image.dtype != tf.float32:
        image = tf.image.convert_image_dtype(image, <span style="color:#660099;">dtype</span>=tf.float32)

    <span style="color:#808080;"><em># 随机截取图像，减小需要关注物体大小对图像识别算法的影响 </em></span><span style="color:#808080;"><em> </em></span>bbox_begin, bbox_size, _ = tf.image.sample_distorted_bounding_box(tf.shape(image),<span style="color:#660099;">bounding_boxes</span>=bbox)
    distorted_image = tf.slice(image, bbox_begin, bbox_size)

    <span style="color:#808080;"><em>#将随机截取的图像调整为神经网络输入层的大小 </em></span><span style="color:#808080;"><em> </em></span>distorted_image = tf.image.resize_images(distorted_image, [height, width], <span style="color:#660099;">method</span>=np.random.randint(<span style="color:#0000ff;">4</span>))

    <span style="color:#808080;"><em>#随机左右翻转图片 </em></span><span style="color:#808080;"><em> </em></span>distorted_image = tf.image.random_flip_left_right(distorted_image)

    <span style="color:#808080;"><em>#使用一种随机的顺序调整颜色图像 </em></span><span style="color:#808080;"><em> </em></span>distorted_image = distort_color(distorted_image, np.random.randint(<span style="color:#0000ff;">5</span>))
    <span style="color:#000080;"><strong>return </strong></span>distorted_image

image_raw_data = tf.gfile.FastGFile(<span style="color:#008080;"><strong>'images/image_0043.jpg'</strong></span>, <span style="color:#008080;"><strong>'rb'</strong></span>).read()
<span style="color:#000080;"><strong>with </strong></span>tf.Session() <span style="color:#000080;"><strong>as </strong></span>sess:
    image_data = tf.image.decode_jpeg(image_raw_data)
    boxes = tf.constant([[[<span style="color:#0000ff;">0.05</span>, <span style="color:#0000ff;">0.05</span>, <span style="color:#0000ff;">0.9</span>, <span style="color:#0000ff;">0.7</span>], [<span style="color:#0000ff;">0.34</span>, <span style="color:#0000ff;">0.47</span>, <span style="color:#0000ff;">0.5</span>, <span style="color:#0000ff;">0.56</span>]]])
    <span style="color:#808080;"><em># print(image_data) </em></span><span style="color:#808080;"><em> #运行6次获得6种不同的图像 </em></span><span style="color:#808080;"><em> </em></span>step = <span style="color:#0000ff;">230
</span><span style="color:#0000ff;">    </span><span style="color:#000080;"><strong>for </strong></span>i <span style="color:#000080;"><strong>in </strong></span><span style="color:#000080;">range</span>(<span style="color:#0000ff;">6</span>):
        result = perprocess_for_train(image_data,<span style="color:#0000ff;">300</span>, <span style="color:#0000ff;">300</span>, boxes)
        step = step+<span style="color:#0000ff;">1
</span><span style="color:#0000ff;">        </span>plt.subplot(step)
        plt.imshow(result.eval())
    plt.show()
</pre>
<p>  <img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180611164328779?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzM2Mzg3Njgz/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70" alt=""></p>
</p>
</p>
</p>
</p>
<div>
   
  </div>
</p></div>
</div>
]]></content:encoded>
										</item>
		<item>
		<title>先验算法（Apriori Algorithm）原理及python代码实现</title>
		<link>https://uzzz.org/article/3151.html</link>
				<pubDate>Thu, 31 May 2018 01:34:03 +0000</pubDate>
		<dc:creator><![CDATA[fandyvon]]></dc:creator>
				<category><![CDATA[机器学习]]></category>

		<guid isPermaLink="false">https://uzzz.org/article/3151.html</guid>
				<description><![CDATA[先验算法（Apriori Algorithm）是关联规则学习的经典算法之一。先验算法的设计目的是为了处理包含交易信息内容的数据库（例如,顾客购买的商品清单，或者网页常访清单。）而其他的算法则是设计用来寻找无交易信息（如Winepi算法和Minepi算法）或无时间标记（如DNA测序）的数据之间的联系规则。关联分析的目的是从大规模数据集中寻找有趣关系的任务。这些关系可以有两种形式：频繁项集或者关联规则。频繁项集(frequent item sets)是指经常出现在一起的物品的集合，关联关系(association rules)暗示两种物品之间可能存在很强的关系。 先验算法采用广度优先搜索算法进行搜索并采用树结构来对候选项目集进行高效计数。它通过长度为 k-1的候选项目集来产生长度为k的候选项目集，然后从中删除包含不常见子模式的候选项。根据向下封闭性引理,该候选项目集包含所有长度为&#160; k的频繁项目集。之后，就可以通过扫描交易数据库来决定候选项目集中的频繁项目集。 from __future__ import division, print_function import numpy as np import itertools class Rule(): def __init__(self, antecedent, concequent, confidence, support): self.antecedent = antecedent self.concequent = concequent self.confidence = confidence self.support = support class Apriori(): """A method for determining frequent itemsets in a transactional database and also for generating rules for those itemsets. Parameters: ----------- min_sup: float The minimum fraction of transactions an itemets needs to occur in to be deemed frequent min_conf: float: The minimum fraction of times the antecedent needs to imply the concequent to justify rule """ def __init__(self, min_sup=0.3, min_conf=0.81): self.min_sup = min_sup self.min_conf = min_conf self.freq_itemsets = None # List of freqeuent itemsets self.transactions = None # List of transactions def _calculate_support(self, itemset): count = 0 for transaction in self.transactions: if self._transaction_contains_items(transaction, itemset): count += 1 support = count / len(self.transactions) return support def _get_frequent_itemsets(self, candidates): """ Prunes the candidates that are not frequent =&#62; returns list with only frequent itemsets """ frequent = [] # Find frequent items for itemset in candidates: support = self._calculate_support(itemset) if support &#62;=]]></description>
								<content:encoded><![CDATA[<div id="article_content" class="article_content clearfix">
 <!--一个博主专栏付费入口--><br />
 <!--一个博主专栏付费入口结束-->
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
 <link rel="stylesheet" href="https://csdnimg.cn/release/phoenix/template/css/ck_htmledit_views-d284373521.css">
<div class="htmledit_views" id="content_views">
   先验算法（Apriori Algorithm）是关联规则学习的经典算法之一。先验算法的设计目的是为了处理包含交易信息内容的数据库（例如,顾客购买的商品清单，或者网页常访清单。）而其他的算法则是设计用来寻找无交易信息（如Winepi算法和Minepi算法）或无时间标记（如DNA测序）的数据之间的联系规则。关联分析的目的是从大规模数据集中寻找有趣关系的任务。这些关系可以有两种形式：频繁项集或者关联规则。频繁项集(frequent item sets)是指经常出现在一起的物品的集合，关联关系(association rules)暗示两种物品之间可能存在很强的关系。<br />
  </p>
<p>先验算法采用广度优先搜索算法进行搜索并采用树结构来对候选项目集进行高效计数。它通过长度为 k-1的候选项目集来产生长度为k的候选项目集，然后从中删除包含不常见子模式的候选项。根据向下封闭性引理,该候选项目集包含所有长度为&nbsp; k的频繁项目集。之后，就可以通过扫描交易数据库来决定候选项目集中的频繁项目集。</p>
<p><img src="https://uzshare.com/_p?https://img-blog.csdn.net/20180531093322153" alt=""></p>
<p></p>
<pre><code class="language-python">from __future__ import division, print_function
import numpy as np
import itertools


class Rule():
    def __init__(self, antecedent, concequent, confidence, support):
        self.antecedent = antecedent
        self.concequent = concequent
        self.confidence = confidence
        self.support = support


class Apriori():
    """A method for determining frequent itemsets in a transactional database and
    also for generating rules for those itemsets. 
    Parameters:
    -----------
    min_sup: float
        The minimum fraction of transactions an itemets needs to
        occur in to be deemed frequent
    min_conf: float:
        The minimum fraction of times the antecedent needs to imply
        the concequent to justify rule
    """
    def __init__(self, min_sup=0.3, min_conf=0.81):

        self.min_sup = min_sup
        self.min_conf = min_conf
        self.freq_itemsets = None       # List of freqeuent itemsets
        self.transactions = None        # List of transactions

    def _calculate_support(self, itemset):
        count = 0
        for transaction in self.transactions:
            if self._transaction_contains_items(transaction, itemset):
                count += 1
        support = count / len(self.transactions)
        return support


    def _get_frequent_itemsets(self, candidates):
        """ Prunes the candidates that are not frequent =&gt; returns list with 
        only frequent itemsets """
        frequent = []
        # Find frequent items
        for itemset in candidates:
            support = self._calculate_support(itemset)
            if support &gt;= self.min_sup:
                frequent.append(itemset)
        return frequent


    def _has_infrequent_itemsets(self, candidate):
        """ True or false depending on the candidate has any
        subset with size k - 1 that is not in the frequent itemset """
        k = len(candidate)
        # Find all combinations of size k-1 in candidate
        # E.g [1,2,3] =&gt; [[1,2],[1,3],[2,3]]
        subsets = list(itertools.combinations(candidate, k - 1))
        for t in subsets:
            # t - is tuple. If size == 1 get the element
            subset = list(t) if len(t) &gt; 1 else t[0]
            if not subset in self.freq_itemsets[-1]:
                return True
        return False


    def _generate_candidates(self, freq_itemset):
        """ Joins the elements in the frequent itemset and prunes
        resulting sets if they contain subsets that have been determined
        to be infrequent. """
        candidates = []
        for itemset1 in freq_itemset:
            for itemset2 in freq_itemset:
                # Valid if every element but the last are the same
                # and the last element in itemset1 is smaller than the last
                # in itemset2
                valid = False
                single_item = isinstance(itemset1, int)
                if single_item and itemset1 &lt; itemset2:
                    valid = True
                elif not single_item and np.array_equal(itemset1[:-1], itemset2[:-1]) and itemset1[-1] &lt; itemset2[-1]:
                    valid = True

                if valid:
                    # JOIN: Add the last element in itemset2 to itemset1 to
                    # create a new candidate
                    if single_item:
                        candidate = [itemset1, itemset2]
                    else:
                        candidate = itemset1 + [itemset2[-1]]
                    # PRUNE: Check if any subset of candidate have been determined
                    # to be infrequent
                    infrequent = self._has_infrequent_itemsets(candidate)
                    if not infrequent:
                        candidates.append(candidate)
        return candidates


    def _transaction_contains_items(self, transaction, items):
        """ True or false depending on each item in the itemset is
        in the transaction """
        # If items is in fact only one item
        if isinstance(items, int):
            return items in transaction
        # Iterate through list of items and make sure that
        # all items are in the transaction
        for item in items:
            if not item in transaction:
                return False
        return True

    def find_frequent_itemsets(self, transactions):
        """ Returns the set of frequent itemsets in the list of transactions """
        self.transactions = transactions
        # Get all unique items in the transactions
        unique_items = set(item for transaction in self.transactions for item in transaction)
        # Get the frequent items
        self.freq_itemsets = [self._get_frequent_itemsets(unique_items)]
        while(True):
            # Generate new candidates from last added frequent itemsets
            candidates = self._generate_candidates(self.freq_itemsets[-1])
            # Get the frequent itemsets among those candidates
            frequent_itemsets = self._get_frequent_itemsets(candidates)

            # If there are no frequent itemsets we're done
            if not frequent_itemsets:
                break

            # Add them to the total list of frequent itemsets and start over
            self.freq_itemsets.append(frequent_itemsets)

        # Flatten the array and return every frequent itemset
        frequent_itemsets = [
            itemset for sublist in self.freq_itemsets for itemset in sublist]
        return frequent_itemsets


    def _rules_from_itemset(self, initial_itemset, itemset):
        """ Recursive function which returns the rules where confidence &gt;= min_confidence
        Starts with large itemset and recursively explores rules for subsets """
        rules = []
        k = len(itemset)
        # Get all combinations of sub-itemsets of size k - 1 from itemset
        # E.g [1,2,3] =&gt; [[1,2],[1,3],[2,3]]
        subsets = list(itertools.combinations(itemset, k - 1))
        support = self._calculate_support(initial_itemset)
        for antecedent in subsets:
            # itertools.combinations returns tuples =&gt; convert to list
            antecedent = list(antecedent)
            antecedent_support = self._calculate_support(antecedent)
            # Calculate the confidence as sup(A and B) / sup(B), if antecedent
            # is B in an itemset of A and B
            confidence = float("{0:.2f}".format(support / antecedent_support))
            if confidence &gt;= self.min_conf:
                # The concequent is the initial_itemset except for antecedent
                concequent = [itemset for itemset in initial_itemset if not itemset in antecedent]
                # If single item =&gt; get item
                if len(antecedent) == 1:
                    antecedent = antecedent[0]
                if len(concequent) == 1:
                    concequent = concequent[0]
                # Create new rule
                rule = Rule(
                        antecedent=antecedent,
                        concequent=concequent,
                        confidence=confidence,
                        support=support)
                rules.append(rule)
                    
                # If there are subsets that could result in rules
                # recursively add rules from subsets
                if k - 1 &gt; 1:
                    rules += self._rules_from_itemset(initial_itemset, antecedent)
        return rules

    def generate_rules(self, transactions):
        self.transactions = transactions
        frequent_itemsets = self.find_frequent_itemsets(transactions)
        # Only consider itemsets of size &gt;= 2 items
        frequent_itemsets = [itemset for itemset in frequent_itemsets if not isinstance(
                itemset, int)]
        rules = []
        for itemset in frequent_itemsets:
            rules += self._rules_from_itemset(itemset, itemset)
        # Remove empty values
        return rules</code></pre>
<p> 
 </div>
</div>
]]></content:encoded>
										</item>
	</channel>
</rss>
